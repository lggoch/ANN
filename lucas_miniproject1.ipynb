{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miniproject 1: Image Classification\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### Description\n",
    "\n",
    "One of the deepest traditions in learning about deep learning is to first [tackle the exciting problem of MNIST classification](http://deeplearning.net/tutorial/logreg.html). [The MNIST database](https://en.wikipedia.org/wiki/MNIST_database) (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that was [recently extended](https://arxiv.org/abs/1702.05373). We break with this tradition (just a little bit) and tackle first the related problem of classifying cropped, downsampled and grayscaled images of house numbers in the [The Street View House Numbers (SVHN) Dataset](http://ufldl.stanford.edu/housenumbers/).\n",
    "\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- You should have a running installation of [tensorflow](https://www.tensorflow.org/install/) and [keras](https://keras.io/).\n",
    "- You should know the concepts \"multilayer perceptron\", \"stochastic gradient descent with minibatches\", \"training and validation data\", \"overfitting\" and \"early stopping\".\n",
    "\n",
    "### What you will learn\n",
    "\n",
    "- You will learn how to define feedforward neural networks in keras and fit them to data.\n",
    "- You will be guided through a prototyping procedure for the application of deep learning to a specific domain.\n",
    "- You will get in contact with concepts discussed later in the lecture, like \"regularization\", \"batch normalization\" and \"convolutional networks\".\n",
    "- You will gain some experience on the influence of network architecture, optimizer and regularization choices on the goodness of fit.\n",
    "- You will learn to be more patient :) Some fits may take your computer quite a bit of time; run them over night.\n",
    "\n",
    "### Evaluation criteria\n",
    "\n",
    "The evaluation is (mostly) based on the figures you submit and your answer sentences. \n",
    "We will only do random tests of your code and not re-run the full notebook.\n",
    "\n",
    "### Your names\n",
    "\n",
    "Before you start, please enter your full name(s) in the field below; they are used to load the data. The variable student2 may remain empty, if you work alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T09:08:24.514461Z",
     "start_time": "2018-03-09T09:08:24.506410Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "student1 = \"Lucas Gauchoux\"\n",
    "student2 = \"Oussama AbouzaÃ¯d\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helper functions\n",
    "\n",
    "For your convenience we provide here some functions to preprocess the data and plot the results later. Simply run the following cells with `Shift-Enter`.\n",
    "\n",
    "### Dependencies and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T09:09:16.113721Z",
     "start_time": "2018-03-09T09:09:16.100520Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "# you may experiment with different subsets, \n",
    "# but make sure in the submission \n",
    "# it is generated with the correct random seed for all exercises.\n",
    "np.random.seed(hash(student1 + student2) % 2**32)\n",
    "subset_of_classes = np.random.choice(range(10), 5, replace = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 6\n",
    "def plot_some_samples(x, y = [], yhat = [], select_from = [], \n",
    "                      ncols = 6, nrows = 4, xdim = 16, ydim = 16,\n",
    "                      label_mapping = range(10)):\n",
    "    \"\"\"plot some input vectors as grayscale images (optionally together with their assigned or predicted labels).\n",
    "    \n",
    "    x is an NxD - dimensional array, where D is the length of an input vector and N is the number of samples.\n",
    "    Out of the N samples, ncols x nrows indices are randomly selected from the list select_from (if it is empty, select_from becomes range(N)).\n",
    "    \n",
    "    Keyword arguments:\n",
    "    y             -- corresponding labels to plot in green below each image.\n",
    "    yhat          -- corresponding predicted labels to plot in red below each image.\n",
    "    select_from   -- list of indices from which to select the images.\n",
    "    ncols, nrows  -- number of columns and rows to plot.\n",
    "    xdim, ydim    -- number of pixels of the images in x- and y-direction.\n",
    "    label_mapping -- map labels to digits.\n",
    "    \n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(nrows, ncols)\n",
    "    if len(select_from) == 0:\n",
    "        select_from = range(x.shape[0])\n",
    "    indices = np.random.choice(select_from, size = min(ncols * nrows, len(select_from)), replace = False)\n",
    "    for i, ind in enumerate(indices):\n",
    "        thisax = ax[i//ncols,i%ncols]\n",
    "        thisax.matshow(x[ind].reshape(xdim, ydim), cmap='gray')\n",
    "        thisax.set_axis_off()\n",
    "        if len(y) != 0:\n",
    "            j = y[ind] if type(y[ind]) != np.ndarray else y[ind].argmax()\n",
    "            thisax.text(0, 0, (label_mapping[j]+1)%10, color='green', \n",
    "                                                       verticalalignment='top',\n",
    "                                                       transform=thisax.transAxes)\n",
    "        if len(yhat) != 0:\n",
    "            k = yhat[ind] if type(yhat[ind]) != np.ndarray else yhat[ind].argmax()\n",
    "            thisax.text(1, 0, (label_mapping[k]+1)%10, color='red',\n",
    "                                             verticalalignment='top',\n",
    "                                             horizontalalignment='right',\n",
    "                                             transform=thisax.transAxes)\n",
    "    return fig\n",
    "\n",
    "def prepare_standardplot(title, xlabel):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.suptitle(title)\n",
    "    ax1.set_ylabel('categorical cross entropy')\n",
    "    ax1.set_xlabel(xlabel)\n",
    "    ax1.set_yscale('log')\n",
    "    ax2.set_ylabel('accuracy [% correct]')\n",
    "    ax2.set_xlabel(xlabel)\n",
    "    return fig, ax1, ax2\n",
    "\n",
    "def finalize_standardplot(fig, ax1, ax2):\n",
    "    ax1handles, ax1labels = ax1.get_legend_handles_labels()\n",
    "    if len(ax1labels) > 0:\n",
    "        ax1.legend(ax1handles, ax1labels)\n",
    "    ax2handles, ax2labels = ax2.get_legend_handles_labels()\n",
    "    if len(ax2labels) > 0:\n",
    "        ax2.legend(ax2handles, ax2labels)\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "\n",
    "def plot_history(history, title):\n",
    "    fig, ax1, ax2 = prepare_standardplot(title, 'epoch')\n",
    "    ax1.plot(history.history['loss'], label = \"training\")\n",
    "    ax1.plot(history.history['val_loss'], label = \"validation\")\n",
    "    ax2.plot(history.history['acc'], label = \"training\")\n",
    "    ax2.plot(history.history['val_acc'], label = \"validation\")\n",
    "    finalize_standardplot(fig, ax1, ax2)\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and preprocessing the data\n",
    "\n",
    "The data consists of RGB color images with 32x32 pixels, loaded into an array of dimension 32x32x3x(number of images). We convert them to grayscale (using [this method](https://en.wikipedia.org/wiki/SRGB#The_reverse_transformation)) and we downsample them to images of 16x16 pixels by averaging over patches of 2x2 pixels.\n",
    "\n",
    "With these preprocessing steps we obviously remove some information that could be helpful in classifying the images. But, since the processed data is much lower dimensional, the fitting procedures converge faster. This is an advantage in situations like here (or generally when prototyping), were we want to try many different things without having to wait too long for computations to finish. After having gained some experience, one may want to go back to work on the 32x32 RGB images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert RGB images x to grayscale using the formula for Y_linear in https://en.wikipedia.org/wiki/Grayscale#Colorimetric_(perceptual_luminance-preserving)_conversion_to_grayscale\n",
    "def grayscale(x):\n",
    "    x = x.astype('float32')/255\n",
    "    x = np.piecewise(x, [x <= 0.04045, x > 0.04045], \n",
    "                        [lambda x: x/12.92, lambda x: ((x + .055)/1.055)**2.4])\n",
    "    return .2126 * x[:,:,0,:] + .7152 * x[:,:,1,:]  + .07152 * x[:,:,2,:]\n",
    "\n",
    "def downsample(x):\n",
    "    return sum([x[i::2,j::2,:] for i in range(2) for j in range(2)])/4\n",
    "\n",
    "def preprocess(data):\n",
    "    gray = grayscale(data['X'])\n",
    "    downsampled = downsample(gray)\n",
    "    return (downsampled.reshape(16*16, gray.shape[2]).transpose(),\n",
    "            data['y'].flatten() - 1)\n",
    "\n",
    "\n",
    "data_train = scipy.io.loadmat('housenumbers/train_32x32.mat')\n",
    "data_test = scipy.io.loadmat('housenumbers/test_32x32.mat')\n",
    "\n",
    "x_train_all, y_train_all = preprocess(data_train)\n",
    "x_test_all, y_test_all = preprocess(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a subset of classes\n",
    "\n",
    "We furter reduce the size of the dataset (and thus reduce computation time) by selecting only the 5 (out of 10 digits) in subset_of_classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_classes(x, y, classes):\n",
    "    indices = []\n",
    "    labels = []\n",
    "    count = 0\n",
    "    for c in classes:\n",
    "        tmp = np.where(y == c)[0]\n",
    "        indices.extend(tmp)\n",
    "        labels.extend(np.ones(len(tmp), dtype='uint8') * count)\n",
    "        count += 1\n",
    "    return x[indices], labels\n",
    "\n",
    "x_train, y_train = extract_classes(x_train_all, y_train_all, subset_of_classes)\n",
    "x_test, y_test = extract_classes(x_test_all, y_test_all, subset_of_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot some examples now. The green digit at the bottom left of each image indicates the corresponding label in y_test.\n",
    "For further usage of the function plot_some_samples, please have a look at its definition in the plotting section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAECCAYAAAAMxDf2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQDdzIYQoAf8HgGBUdQrfDisAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d9fb0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_some_samples(x_test, y_test, label_mapping = subset_of_classes);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare for fitting we transform the labels to one hot coding, i.e. for 5 classes, label 2 becomes the vector [0, 0, 1, 0, 0] (python uses 0-indexing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: No hidden layer\n",
    "\n",
    "### Description\n",
    "\n",
    "Define and fit a model without a hidden layer. \n",
    "\n",
    "1. Use the softmax activation for the output layer.\n",
    "2. Use the categorical_crossentropy loss.\n",
    "3. Add the accuracy metric to the metrics.\n",
    "4. Choose stochastic gradient descent for the optimizer.\n",
    "5. Choose a minibatch size of 128.\n",
    "6. Fit for as many epochs as needed to see no further decrease in the validation loss.\n",
    "7. Plot the output of the fitting procedure (a history object) using the function plot_history defined above.\n",
    "8. Determine the indices of all test images that are misclassified by the fitted model and plot some of them using the function \n",
    "   `plot_some_samples(x_test, y_test, yhat_test, error_indices, label_mapping = subset_of_classes)`\n",
    "\n",
    "\n",
    "Hints:\n",
    "* Read the keras docs, in particular [Getting started with the Keras Sequential model](https://keras.io/getting-started/sequential-model-guide/).\n",
    "* Have a look at the keras [examples](https://github.com/keras-team/keras/tree/master/examples), e.g. [mnist_mlp](https://github.com/keras-team/keras/blob/master/examples/mnist_mlp.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(5, input_shape=(256,)),\n",
    "    Activation(\"softmax\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34108 samples, validate on 12117 samples\n",
      "Epoch 1/100\n",
      "34108/34108 [==============================] - 1s 20us/step - loss: 1.5324 - acc: 0.3975 - val_loss: 1.5161 - val_acc: 0.4188\n",
      "Epoch 2/100\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 1.5152 - acc: 0.4064 - val_loss: 1.5032 - val_acc: 0.4207\n",
      "Epoch 3/100\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 1.5060 - acc: 0.4066 - val_loss: 1.4939 - val_acc: 0.4210\n",
      "Epoch 4/100\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 1.4999 - acc: 0.4066 - val_loss: 1.4882 - val_acc: 0.4216\n",
      "Epoch 5/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4955 - acc: 0.4067 - val_loss: 1.4850 - val_acc: 0.4219\n",
      "Epoch 6/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4924 - acc: 0.4067 - val_loss: 1.4816 - val_acc: 0.4221\n",
      "Epoch 7/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4898 - acc: 0.4069 - val_loss: 1.4791 - val_acc: 0.4221\n",
      "Epoch 8/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4876 - acc: 0.4069 - val_loss: 1.4795 - val_acc: 0.4235\n",
      "Epoch 9/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4861 - acc: 0.4074 - val_loss: 1.4777 - val_acc: 0.4235\n",
      "Epoch 10/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4845 - acc: 0.4075 - val_loss: 1.4747 - val_acc: 0.4233\n",
      "Epoch 11/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4832 - acc: 0.4074 - val_loss: 1.4754 - val_acc: 0.4242\n",
      "Epoch 12/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4821 - acc: 0.4078 - val_loss: 1.4736 - val_acc: 0.4246\n",
      "Epoch 13/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4809 - acc: 0.4081 - val_loss: 1.4719 - val_acc: 0.4244\n",
      "Epoch 14/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4798 - acc: 0.4080 - val_loss: 1.4718 - val_acc: 0.4251\n",
      "Epoch 15/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4789 - acc: 0.4083 - val_loss: 1.4705 - val_acc: 0.4259\n",
      "Epoch 16/100\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 1.4778 - acc: 0.4088 - val_loss: 1.4696 - val_acc: 0.4251\n",
      "Epoch 17/100\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 1.4770 - acc: 0.4092 - val_loss: 1.4695 - val_acc: 0.4254\n",
      "Epoch 18/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4761 - acc: 0.4092 - val_loss: 1.4689 - val_acc: 0.4270\n",
      "Epoch 19/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4752 - acc: 0.4094 - val_loss: 1.4691 - val_acc: 0.4273\n",
      "Epoch 20/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4744 - acc: 0.4096 - val_loss: 1.4682 - val_acc: 0.4267\n",
      "Epoch 21/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4736 - acc: 0.4098 - val_loss: 1.4685 - val_acc: 0.4290\n",
      "Epoch 22/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4729 - acc: 0.4100 - val_loss: 1.4678 - val_acc: 0.4290\n",
      "Epoch 23/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4722 - acc: 0.4103 - val_loss: 1.4672 - val_acc: 0.4287\n",
      "Epoch 24/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4714 - acc: 0.4109 - val_loss: 1.4665 - val_acc: 0.4269\n",
      "Epoch 25/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4708 - acc: 0.4111 - val_loss: 1.4671 - val_acc: 0.4307\n",
      "Epoch 26/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4701 - acc: 0.4116 - val_loss: 1.4671 - val_acc: 0.4317\n",
      "Epoch 27/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4695 - acc: 0.4120 - val_loss: 1.4658 - val_acc: 0.4297\n",
      "Epoch 28/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4688 - acc: 0.4122 - val_loss: 1.4663 - val_acc: 0.4316\n",
      "Epoch 29/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4683 - acc: 0.4127 - val_loss: 1.4661 - val_acc: 0.4312\n",
      "Epoch 30/100\n",
      "34108/34108 [==============================] - 0s 8us/step - loss: 1.4676 - acc: 0.4128 - val_loss: 1.4651 - val_acc: 0.4310\n",
      "Epoch 31/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4670 - acc: 0.4129 - val_loss: 1.4665 - val_acc: 0.4336\n",
      "Epoch 32/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4665 - acc: 0.4136 - val_loss: 1.4651 - val_acc: 0.4325\n",
      "Epoch 33/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4660 - acc: 0.4138 - val_loss: 1.4646 - val_acc: 0.4319\n",
      "Epoch 34/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4654 - acc: 0.4142 - val_loss: 1.4642 - val_acc: 0.4312\n",
      "Epoch 35/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4649 - acc: 0.4142 - val_loss: 1.4653 - val_acc: 0.4343\n",
      "Epoch 36/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4644 - acc: 0.4150 - val_loss: 1.4645 - val_acc: 0.4332\n",
      "Epoch 37/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4640 - acc: 0.4149 - val_loss: 1.4640 - val_acc: 0.4331\n",
      "Epoch 38/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4634 - acc: 0.4149 - val_loss: 1.4648 - val_acc: 0.4343\n",
      "Epoch 39/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4630 - acc: 0.4157 - val_loss: 1.4639 - val_acc: 0.4341\n",
      "Epoch 40/100\n",
      "34108/34108 [==============================] - 0s 8us/step - loss: 1.4624 - acc: 0.4158 - val_loss: 1.4640 - val_acc: 0.4337\n",
      "Epoch 41/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4621 - acc: 0.4161 - val_loss: 1.4637 - val_acc: 0.4341\n",
      "Epoch 42/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4616 - acc: 0.4164 - val_loss: 1.4631 - val_acc: 0.4339\n",
      "Epoch 43/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4612 - acc: 0.4164 - val_loss: 1.4635 - val_acc: 0.4362\n",
      "Epoch 44/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4607 - acc: 0.4168 - val_loss: 1.4645 - val_acc: 0.4371\n",
      "Epoch 45/100\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 1.4603 - acc: 0.4179 - val_loss: 1.4638 - val_acc: 0.4351\n",
      "Epoch 46/100\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 1.4600 - acc: 0.4176 - val_loss: 1.4631 - val_acc: 0.4358\n",
      "Epoch 47/100\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 1.4595 - acc: 0.4182 - val_loss: 1.4630 - val_acc: 0.4363\n",
      "Epoch 48/100\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 1.4592 - acc: 0.4185 - val_loss: 1.4629 - val_acc: 0.4354\n",
      "Epoch 49/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4588 - acc: 0.4187 - val_loss: 1.4629 - val_acc: 0.4359\n",
      "Epoch 50/100\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 1.4585 - acc: 0.4183 - val_loss: 1.4635 - val_acc: 0.4382\n",
      "Epoch 51/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4581 - acc: 0.4194 - val_loss: 1.4630 - val_acc: 0.4368\n",
      "Epoch 52/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4576 - acc: 0.4199 - val_loss: 1.4630 - val_acc: 0.4362\n",
      "Epoch 53/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4574 - acc: 0.4193 - val_loss: 1.4635 - val_acc: 0.4385\n",
      "Epoch 54/100\n",
      "34108/34108 [==============================] - 0s 8us/step - loss: 1.4571 - acc: 0.4199 - val_loss: 1.4634 - val_acc: 0.4379\n",
      "Epoch 55/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4567 - acc: 0.4198 - val_loss: 1.4629 - val_acc: 0.4395\n",
      "Epoch 56/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4564 - acc: 0.4204 - val_loss: 1.4624 - val_acc: 0.4375\n",
      "Epoch 57/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4561 - acc: 0.4204 - val_loss: 1.4629 - val_acc: 0.4386\n",
      "Epoch 58/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4557 - acc: 0.4212 - val_loss: 1.4625 - val_acc: 0.4386\n",
      "Epoch 59/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4554 - acc: 0.4212 - val_loss: 1.4622 - val_acc: 0.4379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4551 - acc: 0.4209 - val_loss: 1.4631 - val_acc: 0.4400\n",
      "Epoch 61/100\n",
      "34108/34108 [==============================] - 0s 8us/step - loss: 1.4549 - acc: 0.4211 - val_loss: 1.4633 - val_acc: 0.4416\n",
      "Epoch 62/100\n",
      "34108/34108 [==============================] - 0s 8us/step - loss: 1.4545 - acc: 0.4218 - val_loss: 1.4626 - val_acc: 0.4391\n",
      "Epoch 63/100\n",
      "34108/34108 [==============================] - 0s 8us/step - loss: 1.4543 - acc: 0.4216 - val_loss: 1.4626 - val_acc: 0.4396\n",
      "Epoch 64/100\n",
      "34108/34108 [==============================] - 0s 8us/step - loss: 1.4540 - acc: 0.4219 - val_loss: 1.4629 - val_acc: 0.4404\n",
      "Epoch 65/100\n",
      "34108/34108 [==============================] - 0s 8us/step - loss: 1.4538 - acc: 0.4222 - val_loss: 1.4627 - val_acc: 0.4411\n",
      "Epoch 66/100\n",
      "34108/34108 [==============================] - 0s 8us/step - loss: 1.4535 - acc: 0.4223 - val_loss: 1.4629 - val_acc: 0.4409\n",
      "Epoch 67/100\n",
      "34108/34108 [==============================] - 0s 8us/step - loss: 1.4531 - acc: 0.4230 - val_loss: 1.4623 - val_acc: 0.4383\n",
      "Epoch 68/100\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 1.4530 - acc: 0.4222 - val_loss: 1.4632 - val_acc: 0.4423\n",
      "Epoch 69/100\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 1.4527 - acc: 0.4230 - val_loss: 1.4622 - val_acc: 0.4395\n",
      "Epoch 70/100\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 1.4525 - acc: 0.4231 - val_loss: 1.4628 - val_acc: 0.4424\n",
      "Epoch 71/100\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 1.4522 - acc: 0.4233 - val_loss: 1.4635 - val_acc: 0.4443\n",
      "Epoch 72/100\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 1.4519 - acc: 0.4236 - val_loss: 1.4633 - val_acc: 0.4426\n",
      "Epoch 73/100\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 1.4518 - acc: 0.4240 - val_loss: 1.4623 - val_acc: 0.4412\n",
      "Epoch 74/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4515 - acc: 0.4231 - val_loss: 1.4634 - val_acc: 0.4449\n",
      "Epoch 75/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4513 - acc: 0.4239 - val_loss: 1.4637 - val_acc: 0.4447\n",
      "Epoch 76/100\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 1.4511 - acc: 0.4242 - val_loss: 1.4622 - val_acc: 0.4411\n",
      "Epoch 77/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4509 - acc: 0.4245 - val_loss: 1.4647 - val_acc: 0.4462\n",
      "Epoch 78/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4505 - acc: 0.4248 - val_loss: 1.4625 - val_acc: 0.4419\n",
      "Epoch 79/100\n",
      "34108/34108 [==============================] - 0s 8us/step - loss: 1.4504 - acc: 0.4247 - val_loss: 1.4630 - val_acc: 0.4430\n",
      "Epoch 80/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4501 - acc: 0.4248 - val_loss: 1.4634 - val_acc: 0.4459\n",
      "Epoch 81/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4499 - acc: 0.4254 - val_loss: 1.4626 - val_acc: 0.4420\n",
      "Epoch 82/100\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 1.4498 - acc: 0.4253 - val_loss: 1.4627 - val_acc: 0.4407\n",
      "Epoch 83/100\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 1.4496 - acc: 0.4250 - val_loss: 1.4627 - val_acc: 0.4414\n",
      "Epoch 84/100\n",
      "34108/34108 [==============================] - 0s 8us/step - loss: 1.4494 - acc: 0.4255 - val_loss: 1.4632 - val_acc: 0.4452\n",
      "Epoch 85/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4492 - acc: 0.4256 - val_loss: 1.4636 - val_acc: 0.4464\n",
      "Epoch 86/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4489 - acc: 0.4256 - val_loss: 1.4634 - val_acc: 0.4471\n",
      "Epoch 87/100\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 1.4488 - acc: 0.4261 - val_loss: 1.4634 - val_acc: 0.4452\n",
      "Epoch 88/100\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 1.4487 - acc: 0.4260 - val_loss: 1.4630 - val_acc: 0.4466\n",
      "Epoch 89/100\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 1.4485 - acc: 0.4266 - val_loss: 1.4628 - val_acc: 0.4428\n",
      "Epoch 90/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4482 - acc: 0.4262 - val_loss: 1.4626 - val_acc: 0.4443\n",
      "Epoch 91/100\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 1.4480 - acc: 0.4267 - val_loss: 1.4626 - val_acc: 0.4443\n",
      "Epoch 92/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4478 - acc: 0.4268 - val_loss: 1.4634 - val_acc: 0.4443\n",
      "Epoch 93/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4477 - acc: 0.4269 - val_loss: 1.4634 - val_acc: 0.4473\n",
      "Epoch 94/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4476 - acc: 0.4270 - val_loss: 1.4637 - val_acc: 0.4487\n",
      "Epoch 95/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4474 - acc: 0.4279 - val_loss: 1.4631 - val_acc: 0.4458\n",
      "Epoch 96/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4472 - acc: 0.4276 - val_loss: 1.4628 - val_acc: 0.4427\n",
      "Epoch 97/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4470 - acc: 0.4273 - val_loss: 1.4635 - val_acc: 0.4472\n",
      "Epoch 98/100\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 1.4469 - acc: 0.4275 - val_loss: 1.4630 - val_acc: 0.4462\n",
      "Epoch 99/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4467 - acc: 0.4275 - val_loss: 1.4637 - val_acc: 0.4491\n",
      "Epoch 100/100\n",
      "34108/34108 [==============================] - 0s 9us/step - loss: 1.4465 - acc: 0.4283 - val_loss: 1.4639 - val_acc: 0.4497\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs = 100,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEdCAYAAABZtfMGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x182b6c9438>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEdCAYAAABZtfMGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x182b6c9438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history,\"TEST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: One hidden layer, different optizimizers\n",
    "### Description\n",
    "\n",
    "Train a network with one hidden layer and compare different optimizers.\n",
    "\n",
    "1. Use one hidden layer with 64 units and the 'relu' activation. Use the [summary method](https://keras.io/models/about-keras-models/) to inspect your model.\n",
    "2. Fit the model for 50 epochs with different learning rates of stochastic gradient descent and answer the question below.\n",
    "3. Replace the stochastic gradient descent optimizer with the [Adam optimizer](https://keras.io/optimizers/#adam).\n",
    "4. Plot the learning curves of SGD with a reasonable learning rate together with the learning curves of Adam in the same figure. Take care of a reasonable labeling of the curves in the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential([\n",
    "    Dense(64, input_shape=(256,)),\n",
    "    Activation('relu'),\n",
    "    Dense(5),\n",
    "    Activation('softmax'),\n",
    "])\n",
    "#model_2.add(Dense(64, input_shape=(256,), activation = 'relu'))\n",
    "#model_2.add(Dense(5, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_2.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 16,773\n",
      "Trainable params: 16,773\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34108 samples, validate on 12117 samples\n",
      "Epoch 1/50\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.5333 - acc: 0.8404 - val_loss: 0.6124 - val_acc: 0.8180\n",
      "Epoch 2/50\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.5326 - acc: 0.8409 - val_loss: 0.6112 - val_acc: 0.8186\n",
      "Epoch 3/50\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.5319 - acc: 0.8405 - val_loss: 0.6111 - val_acc: 0.8198\n",
      "Epoch 4/50\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.5309 - acc: 0.8413 - val_loss: 0.6114 - val_acc: 0.8182\n",
      "Epoch 5/50\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.5300 - acc: 0.8419 - val_loss: 0.6098 - val_acc: 0.8191\n",
      "Epoch 6/50\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.5293 - acc: 0.8419 - val_loss: 0.6128 - val_acc: 0.8187\n",
      "Epoch 7/50\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.5282 - acc: 0.8415 - val_loss: 0.6112 - val_acc: 0.8191\n",
      "Epoch 8/50\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.5276 - acc: 0.8417 - val_loss: 0.6086 - val_acc: 0.8193\n",
      "Epoch 9/50\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.5270 - acc: 0.8417 - val_loss: 0.6059 - val_acc: 0.8207\n",
      "Epoch 10/50\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.5257 - acc: 0.8423 - val_loss: 0.6116 - val_acc: 0.8193\n",
      "Epoch 11/50\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.5256 - acc: 0.8429 - val_loss: 0.6100 - val_acc: 0.8205\n",
      "Epoch 12/50\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.5242 - acc: 0.8434 - val_loss: 0.6078 - val_acc: 0.8207\n",
      "Epoch 13/50\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.5237 - acc: 0.8433 - val_loss: 0.6046 - val_acc: 0.8207\n",
      "Epoch 14/50\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.5229 - acc: 0.8423 - val_loss: 0.6044 - val_acc: 0.8211\n",
      "Epoch 15/50\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.5222 - acc: 0.8435 - val_loss: 0.6077 - val_acc: 0.8219\n",
      "Epoch 16/50\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.5213 - acc: 0.8438 - val_loss: 0.6053 - val_acc: 0.8203\n",
      "Epoch 17/50\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.5207 - acc: 0.8449 - val_loss: 0.6097 - val_acc: 0.8196\n",
      "Epoch 18/50\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.5194 - acc: 0.8434 - val_loss: 0.6020 - val_acc: 0.8201\n",
      "Epoch 19/50\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.5195 - acc: 0.8446 - val_loss: 0.6023 - val_acc: 0.8222\n",
      "Epoch 20/50\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.5185 - acc: 0.8444 - val_loss: 0.6070 - val_acc: 0.8229\n",
      "Epoch 21/50\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.5179 - acc: 0.8438 - val_loss: 0.6033 - val_acc: 0.8220\n",
      "Epoch 22/50\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.5172 - acc: 0.8450 - val_loss: 0.6000 - val_acc: 0.8223\n",
      "Epoch 23/50\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.5164 - acc: 0.8443 - val_loss: 0.6020 - val_acc: 0.8210\n",
      "Epoch 24/50\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.5156 - acc: 0.8454 - val_loss: 0.6006 - val_acc: 0.8227\n",
      "Epoch 25/50\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.5147 - acc: 0.8460 - val_loss: 0.6071 - val_acc: 0.8212\n",
      "Epoch 26/50\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.5146 - acc: 0.8456 - val_loss: 0.6022 - val_acc: 0.8225\n",
      "Epoch 27/50\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.5131 - acc: 0.8450 - val_loss: 0.6049 - val_acc: 0.8224\n",
      "Epoch 28/50\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.5128 - acc: 0.8457 - val_loss: 0.6009 - val_acc: 0.8242\n",
      "Epoch 29/50\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.5120 - acc: 0.8458 - val_loss: 0.6003 - val_acc: 0.8236\n",
      "Epoch 30/50\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.5115 - acc: 0.8462 - val_loss: 0.5973 - val_acc: 0.8245\n",
      "Epoch 31/50\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.5109 - acc: 0.8470 - val_loss: 0.5997 - val_acc: 0.8240\n",
      "Epoch 32/50\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.5097 - acc: 0.8475 - val_loss: 0.5975 - val_acc: 0.8248\n",
      "Epoch 33/50\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.5092 - acc: 0.8470 - val_loss: 0.5954 - val_acc: 0.8240\n",
      "Epoch 34/50\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.5087 - acc: 0.8478 - val_loss: 0.5963 - val_acc: 0.8244\n",
      "Epoch 35/50\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.5080 - acc: 0.8477 - val_loss: 0.6043 - val_acc: 0.8246\n",
      "Epoch 36/50\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.5074 - acc: 0.8481 - val_loss: 0.5947 - val_acc: 0.8245\n",
      "Epoch 37/50\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.5065 - acc: 0.8475 - val_loss: 0.5986 - val_acc: 0.8250\n",
      "Epoch 38/50\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.5060 - acc: 0.8486 - val_loss: 0.5943 - val_acc: 0.8248\n",
      "Epoch 39/50\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.5053 - acc: 0.8482 - val_loss: 0.5966 - val_acc: 0.8251\n",
      "Epoch 40/50\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.5046 - acc: 0.8491 - val_loss: 0.5953 - val_acc: 0.8261\n",
      "Epoch 41/50\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.5038 - acc: 0.8490 - val_loss: 0.5948 - val_acc: 0.8260\n",
      "Epoch 42/50\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.5033 - acc: 0.8493 - val_loss: 0.5922 - val_acc: 0.8251\n",
      "Epoch 43/50\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.5027 - acc: 0.8487 - val_loss: 0.5946 - val_acc: 0.8254\n",
      "Epoch 44/50\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.5017 - acc: 0.8496 - val_loss: 0.5952 - val_acc: 0.8260\n",
      "Epoch 45/50\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.5013 - acc: 0.8490 - val_loss: 0.5926 - val_acc: 0.8268\n",
      "Epoch 46/50\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.5004 - acc: 0.8502 - val_loss: 0.5944 - val_acc: 0.8274\n",
      "Epoch 47/50\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.4999 - acc: 0.8490 - val_loss: 0.5907 - val_acc: 0.8274\n",
      "Epoch 48/50\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.4995 - acc: 0.8495 - val_loss: 0.5945 - val_acc: 0.8267\n",
      "Epoch 49/50\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.4989 - acc: 0.8498 - val_loss: 0.5919 - val_acc: 0.8275\n",
      "Epoch 50/50\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.4982 - acc: 0.8503 - val_loss: 0.5920 - val_acc: 0.8270\n"
     ]
    }
   ],
   "source": [
    "history = model_2.fit(x_train, y_train,\n",
    "           batch_size= 128,\n",
    "           epochs=50,\n",
    "           verbose=1,\n",
    "           validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEdCAYAAABZtfMGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x182fec4f60>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEdCAYAAABZtfMGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x182fec4f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history, \"Fit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What happens if the learning rate of SGD is A) very large B) very small? Please answer A) and B) with one full sentence (double click this markdown cell to edit).\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "A) \n",
    "\n",
    "B) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Overfitting and early stopping with Adam\n",
    "\n",
    "### Description\n",
    "\n",
    "Run the above simulation with Adam for sufficiently many epochs (be patient!) until you see clear overfitting.\n",
    "\n",
    "1. Plot the learning curves of a fit with Adam and sufficiently many epochs and answer the questions below.\n",
    "\n",
    "A simple, but effective mean to avoid overfitting is early stopping, i.e. a fit is not run until convergence but stopped as soon as the validation error starts to increase. We will use early stopping in all subsequent exercises.\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_2.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 16,773\n",
      "Trainable params: 16,773\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34108 samples, validate on 12117 samples\n",
      "Epoch 1/1000\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.5169 - acc: 0.8434 - val_loss: 0.6026 - val_acc: 0.8239\n",
      "Epoch 2/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.5079 - acc: 0.8454 - val_loss: 0.5957 - val_acc: 0.8213\n",
      "Epoch 3/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.5040 - acc: 0.8465 - val_loss: 0.5854 - val_acc: 0.8288\n",
      "Epoch 4/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.4940 - acc: 0.8510 - val_loss: 0.5708 - val_acc: 0.8324\n",
      "Epoch 5/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.4878 - acc: 0.8532 - val_loss: 0.5886 - val_acc: 0.8292\n",
      "Epoch 6/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.4790 - acc: 0.8544 - val_loss: 0.5763 - val_acc: 0.8354\n",
      "Epoch 7/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.4753 - acc: 0.8557 - val_loss: 0.5746 - val_acc: 0.8314\n",
      "Epoch 8/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.4681 - acc: 0.8583 - val_loss: 0.5592 - val_acc: 0.8365\n",
      "Epoch 9/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.4623 - acc: 0.8612 - val_loss: 0.5662 - val_acc: 0.8328\n",
      "Epoch 10/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.4569 - acc: 0.8613 - val_loss: 0.5518 - val_acc: 0.8369\n",
      "Epoch 11/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.4511 - acc: 0.8638 - val_loss: 0.5529 - val_acc: 0.8401\n",
      "Epoch 12/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.4442 - acc: 0.8650 - val_loss: 0.5598 - val_acc: 0.8388\n",
      "Epoch 13/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.4387 - acc: 0.8676 - val_loss: 0.5722 - val_acc: 0.8349\n",
      "Epoch 14/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.4370 - acc: 0.8678 - val_loss: 0.5426 - val_acc: 0.8458\n",
      "Epoch 15/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.4284 - acc: 0.8719 - val_loss: 0.5613 - val_acc: 0.8378\n",
      "Epoch 16/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.4250 - acc: 0.8728 - val_loss: 0.5354 - val_acc: 0.8480\n",
      "Epoch 17/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.4199 - acc: 0.8746 - val_loss: 0.5344 - val_acc: 0.8468\n",
      "Epoch 18/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.4097 - acc: 0.8778 - val_loss: 0.5291 - val_acc: 0.8467\n",
      "Epoch 19/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.4094 - acc: 0.8777 - val_loss: 0.5492 - val_acc: 0.8454\n",
      "Epoch 20/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.4077 - acc: 0.8779 - val_loss: 0.5221 - val_acc: 0.8534\n",
      "Epoch 21/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.3990 - acc: 0.8814 - val_loss: 0.5276 - val_acc: 0.8503\n",
      "Epoch 22/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.3968 - acc: 0.8816 - val_loss: 0.5157 - val_acc: 0.8564\n",
      "Epoch 23/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.3911 - acc: 0.8840 - val_loss: 0.5565 - val_acc: 0.8488\n",
      "Epoch 24/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.3911 - acc: 0.8840 - val_loss: 0.5542 - val_acc: 0.8474\n",
      "Epoch 25/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.3845 - acc: 0.8862 - val_loss: 0.5322 - val_acc: 0.8518\n",
      "Epoch 26/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.3799 - acc: 0.8872 - val_loss: 0.5212 - val_acc: 0.8558\n",
      "Epoch 27/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.3769 - acc: 0.8892 - val_loss: 0.5066 - val_acc: 0.8617\n",
      "Epoch 28/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.3769 - acc: 0.8872 - val_loss: 0.5069 - val_acc: 0.8591\n",
      "Epoch 29/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.3689 - acc: 0.8915 - val_loss: 0.5113 - val_acc: 0.8626\n",
      "Epoch 30/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.3678 - acc: 0.8911 - val_loss: 0.5136 - val_acc: 0.8623\n",
      "Epoch 31/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.3637 - acc: 0.8930 - val_loss: 0.5043 - val_acc: 0.8621\n",
      "Epoch 32/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.3630 - acc: 0.8917 - val_loss: 0.5066 - val_acc: 0.8607\n",
      "Epoch 33/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.3583 - acc: 0.8946 - val_loss: 0.5084 - val_acc: 0.8651\n",
      "Epoch 34/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.3551 - acc: 0.8944 - val_loss: 0.5090 - val_acc: 0.8600\n",
      "Epoch 35/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.3558 - acc: 0.8938 - val_loss: 0.4931 - val_acc: 0.8650\n",
      "Epoch 36/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.3483 - acc: 0.8959 - val_loss: 0.4893 - val_acc: 0.8685\n",
      "Epoch 37/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.3465 - acc: 0.8964 - val_loss: 0.4950 - val_acc: 0.8670\n",
      "Epoch 38/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.3470 - acc: 0.8972 - val_loss: 0.4866 - val_acc: 0.8714\n",
      "Epoch 39/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.3411 - acc: 0.8987 - val_loss: 0.4903 - val_acc: 0.8711\n",
      "Epoch 40/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.3395 - acc: 0.8994 - val_loss: 0.5156 - val_acc: 0.8631\n",
      "Epoch 41/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.3390 - acc: 0.9008 - val_loss: 0.4910 - val_acc: 0.8708\n",
      "Epoch 42/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.3347 - acc: 0.9010 - val_loss: 0.5110 - val_acc: 0.8684\n",
      "Epoch 43/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.3326 - acc: 0.9008 - val_loss: 0.4930 - val_acc: 0.8684\n",
      "Epoch 44/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.3346 - acc: 0.9005 - val_loss: 0.4923 - val_acc: 0.8708\n",
      "Epoch 45/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.3329 - acc: 0.9008 - val_loss: 0.5225 - val_acc: 0.8662\n",
      "Epoch 46/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.3284 - acc: 0.9010 - val_loss: 0.5078 - val_acc: 0.8670\n",
      "Epoch 47/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.3222 - acc: 0.9031 - val_loss: 0.4890 - val_acc: 0.8735\n",
      "Epoch 48/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.3208 - acc: 0.9048 - val_loss: 0.4991 - val_acc: 0.8695\n",
      "Epoch 49/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.3219 - acc: 0.9044 - val_loss: 0.4938 - val_acc: 0.8736\n",
      "Epoch 50/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.3218 - acc: 0.9032 - val_loss: 0.5128 - val_acc: 0.8668\n",
      "Epoch 51/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.3167 - acc: 0.9062 - val_loss: 0.5066 - val_acc: 0.8712\n",
      "Epoch 52/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.3187 - acc: 0.9049 - val_loss: 0.4922 - val_acc: 0.8722\n",
      "Epoch 53/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.3133 - acc: 0.9062 - val_loss: 0.4917 - val_acc: 0.8703\n",
      "Epoch 54/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.3130 - acc: 0.9064 - val_loss: 0.4864 - val_acc: 0.8734\n",
      "Epoch 55/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.3096 - acc: 0.9078 - val_loss: 0.5004 - val_acc: 0.8720\n",
      "Epoch 56/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.3080 - acc: 0.9077 - val_loss: 0.5008 - val_acc: 0.8711\n",
      "Epoch 57/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.3090 - acc: 0.9073 - val_loss: 0.4856 - val_acc: 0.8748\n",
      "Epoch 58/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.3047 - acc: 0.9090 - val_loss: 0.4938 - val_acc: 0.8732\n",
      "Epoch 59/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.3046 - acc: 0.9093 - val_loss: 0.4878 - val_acc: 0.8768\n",
      "Epoch 60/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.3010 - acc: 0.9103 - val_loss: 0.4913 - val_acc: 0.8736\n",
      "Epoch 61/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.3016 - acc: 0.9105 - val_loss: 0.5087 - val_acc: 0.8705\n",
      "Epoch 62/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.3001 - acc: 0.9092 - val_loss: 0.4906 - val_acc: 0.8751\n",
      "Epoch 63/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.2980 - acc: 0.9111 - val_loss: 0.4968 - val_acc: 0.8719\n",
      "Epoch 64/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.2951 - acc: 0.9114 - val_loss: 0.4936 - val_acc: 0.8751\n",
      "Epoch 65/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2943 - acc: 0.9113 - val_loss: 0.4932 - val_acc: 0.8746\n",
      "Epoch 66/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2947 - acc: 0.9113 - val_loss: 0.4862 - val_acc: 0.8760\n",
      "Epoch 67/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2903 - acc: 0.9125 - val_loss: 0.4967 - val_acc: 0.8726\n",
      "Epoch 68/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.2910 - acc: 0.9103 - val_loss: 0.4945 - val_acc: 0.8774\n",
      "Epoch 69/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2927 - acc: 0.9125 - val_loss: 0.5214 - val_acc: 0.8675\n",
      "Epoch 70/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.2874 - acc: 0.9142 - val_loss: 0.4996 - val_acc: 0.8769\n",
      "Epoch 71/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2873 - acc: 0.9141 - val_loss: 0.4860 - val_acc: 0.8793\n",
      "Epoch 72/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2856 - acc: 0.9141 - val_loss: 0.4918 - val_acc: 0.8785\n",
      "Epoch 73/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2828 - acc: 0.9148 - val_loss: 0.4974 - val_acc: 0.8770\n",
      "Epoch 74/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2827 - acc: 0.9153 - val_loss: 0.4988 - val_acc: 0.8742\n",
      "Epoch 75/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.2811 - acc: 0.9162 - val_loss: 0.4892 - val_acc: 0.8798\n",
      "Epoch 76/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2801 - acc: 0.9161 - val_loss: 0.5032 - val_acc: 0.8768\n",
      "Epoch 77/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2786 - acc: 0.9182 - val_loss: 0.4945 - val_acc: 0.8762\n",
      "Epoch 78/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2772 - acc: 0.9172 - val_loss: 0.4922 - val_acc: 0.8772\n",
      "Epoch 79/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2748 - acc: 0.9183 - val_loss: 0.4943 - val_acc: 0.8783\n",
      "Epoch 80/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2799 - acc: 0.9149 - val_loss: 0.4904 - val_acc: 0.8802\n",
      "Epoch 81/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2753 - acc: 0.9159 - val_loss: 0.5165 - val_acc: 0.8741\n",
      "Epoch 82/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2732 - acc: 0.9185 - val_loss: 0.4963 - val_acc: 0.8785\n",
      "Epoch 83/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.2735 - acc: 0.9174 - val_loss: 0.5414 - val_acc: 0.8661\n",
      "Epoch 84/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2703 - acc: 0.9195 - val_loss: 0.5121 - val_acc: 0.8760\n",
      "Epoch 85/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2695 - acc: 0.9183 - val_loss: 0.4974 - val_acc: 0.8798\n",
      "Epoch 86/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.2684 - acc: 0.9199 - val_loss: 0.4960 - val_acc: 0.8790\n",
      "Epoch 87/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.2708 - acc: 0.9180 - val_loss: 0.4906 - val_acc: 0.8819\n",
      "Epoch 88/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2753 - acc: 0.9175 - val_loss: 0.4996 - val_acc: 0.8790\n",
      "Epoch 89/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2676 - acc: 0.9191 - val_loss: 0.4988 - val_acc: 0.8781\n",
      "Epoch 90/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.2708 - acc: 0.9166 - val_loss: 0.5017 - val_acc: 0.8801\n",
      "Epoch 91/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2648 - acc: 0.9208 - val_loss: 0.5265 - val_acc: 0.8726\n",
      "Epoch 92/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.2607 - acc: 0.9216 - val_loss: 0.5028 - val_acc: 0.8797\n",
      "Epoch 93/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.2625 - acc: 0.9206 - val_loss: 0.5018 - val_acc: 0.8779\n",
      "Epoch 94/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.2607 - acc: 0.9221 - val_loss: 0.5016 - val_acc: 0.8781\n",
      "Epoch 95/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2611 - acc: 0.9215 - val_loss: 0.5010 - val_acc: 0.8781\n",
      "Epoch 96/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2594 - acc: 0.9220 - val_loss: 0.5160 - val_acc: 0.8769\n",
      "Epoch 97/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2582 - acc: 0.9218 - val_loss: 0.5021 - val_acc: 0.8775\n",
      "Epoch 98/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2556 - acc: 0.9239 - val_loss: 0.5130 - val_acc: 0.8765\n",
      "Epoch 99/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2584 - acc: 0.9213 - val_loss: 0.4947 - val_acc: 0.8831\n",
      "Epoch 100/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2540 - acc: 0.9232 - val_loss: 0.5039 - val_acc: 0.8789\n",
      "Epoch 101/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2531 - acc: 0.9243 - val_loss: 0.5089 - val_acc: 0.8777\n",
      "Epoch 102/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2524 - acc: 0.9234 - val_loss: 0.5174 - val_acc: 0.8769\n",
      "Epoch 103/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2545 - acc: 0.9228 - val_loss: 0.5059 - val_acc: 0.8812\n",
      "Epoch 104/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2518 - acc: 0.9245 - val_loss: 0.5095 - val_acc: 0.8817\n",
      "Epoch 105/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2559 - acc: 0.9210 - val_loss: 0.5312 - val_acc: 0.8748\n",
      "Epoch 106/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2502 - acc: 0.9245 - val_loss: 0.5276 - val_acc: 0.8770\n",
      "Epoch 107/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2508 - acc: 0.9243 - val_loss: 0.5136 - val_acc: 0.8813\n",
      "Epoch 108/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2462 - acc: 0.9253 - val_loss: 0.5066 - val_acc: 0.8813\n",
      "Epoch 109/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2499 - acc: 0.9243 - val_loss: 0.5145 - val_acc: 0.8793\n",
      "Epoch 110/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2456 - acc: 0.9255 - val_loss: 0.5157 - val_acc: 0.8772\n",
      "Epoch 111/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2474 - acc: 0.9238 - val_loss: 0.5103 - val_acc: 0.8809\n",
      "Epoch 112/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2457 - acc: 0.9266 - val_loss: 0.5105 - val_acc: 0.8821\n",
      "Epoch 113/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2411 - acc: 0.9276 - val_loss: 0.5106 - val_acc: 0.8817\n",
      "Epoch 114/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2427 - acc: 0.9276 - val_loss: 0.5119 - val_acc: 0.8811\n",
      "Epoch 115/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2433 - acc: 0.9270 - val_loss: 0.5096 - val_acc: 0.8803\n",
      "Epoch 116/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2417 - acc: 0.9277 - val_loss: 0.5151 - val_acc: 0.8792\n",
      "Epoch 117/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2378 - acc: 0.9274 - val_loss: 0.5153 - val_acc: 0.8809\n",
      "Epoch 118/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.2421 - acc: 0.9272 - val_loss: 0.5030 - val_acc: 0.8825\n",
      "Epoch 119/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2383 - acc: 0.9288 - val_loss: 0.5172 - val_acc: 0.8803\n",
      "Epoch 120/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.2389 - acc: 0.9276 - val_loss: 0.5213 - val_acc: 0.8769\n",
      "Epoch 121/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2391 - acc: 0.9270 - val_loss: 0.5248 - val_acc: 0.8765\n",
      "Epoch 122/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2377 - acc: 0.9280 - val_loss: 0.5249 - val_acc: 0.8815\n",
      "Epoch 123/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.2393 - acc: 0.9280 - val_loss: 0.5235 - val_acc: 0.8788\n",
      "Epoch 124/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2382 - acc: 0.9276 - val_loss: 0.5376 - val_acc: 0.8751\n",
      "Epoch 125/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2372 - acc: 0.9275 - val_loss: 0.5236 - val_acc: 0.8786\n",
      "Epoch 126/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2346 - acc: 0.9289 - val_loss: 0.5447 - val_acc: 0.8743\n",
      "Epoch 127/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2354 - acc: 0.9298 - val_loss: 0.5359 - val_acc: 0.8764\n",
      "Epoch 128/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2342 - acc: 0.9290 - val_loss: 0.5331 - val_acc: 0.8775\n",
      "Epoch 129/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2337 - acc: 0.9304 - val_loss: 0.5198 - val_acc: 0.8806\n",
      "Epoch 130/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2302 - acc: 0.9309 - val_loss: 0.5373 - val_acc: 0.8783\n",
      "Epoch 131/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2334 - acc: 0.9281 - val_loss: 0.5265 - val_acc: 0.8798\n",
      "Epoch 132/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2319 - acc: 0.9289 - val_loss: 0.5221 - val_acc: 0.8803\n",
      "Epoch 133/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2289 - acc: 0.9303 - val_loss: 0.5234 - val_acc: 0.8797\n",
      "Epoch 134/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2254 - acc: 0.9322 - val_loss: 0.5184 - val_acc: 0.8814\n",
      "Epoch 135/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2296 - acc: 0.9315 - val_loss: 0.5170 - val_acc: 0.8824\n",
      "Epoch 136/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2281 - acc: 0.9316 - val_loss: 0.5133 - val_acc: 0.8828\n",
      "Epoch 137/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2255 - acc: 0.9312 - val_loss: 0.5458 - val_acc: 0.8780\n",
      "Epoch 138/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.2261 - acc: 0.9312 - val_loss: 0.5225 - val_acc: 0.8819\n",
      "Epoch 139/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2258 - acc: 0.9312 - val_loss: 0.5271 - val_acc: 0.8818\n",
      "Epoch 140/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2276 - acc: 0.9313 - val_loss: 0.5252 - val_acc: 0.8809\n",
      "Epoch 141/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2255 - acc: 0.9315 - val_loss: 0.5354 - val_acc: 0.8803\n",
      "Epoch 142/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2227 - acc: 0.9336 - val_loss: 0.5321 - val_acc: 0.8806\n",
      "Epoch 143/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2246 - acc: 0.9305 - val_loss: 0.5314 - val_acc: 0.8810\n",
      "Epoch 144/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2236 - acc: 0.9324 - val_loss: 0.5347 - val_acc: 0.8803\n",
      "Epoch 145/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2215 - acc: 0.9329 - val_loss: 0.5326 - val_acc: 0.8801\n",
      "Epoch 146/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2251 - acc: 0.9316 - val_loss: 0.5368 - val_acc: 0.8777\n",
      "Epoch 147/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2190 - acc: 0.9332 - val_loss: 0.5282 - val_acc: 0.8817\n",
      "Epoch 148/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2191 - acc: 0.9341 - val_loss: 0.5700 - val_acc: 0.8723\n",
      "Epoch 149/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2179 - acc: 0.9340 - val_loss: 0.5722 - val_acc: 0.8689\n",
      "Epoch 150/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2201 - acc: 0.9334 - val_loss: 0.5454 - val_acc: 0.8785\n",
      "Epoch 151/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2169 - acc: 0.9340 - val_loss: 0.5574 - val_acc: 0.8768\n",
      "Epoch 152/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2196 - acc: 0.9327 - val_loss: 0.5444 - val_acc: 0.8776\n",
      "Epoch 153/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2199 - acc: 0.9326 - val_loss: 0.5404 - val_acc: 0.8802\n",
      "Epoch 154/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2149 - acc: 0.9350 - val_loss: 0.5361 - val_acc: 0.8821\n",
      "Epoch 155/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2144 - acc: 0.9360 - val_loss: 0.5331 - val_acc: 0.8807\n",
      "Epoch 156/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2187 - acc: 0.9331 - val_loss: 0.5418 - val_acc: 0.8798\n",
      "Epoch 157/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2185 - acc: 0.9320 - val_loss: 0.5444 - val_acc: 0.8788\n",
      "Epoch 158/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2145 - acc: 0.9351 - val_loss: 0.5420 - val_acc: 0.8811\n",
      "Epoch 159/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2142 - acc: 0.9342 - val_loss: 0.5335 - val_acc: 0.8807\n",
      "Epoch 160/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2152 - acc: 0.9342 - val_loss: 0.5502 - val_acc: 0.8750\n",
      "Epoch 161/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2146 - acc: 0.9344 - val_loss: 0.5594 - val_acc: 0.8762\n",
      "Epoch 162/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2121 - acc: 0.9342 - val_loss: 0.5630 - val_acc: 0.8741\n",
      "Epoch 163/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2133 - acc: 0.9344 - val_loss: 0.5459 - val_acc: 0.8808\n",
      "Epoch 164/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.2121 - acc: 0.9340 - val_loss: 0.5776 - val_acc: 0.8720\n",
      "Epoch 165/1000\n",
      "34108/34108 [==============================] - 1s 20us/step - loss: 0.2100 - acc: 0.9350 - val_loss: 0.5535 - val_acc: 0.8763\n",
      "Epoch 166/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.2106 - acc: 0.9357 - val_loss: 0.5389 - val_acc: 0.8810\n",
      "Epoch 167/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2113 - acc: 0.9351 - val_loss: 0.5362 - val_acc: 0.8828\n",
      "Epoch 168/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2088 - acc: 0.9364 - val_loss: 0.5567 - val_acc: 0.8772\n",
      "Epoch 169/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.2112 - acc: 0.9367 - val_loss: 0.5348 - val_acc: 0.8805\n",
      "Epoch 170/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2095 - acc: 0.9362 - val_loss: 0.5512 - val_acc: 0.8778\n",
      "Epoch 171/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2109 - acc: 0.9350 - val_loss: 0.5412 - val_acc: 0.8812\n",
      "Epoch 172/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2097 - acc: 0.9362 - val_loss: 0.5415 - val_acc: 0.8826\n",
      "Epoch 173/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2073 - acc: 0.9361 - val_loss: 0.5407 - val_acc: 0.8818\n",
      "Epoch 174/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.2052 - acc: 0.9376 - val_loss: 0.5503 - val_acc: 0.8789\n",
      "Epoch 175/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.2048 - acc: 0.9377 - val_loss: 0.5487 - val_acc: 0.8789\n",
      "Epoch 176/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.2042 - acc: 0.9378 - val_loss: 0.5546 - val_acc: 0.8776\n",
      "Epoch 177/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2052 - acc: 0.9378 - val_loss: 0.5548 - val_acc: 0.8792\n",
      "Epoch 178/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.2070 - acc: 0.9373 - val_loss: 0.5455 - val_acc: 0.8826\n",
      "Epoch 179/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.2070 - acc: 0.9365 - val_loss: 0.5604 - val_acc: 0.8763\n",
      "Epoch 180/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.2022 - acc: 0.9392 - val_loss: 0.5437 - val_acc: 0.8803\n",
      "Epoch 181/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.2047 - acc: 0.9374 - val_loss: 0.5542 - val_acc: 0.8807\n",
      "Epoch 182/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2054 - acc: 0.9374 - val_loss: 0.5809 - val_acc: 0.8758\n",
      "Epoch 183/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.2022 - acc: 0.9374 - val_loss: 0.6038 - val_acc: 0.8657\n",
      "Epoch 184/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2012 - acc: 0.9385 - val_loss: 0.5522 - val_acc: 0.8807\n",
      "Epoch 185/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1989 - acc: 0.9402 - val_loss: 0.5693 - val_acc: 0.8771\n",
      "Epoch 186/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2064 - acc: 0.9364 - val_loss: 0.5595 - val_acc: 0.8808\n",
      "Epoch 187/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1960 - acc: 0.9397 - val_loss: 0.5657 - val_acc: 0.8774\n",
      "Epoch 188/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1979 - acc: 0.9390 - val_loss: 0.5510 - val_acc: 0.8818\n",
      "Epoch 189/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1978 - acc: 0.9399 - val_loss: 0.5531 - val_acc: 0.8807\n",
      "Epoch 190/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1999 - acc: 0.9385 - val_loss: 0.5473 - val_acc: 0.8812\n",
      "Epoch 191/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2022 - acc: 0.9383 - val_loss: 0.5554 - val_acc: 0.8798\n",
      "Epoch 192/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1957 - acc: 0.9404 - val_loss: 0.5512 - val_acc: 0.8817\n",
      "Epoch 193/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1965 - acc: 0.9399 - val_loss: 0.5703 - val_acc: 0.8762\n",
      "Epoch 194/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1980 - acc: 0.9384 - val_loss: 0.5749 - val_acc: 0.8754\n",
      "Epoch 195/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1976 - acc: 0.9392 - val_loss: 0.5874 - val_acc: 0.8751\n",
      "Epoch 196/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.2006 - acc: 0.9384 - val_loss: 0.5627 - val_acc: 0.8777\n",
      "Epoch 197/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1961 - acc: 0.9397 - val_loss: 0.5595 - val_acc: 0.8788\n",
      "Epoch 198/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1968 - acc: 0.9404 - val_loss: 0.5956 - val_acc: 0.8718\n",
      "Epoch 199/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1948 - acc: 0.9408 - val_loss: 0.5822 - val_acc: 0.8758\n",
      "Epoch 200/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1956 - acc: 0.9393 - val_loss: 0.5748 - val_acc: 0.8765\n",
      "Epoch 201/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1960 - acc: 0.9393 - val_loss: 0.5682 - val_acc: 0.8805\n",
      "Epoch 202/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1991 - acc: 0.9387 - val_loss: 0.5607 - val_acc: 0.8797\n",
      "Epoch 203/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1903 - acc: 0.9423 - val_loss: 0.5651 - val_acc: 0.8798\n",
      "Epoch 204/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1930 - acc: 0.9420 - val_loss: 0.5724 - val_acc: 0.8803\n",
      "Epoch 205/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1941 - acc: 0.9402 - val_loss: 0.5574 - val_acc: 0.8812\n",
      "Epoch 206/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1941 - acc: 0.9403 - val_loss: 0.5760 - val_acc: 0.8779\n",
      "Epoch 207/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1931 - acc: 0.9409 - val_loss: 0.5884 - val_acc: 0.8731\n",
      "Epoch 208/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1899 - acc: 0.9423 - val_loss: 0.6046 - val_acc: 0.8694\n",
      "Epoch 209/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1965 - acc: 0.9394 - val_loss: 0.5679 - val_acc: 0.8819\n",
      "Epoch 210/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1904 - acc: 0.9425 - val_loss: 0.5892 - val_acc: 0.8738\n",
      "Epoch 211/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1920 - acc: 0.9417 - val_loss: 0.5595 - val_acc: 0.8809\n",
      "Epoch 212/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1868 - acc: 0.9429 - val_loss: 0.5672 - val_acc: 0.8809\n",
      "Epoch 213/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1902 - acc: 0.9415 - val_loss: 0.5679 - val_acc: 0.8795\n",
      "Epoch 214/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1901 - acc: 0.9430 - val_loss: 0.5655 - val_acc: 0.8812\n",
      "Epoch 215/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1914 - acc: 0.9409 - val_loss: 0.5734 - val_acc: 0.8788\n",
      "Epoch 216/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1873 - acc: 0.9426 - val_loss: 0.5775 - val_acc: 0.8801\n",
      "Epoch 217/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1882 - acc: 0.9433 - val_loss: 0.5766 - val_acc: 0.8763\n",
      "Epoch 218/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1881 - acc: 0.9427 - val_loss: 0.5824 - val_acc: 0.8750\n",
      "Epoch 219/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1871 - acc: 0.9421 - val_loss: 0.5583 - val_acc: 0.8835\n",
      "Epoch 220/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1850 - acc: 0.9436 - val_loss: 0.5876 - val_acc: 0.8755\n",
      "Epoch 221/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1877 - acc: 0.9424 - val_loss: 0.5706 - val_acc: 0.8798\n",
      "Epoch 222/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1843 - acc: 0.9438 - val_loss: 0.5737 - val_acc: 0.8793\n",
      "Epoch 223/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1859 - acc: 0.9432 - val_loss: 0.5793 - val_acc: 0.8788\n",
      "Epoch 224/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1862 - acc: 0.9432 - val_loss: 0.5747 - val_acc: 0.8813\n",
      "Epoch 225/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1846 - acc: 0.9443 - val_loss: 0.5852 - val_acc: 0.8777\n",
      "Epoch 226/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1807 - acc: 0.9451 - val_loss: 0.6128 - val_acc: 0.8714\n",
      "Epoch 227/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1852 - acc: 0.9441 - val_loss: 0.5788 - val_acc: 0.8793\n",
      "Epoch 228/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1878 - acc: 0.9419 - val_loss: 0.5757 - val_acc: 0.8792\n",
      "Epoch 229/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1881 - acc: 0.9417 - val_loss: 0.5885 - val_acc: 0.8782\n",
      "Epoch 230/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1843 - acc: 0.9439 - val_loss: 0.5938 - val_acc: 0.8793\n",
      "Epoch 231/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1821 - acc: 0.9439 - val_loss: 0.5834 - val_acc: 0.8788\n",
      "Epoch 232/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1851 - acc: 0.9434 - val_loss: 0.5756 - val_acc: 0.8805\n",
      "Epoch 233/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1836 - acc: 0.9422 - val_loss: 0.5781 - val_acc: 0.8793\n",
      "Epoch 234/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1843 - acc: 0.9436 - val_loss: 0.5919 - val_acc: 0.8777\n",
      "Epoch 235/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1816 - acc: 0.9442 - val_loss: 0.5889 - val_acc: 0.8782\n",
      "Epoch 236/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1790 - acc: 0.9449 - val_loss: 0.5887 - val_acc: 0.8798\n",
      "Epoch 237/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1840 - acc: 0.9440 - val_loss: 0.5744 - val_acc: 0.8812\n",
      "Epoch 238/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1787 - acc: 0.9447 - val_loss: 0.6086 - val_acc: 0.8759\n",
      "Epoch 239/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1806 - acc: 0.9442 - val_loss: 0.5810 - val_acc: 0.8816\n",
      "Epoch 240/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1798 - acc: 0.9450 - val_loss: 0.6102 - val_acc: 0.8727\n",
      "Epoch 241/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1792 - acc: 0.9450 - val_loss: 0.6029 - val_acc: 0.8772\n",
      "Epoch 242/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1785 - acc: 0.9453 - val_loss: 0.5847 - val_acc: 0.8807\n",
      "Epoch 243/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1778 - acc: 0.9461 - val_loss: 0.6062 - val_acc: 0.8752\n",
      "Epoch 244/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1811 - acc: 0.9446 - val_loss: 0.6081 - val_acc: 0.8775\n",
      "Epoch 245/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1777 - acc: 0.9456 - val_loss: 0.6058 - val_acc: 0.8744\n",
      "Epoch 246/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1774 - acc: 0.9460 - val_loss: 0.5946 - val_acc: 0.8784\n",
      "Epoch 247/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1764 - acc: 0.9458 - val_loss: 0.5960 - val_acc: 0.8793\n",
      "Epoch 248/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1771 - acc: 0.9449 - val_loss: 0.5982 - val_acc: 0.8765\n",
      "Epoch 249/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1770 - acc: 0.9450 - val_loss: 0.6156 - val_acc: 0.8798\n",
      "Epoch 250/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1744 - acc: 0.9475 - val_loss: 0.6023 - val_acc: 0.8777\n",
      "Epoch 251/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1759 - acc: 0.9465 - val_loss: 0.6042 - val_acc: 0.8777\n",
      "Epoch 252/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1790 - acc: 0.9447 - val_loss: 0.5906 - val_acc: 0.8796\n",
      "Epoch 253/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1767 - acc: 0.9454 - val_loss: 0.6061 - val_acc: 0.8775\n",
      "Epoch 254/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1740 - acc: 0.9473 - val_loss: 0.6117 - val_acc: 0.8762\n",
      "Epoch 255/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1701 - acc: 0.9482 - val_loss: 0.6170 - val_acc: 0.8743\n",
      "Epoch 256/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1749 - acc: 0.9458 - val_loss: 0.5896 - val_acc: 0.8798\n",
      "Epoch 257/1000\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1766 - acc: 0.9455 - val_loss: 0.6039 - val_acc: 0.8762\n",
      "Epoch 258/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1778 - acc: 0.9449 - val_loss: 0.6029 - val_acc: 0.8785\n",
      "Epoch 259/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1772 - acc: 0.9445 - val_loss: 0.5991 - val_acc: 0.8794\n",
      "Epoch 260/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1722 - acc: 0.9479 - val_loss: 0.6297 - val_acc: 0.8713\n",
      "Epoch 261/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1757 - acc: 0.9463 - val_loss: 0.6102 - val_acc: 0.8770\n",
      "Epoch 262/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1743 - acc: 0.9463 - val_loss: 0.5970 - val_acc: 0.8794\n",
      "Epoch 263/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1735 - acc: 0.9470 - val_loss: 0.6071 - val_acc: 0.8806\n",
      "Epoch 264/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1749 - acc: 0.9460 - val_loss: 0.6312 - val_acc: 0.8723\n",
      "Epoch 265/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1739 - acc: 0.9470 - val_loss: 0.6217 - val_acc: 0.8741\n",
      "Epoch 266/1000\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1737 - acc: 0.9462 - val_loss: 0.5997 - val_acc: 0.8807\n",
      "Epoch 267/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1717 - acc: 0.9481 - val_loss: 0.6171 - val_acc: 0.8737\n",
      "Epoch 268/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1734 - acc: 0.9463 - val_loss: 0.6157 - val_acc: 0.8766\n",
      "Epoch 269/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1723 - acc: 0.9476 - val_loss: 0.6014 - val_acc: 0.8786\n",
      "Epoch 270/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1670 - acc: 0.9496 - val_loss: 0.6013 - val_acc: 0.8802\n",
      "Epoch 271/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1715 - acc: 0.9466 - val_loss: 0.6045 - val_acc: 0.8803\n",
      "Epoch 272/1000\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.1698 - acc: 0.9486 - val_loss: 0.6138 - val_acc: 0.8780\n",
      "Epoch 273/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1714 - acc: 0.9483 - val_loss: 0.6048 - val_acc: 0.8802\n",
      "Epoch 274/1000\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1690 - acc: 0.9480 - val_loss: 0.6076 - val_acc: 0.8792\n",
      "Epoch 275/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1697 - acc: 0.9479 - val_loss: 0.6029 - val_acc: 0.8812\n",
      "Epoch 276/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1699 - acc: 0.9479 - val_loss: 0.6161 - val_acc: 0.8773\n",
      "Epoch 277/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1665 - acc: 0.9500 - val_loss: 0.6141 - val_acc: 0.8790\n",
      "Epoch 278/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1679 - acc: 0.9485 - val_loss: 0.6343 - val_acc: 0.8754\n",
      "Epoch 279/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1714 - acc: 0.9476 - val_loss: 0.6341 - val_acc: 0.8725\n",
      "Epoch 280/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1726 - acc: 0.9472 - val_loss: 0.6142 - val_acc: 0.8777\n",
      "Epoch 281/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1672 - acc: 0.9490 - val_loss: 0.6228 - val_acc: 0.8774\n",
      "Epoch 282/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1707 - acc: 0.9463 - val_loss: 0.6178 - val_acc: 0.8778\n",
      "Epoch 283/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1669 - acc: 0.9494 - val_loss: 0.6067 - val_acc: 0.8806\n",
      "Epoch 284/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1680 - acc: 0.9483 - val_loss: 0.6278 - val_acc: 0.8761\n",
      "Epoch 285/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1669 - acc: 0.9490 - val_loss: 0.6144 - val_acc: 0.8790\n",
      "Epoch 286/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1642 - acc: 0.9502 - val_loss: 0.6261 - val_acc: 0.8774\n",
      "Epoch 287/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1720 - acc: 0.9463 - val_loss: 0.6083 - val_acc: 0.8816\n",
      "Epoch 288/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1602 - acc: 0.9504 - val_loss: 0.6241 - val_acc: 0.8772\n",
      "Epoch 289/1000\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1670 - acc: 0.9471 - val_loss: 0.6156 - val_acc: 0.8795\n",
      "Epoch 290/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1651 - acc: 0.9491 - val_loss: 0.6276 - val_acc: 0.8760\n",
      "Epoch 291/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1667 - acc: 0.9476 - val_loss: 0.6235 - val_acc: 0.8787\n",
      "Epoch 292/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1634 - acc: 0.9496 - val_loss: 0.6206 - val_acc: 0.8793\n",
      "Epoch 293/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1649 - acc: 0.9496 - val_loss: 0.6235 - val_acc: 0.8779\n",
      "Epoch 294/1000\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1690 - acc: 0.9470 - val_loss: 0.6169 - val_acc: 0.8783\n",
      "Epoch 295/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1649 - acc: 0.9499 - val_loss: 0.6336 - val_acc: 0.8778\n",
      "Epoch 296/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1663 - acc: 0.9485 - val_loss: 0.6185 - val_acc: 0.8829\n",
      "Epoch 297/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1619 - acc: 0.9498 - val_loss: 0.6173 - val_acc: 0.8807\n",
      "Epoch 298/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1602 - acc: 0.9515 - val_loss: 0.6315 - val_acc: 0.8794\n",
      "Epoch 299/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1663 - acc: 0.9487 - val_loss: 0.6273 - val_acc: 0.8771\n",
      "Epoch 300/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1672 - acc: 0.9474 - val_loss: 0.6528 - val_acc: 0.8729\n",
      "Epoch 301/1000\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1626 - acc: 0.9501 - val_loss: 0.6315 - val_acc: 0.8792\n",
      "Epoch 302/1000\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1659 - acc: 0.9490 - val_loss: 0.6618 - val_acc: 0.8718\n",
      "Epoch 303/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1598 - acc: 0.9503 - val_loss: 0.6200 - val_acc: 0.8808\n",
      "Epoch 304/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1650 - acc: 0.9487 - val_loss: 0.6205 - val_acc: 0.8765\n",
      "Epoch 305/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1609 - acc: 0.9500 - val_loss: 0.6391 - val_acc: 0.8764\n",
      "Epoch 306/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1626 - acc: 0.9496 - val_loss: 0.6297 - val_acc: 0.8778\n",
      "Epoch 307/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1593 - acc: 0.9508 - val_loss: 0.6258 - val_acc: 0.8785\n",
      "Epoch 308/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1656 - acc: 0.9479 - val_loss: 0.6102 - val_acc: 0.8825\n",
      "Epoch 309/1000\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1628 - acc: 0.9499 - val_loss: 0.6422 - val_acc: 0.8755\n",
      "Epoch 310/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1613 - acc: 0.9507 - val_loss: 0.6256 - val_acc: 0.8800\n",
      "Epoch 311/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1590 - acc: 0.9507 - val_loss: 0.6592 - val_acc: 0.8727\n",
      "Epoch 312/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1597 - acc: 0.9504 - val_loss: 0.6405 - val_acc: 0.8767\n",
      "Epoch 313/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1591 - acc: 0.9519 - val_loss: 0.6302 - val_acc: 0.8793\n",
      "Epoch 314/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1619 - acc: 0.9495 - val_loss: 0.6388 - val_acc: 0.8753\n",
      "Epoch 315/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1575 - acc: 0.9523 - val_loss: 0.6212 - val_acc: 0.8817\n",
      "Epoch 316/1000\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1612 - acc: 0.9507 - val_loss: 0.6531 - val_acc: 0.8772\n",
      "Epoch 317/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1591 - acc: 0.9499 - val_loss: 0.6557 - val_acc: 0.8738\n",
      "Epoch 318/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1580 - acc: 0.9512 - val_loss: 0.6342 - val_acc: 0.8783\n",
      "Epoch 319/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1577 - acc: 0.9513 - val_loss: 0.6436 - val_acc: 0.8768\n",
      "Epoch 320/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1560 - acc: 0.9514 - val_loss: 0.6281 - val_acc: 0.8789\n",
      "Epoch 321/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1566 - acc: 0.9514 - val_loss: 0.6540 - val_acc: 0.8777\n",
      "Epoch 322/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1592 - acc: 0.9500 - val_loss: 0.6300 - val_acc: 0.8798\n",
      "Epoch 323/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1577 - acc: 0.9508 - val_loss: 0.6361 - val_acc: 0.8789\n",
      "Epoch 324/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1565 - acc: 0.9515 - val_loss: 0.6603 - val_acc: 0.8722\n",
      "Epoch 325/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1571 - acc: 0.9508 - val_loss: 0.6519 - val_acc: 0.8746\n",
      "Epoch 326/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1572 - acc: 0.9508 - val_loss: 0.6233 - val_acc: 0.8815\n",
      "Epoch 327/1000\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1509 - acc: 0.9541 - val_loss: 0.6368 - val_acc: 0.8784\n",
      "Epoch 328/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1636 - acc: 0.9487 - val_loss: 0.6397 - val_acc: 0.8802\n",
      "Epoch 329/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1580 - acc: 0.9510 - val_loss: 0.6415 - val_acc: 0.8779\n",
      "Epoch 330/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1584 - acc: 0.9509 - val_loss: 0.6402 - val_acc: 0.8788\n",
      "Epoch 331/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1588 - acc: 0.9514 - val_loss: 0.6261 - val_acc: 0.8805\n",
      "Epoch 332/1000\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1565 - acc: 0.9513 - val_loss: 0.6622 - val_acc: 0.8734\n",
      "Epoch 333/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1532 - acc: 0.9523 - val_loss: 0.6425 - val_acc: 0.8803\n",
      "Epoch 334/1000\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1648 - acc: 0.9481 - val_loss: 0.6374 - val_acc: 0.8794\n",
      "Epoch 335/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1574 - acc: 0.9507 - val_loss: 0.6446 - val_acc: 0.8788\n",
      "Epoch 336/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1506 - acc: 0.9538 - val_loss: 0.6472 - val_acc: 0.8788\n",
      "Epoch 337/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1589 - acc: 0.9511 - val_loss: 0.6405 - val_acc: 0.8783\n",
      "Epoch 338/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1549 - acc: 0.9520 - val_loss: 0.6536 - val_acc: 0.8783\n",
      "Epoch 339/1000\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1594 - acc: 0.9498 - val_loss: 0.6578 - val_acc: 0.8752\n",
      "Epoch 340/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1532 - acc: 0.9522 - val_loss: 0.6501 - val_acc: 0.8794\n",
      "Epoch 341/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1533 - acc: 0.9525 - val_loss: 0.6386 - val_acc: 0.8811\n",
      "Epoch 342/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1564 - acc: 0.9514 - val_loss: 0.6361 - val_acc: 0.8814\n",
      "Epoch 343/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1528 - acc: 0.9536 - val_loss: 0.6558 - val_acc: 0.8783\n",
      "Epoch 344/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1524 - acc: 0.9522 - val_loss: 0.6340 - val_acc: 0.8826\n",
      "Epoch 345/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1549 - acc: 0.9526 - val_loss: 0.6395 - val_acc: 0.8802\n",
      "Epoch 346/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1538 - acc: 0.9522 - val_loss: 0.6431 - val_acc: 0.8800\n",
      "Epoch 347/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1515 - acc: 0.9537 - val_loss: 0.6519 - val_acc: 0.8779\n",
      "Epoch 348/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1532 - acc: 0.9532 - val_loss: 0.6486 - val_acc: 0.8760\n",
      "Epoch 349/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1526 - acc: 0.9530 - val_loss: 0.6531 - val_acc: 0.8787\n",
      "Epoch 350/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1503 - acc: 0.9540 - val_loss: 0.6485 - val_acc: 0.8787\n",
      "Epoch 351/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1528 - acc: 0.9539 - val_loss: 0.6648 - val_acc: 0.8744\n",
      "Epoch 352/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1512 - acc: 0.9534 - val_loss: 0.6685 - val_acc: 0.8743\n",
      "Epoch 353/1000\n",
      "34108/34108 [==============================] - ETA: 0s - loss: 0.1546 - acc: 0.951 - 0s 12us/step - loss: 0.1547 - acc: 0.9507 - val_loss: 0.6685 - val_acc: 0.8737\n",
      "Epoch 354/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1516 - acc: 0.9526 - val_loss: 0.6651 - val_acc: 0.8778\n",
      "Epoch 355/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1558 - acc: 0.9515 - val_loss: 0.6480 - val_acc: 0.8773\n",
      "Epoch 356/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1506 - acc: 0.9529 - val_loss: 0.6820 - val_acc: 0.8754\n",
      "Epoch 357/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1539 - acc: 0.9515 - val_loss: 0.6416 - val_acc: 0.8800\n",
      "Epoch 358/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1462 - acc: 0.9561 - val_loss: 0.6580 - val_acc: 0.8783\n",
      "Epoch 359/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1515 - acc: 0.9529 - val_loss: 0.6702 - val_acc: 0.8758\n",
      "Epoch 360/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1501 - acc: 0.9541 - val_loss: 0.6489 - val_acc: 0.8775\n",
      "Epoch 361/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1522 - acc: 0.9519 - val_loss: 0.6543 - val_acc: 0.8787\n",
      "Epoch 362/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1477 - acc: 0.9550 - val_loss: 0.6747 - val_acc: 0.8724\n",
      "Epoch 363/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1509 - acc: 0.9538 - val_loss: 0.6427 - val_acc: 0.8803\n",
      "Epoch 364/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1534 - acc: 0.9505 - val_loss: 0.7071 - val_acc: 0.8689\n",
      "Epoch 365/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1472 - acc: 0.9538 - val_loss: 0.6634 - val_acc: 0.8762\n",
      "Epoch 366/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1542 - acc: 0.9515 - val_loss: 0.6586 - val_acc: 0.8758\n",
      "Epoch 367/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1446 - acc: 0.9552 - val_loss: 0.6465 - val_acc: 0.8797\n",
      "Epoch 368/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1493 - acc: 0.9538 - val_loss: 0.6630 - val_acc: 0.8769\n",
      "Epoch 369/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1456 - acc: 0.9551 - val_loss: 0.6567 - val_acc: 0.8794\n",
      "Epoch 370/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1460 - acc: 0.9551 - val_loss: 0.6525 - val_acc: 0.8806\n",
      "Epoch 371/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1514 - acc: 0.9539 - val_loss: 0.6585 - val_acc: 0.8780\n",
      "Epoch 372/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1486 - acc: 0.9536 - val_loss: 0.6646 - val_acc: 0.8775\n",
      "Epoch 373/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1506 - acc: 0.9533 - val_loss: 0.6544 - val_acc: 0.8792\n",
      "Epoch 374/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1465 - acc: 0.9548 - val_loss: 0.6497 - val_acc: 0.8791\n",
      "Epoch 375/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1485 - acc: 0.9541 - val_loss: 0.6806 - val_acc: 0.8719\n",
      "Epoch 376/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1478 - acc: 0.9532 - val_loss: 0.6895 - val_acc: 0.8728\n",
      "Epoch 377/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1438 - acc: 0.9551 - val_loss: 0.6449 - val_acc: 0.8830\n",
      "Epoch 378/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1458 - acc: 0.9553 - val_loss: 0.6693 - val_acc: 0.8743\n",
      "Epoch 379/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1477 - acc: 0.9543 - val_loss: 0.6481 - val_acc: 0.8809\n",
      "Epoch 380/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1470 - acc: 0.9528 - val_loss: 0.6557 - val_acc: 0.8793\n",
      "Epoch 381/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1489 - acc: 0.9541 - val_loss: 0.6646 - val_acc: 0.8779\n",
      "Epoch 382/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1470 - acc: 0.9548 - val_loss: 0.6661 - val_acc: 0.8751\n",
      "Epoch 383/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1419 - acc: 0.9562 - val_loss: 0.6714 - val_acc: 0.8764\n",
      "Epoch 384/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1471 - acc: 0.9552 - val_loss: 0.6618 - val_acc: 0.8784\n",
      "Epoch 385/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1447 - acc: 0.9551 - val_loss: 0.7078 - val_acc: 0.8709\n",
      "Epoch 386/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1491 - acc: 0.9534 - val_loss: 0.6668 - val_acc: 0.8785\n",
      "Epoch 387/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1430 - acc: 0.9551 - val_loss: 0.6667 - val_acc: 0.8784\n",
      "Epoch 388/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1410 - acc: 0.9565 - val_loss: 0.6707 - val_acc: 0.8765\n",
      "Epoch 389/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1456 - acc: 0.9555 - val_loss: 0.6774 - val_acc: 0.8749\n",
      "Epoch 390/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1454 - acc: 0.9558 - val_loss: 0.6629 - val_acc: 0.8817\n",
      "Epoch 391/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1437 - acc: 0.9549 - val_loss: 0.6655 - val_acc: 0.8779\n",
      "Epoch 392/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1451 - acc: 0.9561 - val_loss: 0.6596 - val_acc: 0.8813\n",
      "Epoch 393/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1492 - acc: 0.9537 - val_loss: 0.6661 - val_acc: 0.8805\n",
      "Epoch 394/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1448 - acc: 0.9541 - val_loss: 0.6723 - val_acc: 0.8776\n",
      "Epoch 395/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1465 - acc: 0.9539 - val_loss: 0.6777 - val_acc: 0.8770\n",
      "Epoch 396/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1451 - acc: 0.9546 - val_loss: 0.6697 - val_acc: 0.8779\n",
      "Epoch 397/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1453 - acc: 0.9551 - val_loss: 0.6605 - val_acc: 0.8807\n",
      "Epoch 398/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1437 - acc: 0.9549 - val_loss: 0.6711 - val_acc: 0.8767\n",
      "Epoch 399/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1415 - acc: 0.9567 - val_loss: 0.6631 - val_acc: 0.8797\n",
      "Epoch 400/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1425 - acc: 0.9561 - val_loss: 0.6932 - val_acc: 0.8747\n",
      "Epoch 401/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1447 - acc: 0.9551 - val_loss: 0.6997 - val_acc: 0.8733\n",
      "Epoch 402/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1430 - acc: 0.9558 - val_loss: 0.6642 - val_acc: 0.8788\n",
      "Epoch 403/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1443 - acc: 0.9549 - val_loss: 0.6804 - val_acc: 0.8747\n",
      "Epoch 404/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1371 - acc: 0.9584 - val_loss: 0.6768 - val_acc: 0.8794\n",
      "Epoch 405/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1410 - acc: 0.9571 - val_loss: 0.6929 - val_acc: 0.8714\n",
      "Epoch 406/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1385 - acc: 0.9581 - val_loss: 0.6706 - val_acc: 0.8783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1410 - acc: 0.9567 - val_loss: 0.6913 - val_acc: 0.8744\n",
      "Epoch 408/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1384 - acc: 0.9575 - val_loss: 0.6791 - val_acc: 0.8773\n",
      "Epoch 409/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1481 - acc: 0.9541 - val_loss: 0.6921 - val_acc: 0.8741\n",
      "Epoch 410/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1407 - acc: 0.9565 - val_loss: 0.6740 - val_acc: 0.8806\n",
      "Epoch 411/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1408 - acc: 0.9564 - val_loss: 0.6770 - val_acc: 0.8807\n",
      "Epoch 412/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1394 - acc: 0.9573 - val_loss: 0.6805 - val_acc: 0.8785\n",
      "Epoch 413/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1450 - acc: 0.9550 - val_loss: 0.6844 - val_acc: 0.8780\n",
      "Epoch 414/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1423 - acc: 0.9551 - val_loss: 0.6854 - val_acc: 0.8780\n",
      "Epoch 415/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1356 - acc: 0.9585 - val_loss: 0.6696 - val_acc: 0.8808\n",
      "Epoch 416/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1435 - acc: 0.9551 - val_loss: 0.6781 - val_acc: 0.8773\n",
      "Epoch 417/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1446 - acc: 0.9544 - val_loss: 0.6885 - val_acc: 0.8771\n",
      "Epoch 418/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1375 - acc: 0.9574 - val_loss: 0.6946 - val_acc: 0.8758\n",
      "Epoch 419/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1401 - acc: 0.9566 - val_loss: 0.6936 - val_acc: 0.8749\n",
      "Epoch 420/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1398 - acc: 0.9569 - val_loss: 0.6738 - val_acc: 0.8812\n",
      "Epoch 421/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1420 - acc: 0.9554 - val_loss: 0.6854 - val_acc: 0.8756\n",
      "Epoch 422/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1459 - acc: 0.9543 - val_loss: 0.6860 - val_acc: 0.8778\n",
      "Epoch 423/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1403 - acc: 0.9565 - val_loss: 0.6939 - val_acc: 0.8774\n",
      "Epoch 424/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1385 - acc: 0.9571 - val_loss: 0.6726 - val_acc: 0.8806\n",
      "Epoch 425/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1380 - acc: 0.9571 - val_loss: 0.7032 - val_acc: 0.8750\n",
      "Epoch 426/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1409 - acc: 0.9568 - val_loss: 0.6993 - val_acc: 0.8763\n",
      "Epoch 427/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1389 - acc: 0.9567 - val_loss: 0.6820 - val_acc: 0.8788\n",
      "Epoch 428/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1372 - acc: 0.9571 - val_loss: 0.6979 - val_acc: 0.8776\n",
      "Epoch 429/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1409 - acc: 0.9562 - val_loss: 0.6899 - val_acc: 0.8779\n",
      "Epoch 430/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1337 - acc: 0.9594 - val_loss: 0.6863 - val_acc: 0.8782\n",
      "Epoch 431/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1350 - acc: 0.9580 - val_loss: 0.6847 - val_acc: 0.8805\n",
      "Epoch 432/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1412 - acc: 0.9568 - val_loss: 0.6755 - val_acc: 0.8810\n",
      "Epoch 433/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1406 - acc: 0.9558 - val_loss: 0.7253 - val_acc: 0.8734\n",
      "Epoch 434/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1414 - acc: 0.9560 - val_loss: 0.6937 - val_acc: 0.8779\n",
      "Epoch 435/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1414 - acc: 0.9569 - val_loss: 0.6815 - val_acc: 0.8810\n",
      "Epoch 436/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1388 - acc: 0.9571 - val_loss: 0.7344 - val_acc: 0.8676\n",
      "Epoch 437/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1346 - acc: 0.9581 - val_loss: 0.6867 - val_acc: 0.8765\n",
      "Epoch 438/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1372 - acc: 0.9572 - val_loss: 0.7207 - val_acc: 0.8728\n",
      "Epoch 439/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1362 - acc: 0.9581 - val_loss: 0.6847 - val_acc: 0.8811\n",
      "Epoch 440/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1378 - acc: 0.9568 - val_loss: 0.6865 - val_acc: 0.8794\n",
      "Epoch 441/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1351 - acc: 0.9574 - val_loss: 0.7117 - val_acc: 0.8746\n",
      "Epoch 442/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1351 - acc: 0.9587 - val_loss: 0.7050 - val_acc: 0.8747\n",
      "Epoch 443/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1358 - acc: 0.9580 - val_loss: 0.6864 - val_acc: 0.8790\n",
      "Epoch 444/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1341 - acc: 0.9589 - val_loss: 0.6754 - val_acc: 0.8814\n",
      "Epoch 445/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1302 - acc: 0.9604 - val_loss: 0.6915 - val_acc: 0.8799\n",
      "Epoch 446/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1375 - acc: 0.9567 - val_loss: 0.6993 - val_acc: 0.8760\n",
      "Epoch 447/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1327 - acc: 0.9596 - val_loss: 0.6953 - val_acc: 0.8787\n",
      "Epoch 448/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1383 - acc: 0.9568 - val_loss: 0.7131 - val_acc: 0.8748\n",
      "Epoch 449/1000\n",
      "34108/34108 [==============================] - ETA: 0s - loss: 0.1377 - acc: 0.956 - 0s 13us/step - loss: 0.1364 - acc: 0.9570 - val_loss: 0.6924 - val_acc: 0.8788\n",
      "Epoch 450/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1355 - acc: 0.9577 - val_loss: 0.7306 - val_acc: 0.8715\n",
      "Epoch 451/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1332 - acc: 0.9590 - val_loss: 0.6805 - val_acc: 0.8801\n",
      "Epoch 452/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1395 - acc: 0.9567 - val_loss: 0.6978 - val_acc: 0.8787\n",
      "Epoch 453/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1333 - acc: 0.9586 - val_loss: 0.6951 - val_acc: 0.8784\n",
      "Epoch 454/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1323 - acc: 0.9597 - val_loss: 0.7072 - val_acc: 0.8788\n",
      "Epoch 455/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1412 - acc: 0.9560 - val_loss: 0.6942 - val_acc: 0.8779\n",
      "Epoch 456/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1329 - acc: 0.9597 - val_loss: 0.6923 - val_acc: 0.8789\n",
      "Epoch 457/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1338 - acc: 0.9585 - val_loss: 0.6882 - val_acc: 0.8812\n",
      "Epoch 458/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1366 - acc: 0.9578 - val_loss: 0.7308 - val_acc: 0.8743\n",
      "Epoch 459/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1330 - acc: 0.9579 - val_loss: 0.7028 - val_acc: 0.8799\n",
      "Epoch 460/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1316 - acc: 0.9600 - val_loss: 0.6991 - val_acc: 0.8824\n",
      "Epoch 461/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1334 - acc: 0.9589 - val_loss: 0.7031 - val_acc: 0.8780\n",
      "Epoch 462/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1355 - acc: 0.9570 - val_loss: 0.7299 - val_acc: 0.8703\n",
      "Epoch 463/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1383 - acc: 0.9566 - val_loss: 0.7005 - val_acc: 0.8784\n",
      "Epoch 464/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1337 - acc: 0.9592 - val_loss: 0.7081 - val_acc: 0.8769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1313 - acc: 0.9595 - val_loss: 0.7222 - val_acc: 0.8742\n",
      "Epoch 466/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1340 - acc: 0.9588 - val_loss: 0.7174 - val_acc: 0.8730\n",
      "Epoch 467/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1312 - acc: 0.9592 - val_loss: 0.7008 - val_acc: 0.8777\n",
      "Epoch 468/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1360 - acc: 0.9575 - val_loss: 0.7084 - val_acc: 0.8765\n",
      "Epoch 469/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1321 - acc: 0.9587 - val_loss: 0.7052 - val_acc: 0.8797\n",
      "Epoch 470/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1305 - acc: 0.9598 - val_loss: 0.7106 - val_acc: 0.8788\n",
      "Epoch 471/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1349 - acc: 0.9569 - val_loss: 0.7118 - val_acc: 0.8779\n",
      "Epoch 472/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1367 - acc: 0.9565 - val_loss: 0.7004 - val_acc: 0.8799\n",
      "Epoch 473/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1280 - acc: 0.9617 - val_loss: 0.7032 - val_acc: 0.8790\n",
      "Epoch 474/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1282 - acc: 0.9613 - val_loss: 0.6984 - val_acc: 0.8793\n",
      "Epoch 475/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1353 - acc: 0.9579 - val_loss: 0.6991 - val_acc: 0.8788\n",
      "Epoch 476/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1270 - acc: 0.9610 - val_loss: 0.7050 - val_acc: 0.8772\n",
      "Epoch 477/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1312 - acc: 0.9600 - val_loss: 0.7097 - val_acc: 0.8749\n",
      "Epoch 478/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1296 - acc: 0.9595 - val_loss: 0.7299 - val_acc: 0.8755\n",
      "Epoch 479/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1347 - acc: 0.9580 - val_loss: 0.7060 - val_acc: 0.8784\n",
      "Epoch 480/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1311 - acc: 0.9600 - val_loss: 0.7084 - val_acc: 0.8781\n",
      "Epoch 481/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1284 - acc: 0.9611 - val_loss: 0.7369 - val_acc: 0.8721\n",
      "Epoch 482/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1276 - acc: 0.9606 - val_loss: 0.7131 - val_acc: 0.8798\n",
      "Epoch 483/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1339 - acc: 0.9582 - val_loss: 0.7194 - val_acc: 0.8753\n",
      "Epoch 484/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1337 - acc: 0.9578 - val_loss: 0.7115 - val_acc: 0.8791\n",
      "Epoch 485/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1307 - acc: 0.9602 - val_loss: 0.7336 - val_acc: 0.8730\n",
      "Epoch 486/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1331 - acc: 0.9585 - val_loss: 0.7242 - val_acc: 0.8767\n",
      "Epoch 487/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1299 - acc: 0.9602 - val_loss: 0.7490 - val_acc: 0.8708\n",
      "Epoch 488/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1306 - acc: 0.9603 - val_loss: 0.7097 - val_acc: 0.8766\n",
      "Epoch 489/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1340 - acc: 0.9577 - val_loss: 0.7304 - val_acc: 0.8736\n",
      "Epoch 490/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1255 - acc: 0.9611 - val_loss: 0.7130 - val_acc: 0.8803\n",
      "Epoch 491/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1344 - acc: 0.9576 - val_loss: 0.7242 - val_acc: 0.8769\n",
      "Epoch 492/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1287 - acc: 0.9602 - val_loss: 0.7136 - val_acc: 0.8776\n",
      "Epoch 493/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1262 - acc: 0.9600 - val_loss: 0.7406 - val_acc: 0.8718\n",
      "Epoch 494/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1258 - acc: 0.9614 - val_loss: 0.7195 - val_acc: 0.8774\n",
      "Epoch 495/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1309 - acc: 0.9585 - val_loss: 0.7139 - val_acc: 0.8803\n",
      "Epoch 496/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1274 - acc: 0.9610 - val_loss: 0.7165 - val_acc: 0.8785\n",
      "Epoch 497/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1263 - acc: 0.9618 - val_loss: 0.7146 - val_acc: 0.8771\n",
      "Epoch 498/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1279 - acc: 0.9607 - val_loss: 0.7198 - val_acc: 0.8786\n",
      "Epoch 499/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1271 - acc: 0.9606 - val_loss: 0.7177 - val_acc: 0.8770\n",
      "Epoch 500/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1319 - acc: 0.9579 - val_loss: 0.7167 - val_acc: 0.8766\n",
      "Epoch 501/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1264 - acc: 0.9612 - val_loss: 0.7080 - val_acc: 0.8798\n",
      "Epoch 502/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1263 - acc: 0.9610 - val_loss: 0.7180 - val_acc: 0.8774\n",
      "Epoch 503/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1272 - acc: 0.9604 - val_loss: 0.7256 - val_acc: 0.8737\n",
      "Epoch 504/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1302 - acc: 0.9604 - val_loss: 0.7305 - val_acc: 0.8757\n",
      "Epoch 505/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1278 - acc: 0.9602 - val_loss: 0.7361 - val_acc: 0.8765\n",
      "Epoch 506/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1308 - acc: 0.9590 - val_loss: 0.7278 - val_acc: 0.8784\n",
      "Epoch 507/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1238 - acc: 0.9619 - val_loss: 0.7351 - val_acc: 0.8765\n",
      "Epoch 508/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1260 - acc: 0.9607 - val_loss: 0.7232 - val_acc: 0.8776\n",
      "Epoch 509/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1279 - acc: 0.9602 - val_loss: 0.7331 - val_acc: 0.8763\n",
      "Epoch 510/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1239 - acc: 0.9619 - val_loss: 0.7319 - val_acc: 0.8765\n",
      "Epoch 511/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1283 - acc: 0.9595 - val_loss: 0.7206 - val_acc: 0.8779\n",
      "Epoch 512/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1279 - acc: 0.9599 - val_loss: 0.7546 - val_acc: 0.8712\n",
      "Epoch 513/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1262 - acc: 0.9620 - val_loss: 0.7135 - val_acc: 0.8796\n",
      "Epoch 514/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1309 - acc: 0.9594 - val_loss: 0.7253 - val_acc: 0.8790\n",
      "Epoch 515/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1295 - acc: 0.9589 - val_loss: 0.7388 - val_acc: 0.8718\n",
      "Epoch 516/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1254 - acc: 0.9622 - val_loss: 0.7378 - val_acc: 0.8773\n",
      "Epoch 517/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1331 - acc: 0.9583 - val_loss: 0.7221 - val_acc: 0.8796\n",
      "Epoch 518/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1272 - acc: 0.9600 - val_loss: 0.7198 - val_acc: 0.8793\n",
      "Epoch 519/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1231 - acc: 0.9634 - val_loss: 0.7220 - val_acc: 0.8791\n",
      "Epoch 520/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1244 - acc: 0.9612 - val_loss: 0.7438 - val_acc: 0.8762\n",
      "Epoch 521/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1293 - acc: 0.9596 - val_loss: 0.7309 - val_acc: 0.8759\n",
      "Epoch 522/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1262 - acc: 0.9610 - val_loss: 0.7452 - val_acc: 0.8749\n",
      "Epoch 523/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1275 - acc: 0.9611 - val_loss: 0.7395 - val_acc: 0.8748\n",
      "Epoch 524/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1228 - acc: 0.9622 - val_loss: 0.7598 - val_acc: 0.8697\n",
      "Epoch 525/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1238 - acc: 0.9622 - val_loss: 0.7301 - val_acc: 0.8787\n",
      "Epoch 526/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1222 - acc: 0.9620 - val_loss: 0.7258 - val_acc: 0.8791\n",
      "Epoch 527/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1243 - acc: 0.9622 - val_loss: 0.7396 - val_acc: 0.8765\n",
      "Epoch 528/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1293 - acc: 0.9605 - val_loss: 0.7178 - val_acc: 0.8803\n",
      "Epoch 529/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1196 - acc: 0.9633 - val_loss: 0.7232 - val_acc: 0.8789\n",
      "Epoch 530/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1326 - acc: 0.9584 - val_loss: 0.7385 - val_acc: 0.8760\n",
      "Epoch 531/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1200 - acc: 0.9633 - val_loss: 0.7350 - val_acc: 0.8779\n",
      "Epoch 532/1000\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1268 - acc: 0.9597 - val_loss: 0.7300 - val_acc: 0.8781\n",
      "Epoch 533/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1266 - acc: 0.9611 - val_loss: 0.7214 - val_acc: 0.8783\n",
      "Epoch 534/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1252 - acc: 0.9605 - val_loss: 0.7716 - val_acc: 0.8695\n",
      "Epoch 535/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1213 - acc: 0.9633 - val_loss: 0.7518 - val_acc: 0.8754\n",
      "Epoch 536/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1275 - acc: 0.9610 - val_loss: 0.7297 - val_acc: 0.8789\n",
      "Epoch 537/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1273 - acc: 0.9612 - val_loss: 0.7486 - val_acc: 0.8742\n",
      "Epoch 538/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1247 - acc: 0.9612 - val_loss: 0.7279 - val_acc: 0.8806\n",
      "Epoch 539/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1245 - acc: 0.9617 - val_loss: 0.7285 - val_acc: 0.8791\n",
      "Epoch 540/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1236 - acc: 0.9616 - val_loss: 0.7334 - val_acc: 0.8773\n",
      "Epoch 541/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1246 - acc: 0.9617 - val_loss: 0.7240 - val_acc: 0.8795\n",
      "Epoch 542/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1268 - acc: 0.9615 - val_loss: 0.7349 - val_acc: 0.8773\n",
      "Epoch 543/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1224 - acc: 0.9623 - val_loss: 0.7458 - val_acc: 0.8769\n",
      "Epoch 544/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1194 - acc: 0.9643 - val_loss: 0.7302 - val_acc: 0.8779\n",
      "Epoch 545/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1247 - acc: 0.9615 - val_loss: 0.7394 - val_acc: 0.8759\n",
      "Epoch 546/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1219 - acc: 0.9616 - val_loss: 0.7435 - val_acc: 0.8768\n",
      "Epoch 547/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1299 - acc: 0.9587 - val_loss: 0.7609 - val_acc: 0.8736\n",
      "Epoch 548/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1200 - acc: 0.9638 - val_loss: 0.7607 - val_acc: 0.8727\n",
      "Epoch 549/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1198 - acc: 0.9627 - val_loss: 0.7392 - val_acc: 0.8785\n",
      "Epoch 550/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1270 - acc: 0.9606 - val_loss: 0.7498 - val_acc: 0.8755\n",
      "Epoch 551/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1251 - acc: 0.9605 - val_loss: 0.7585 - val_acc: 0.8746\n",
      "Epoch 552/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1218 - acc: 0.9628 - val_loss: 0.7423 - val_acc: 0.8766\n",
      "Epoch 553/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1253 - acc: 0.9612 - val_loss: 0.7717 - val_acc: 0.8715\n",
      "Epoch 554/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1230 - acc: 0.9619 - val_loss: 0.7488 - val_acc: 0.8773\n",
      "Epoch 555/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1232 - acc: 0.9615 - val_loss: 0.7560 - val_acc: 0.8741\n",
      "Epoch 556/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1243 - acc: 0.9612 - val_loss: 0.7638 - val_acc: 0.8755\n",
      "Epoch 557/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1207 - acc: 0.9631 - val_loss: 0.7365 - val_acc: 0.8786\n",
      "Epoch 558/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1188 - acc: 0.9639 - val_loss: 0.7424 - val_acc: 0.8759\n",
      "Epoch 559/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1324 - acc: 0.9591 - val_loss: 0.7416 - val_acc: 0.8777\n",
      "Epoch 560/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1212 - acc: 0.9624 - val_loss: 0.7358 - val_acc: 0.8788\n",
      "Epoch 561/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1175 - acc: 0.9639 - val_loss: 0.7505 - val_acc: 0.8735\n",
      "Epoch 562/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1187 - acc: 0.9633 - val_loss: 0.7643 - val_acc: 0.8751\n",
      "Epoch 563/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1161 - acc: 0.9639 - val_loss: 0.7396 - val_acc: 0.8777\n",
      "Epoch 564/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1184 - acc: 0.9624 - val_loss: 0.7501 - val_acc: 0.8755\n",
      "Epoch 565/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1248 - acc: 0.9618 - val_loss: 0.7431 - val_acc: 0.8742\n",
      "Epoch 566/1000\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1314 - acc: 0.9584 - val_loss: 0.7626 - val_acc: 0.8772\n",
      "Epoch 567/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1265 - acc: 0.9614 - val_loss: 0.7911 - val_acc: 0.8696\n",
      "Epoch 568/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1192 - acc: 0.9631 - val_loss: 0.7506 - val_acc: 0.8755\n",
      "Epoch 569/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1152 - acc: 0.9639 - val_loss: 0.7462 - val_acc: 0.8774\n",
      "Epoch 570/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1231 - acc: 0.9611 - val_loss: 0.8271 - val_acc: 0.8615\n",
      "Epoch 571/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1236 - acc: 0.9609 - val_loss: 0.7603 - val_acc: 0.8747\n",
      "Epoch 572/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1182 - acc: 0.9634 - val_loss: 0.7460 - val_acc: 0.8762\n",
      "Epoch 573/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1191 - acc: 0.9632 - val_loss: 0.7480 - val_acc: 0.8792\n",
      "Epoch 574/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1244 - acc: 0.9607 - val_loss: 0.7322 - val_acc: 0.8794\n",
      "Epoch 575/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1195 - acc: 0.9619 - val_loss: 0.7439 - val_acc: 0.8797\n",
      "Epoch 576/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1200 - acc: 0.9634 - val_loss: 0.7491 - val_acc: 0.8782\n",
      "Epoch 577/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1261 - acc: 0.9600 - val_loss: 0.7552 - val_acc: 0.8756\n",
      "Epoch 578/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1193 - acc: 0.9633 - val_loss: 0.7472 - val_acc: 0.8782\n",
      "Epoch 579/1000\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1183 - acc: 0.9638 - val_loss: 0.7518 - val_acc: 0.8785\n",
      "Epoch 580/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1196 - acc: 0.9629 - val_loss: 0.7599 - val_acc: 0.8759\n",
      "Epoch 581/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1201 - acc: 0.9629 - val_loss: 0.7554 - val_acc: 0.8760\n",
      "Epoch 582/1000\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1230 - acc: 0.9619 - val_loss: 0.7467 - val_acc: 0.8782\n",
      "Epoch 583/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1180 - acc: 0.9648 - val_loss: 0.7505 - val_acc: 0.8786\n",
      "Epoch 584/1000\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1139 - acc: 0.9646 - val_loss: 0.7971 - val_acc: 0.8663\n",
      "Epoch 585/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1184 - acc: 0.9638 - val_loss: 0.7604 - val_acc: 0.8780\n",
      "Epoch 586/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1192 - acc: 0.9636 - val_loss: 0.7463 - val_acc: 0.8779\n",
      "Epoch 587/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1200 - acc: 0.9633 - val_loss: 0.7541 - val_acc: 0.8763\n",
      "Epoch 588/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1165 - acc: 0.9635 - val_loss: 0.7681 - val_acc: 0.8744\n",
      "Epoch 589/1000\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1191 - acc: 0.9637 - val_loss: 0.7534 - val_acc: 0.8779\n",
      "Epoch 590/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1164 - acc: 0.9646 - val_loss: 0.7634 - val_acc: 0.8753\n",
      "Epoch 591/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1180 - acc: 0.9640 - val_loss: 0.7726 - val_acc: 0.8752\n",
      "Epoch 592/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1233 - acc: 0.9606 - val_loss: 0.7602 - val_acc: 0.8760\n",
      "Epoch 593/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1256 - acc: 0.9603 - val_loss: 0.7586 - val_acc: 0.8752\n",
      "Epoch 594/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1180 - acc: 0.9629 - val_loss: 0.7690 - val_acc: 0.8742\n",
      "Epoch 595/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1187 - acc: 0.9631 - val_loss: 0.7624 - val_acc: 0.8765\n",
      "Epoch 596/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1209 - acc: 0.9617 - val_loss: 0.7552 - val_acc: 0.8776\n",
      "Epoch 597/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1117 - acc: 0.9665 - val_loss: 0.7679 - val_acc: 0.8750\n",
      "Epoch 598/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1152 - acc: 0.9649 - val_loss: 0.7691 - val_acc: 0.8751\n",
      "Epoch 599/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1171 - acc: 0.9632 - val_loss: 0.7590 - val_acc: 0.8772\n",
      "Epoch 600/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1177 - acc: 0.9638 - val_loss: 0.7706 - val_acc: 0.8742\n",
      "Epoch 601/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1159 - acc: 0.9635 - val_loss: 0.7584 - val_acc: 0.8788\n",
      "Epoch 602/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1152 - acc: 0.9644 - val_loss: 0.7549 - val_acc: 0.8781\n",
      "Epoch 603/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1120 - acc: 0.9658 - val_loss: 0.7555 - val_acc: 0.8766\n",
      "Epoch 604/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1166 - acc: 0.9639 - val_loss: 0.7680 - val_acc: 0.8761\n",
      "Epoch 605/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1181 - acc: 0.9632 - val_loss: 0.7642 - val_acc: 0.8751\n",
      "Epoch 606/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1197 - acc: 0.9619 - val_loss: 0.7848 - val_acc: 0.8718\n",
      "Epoch 607/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1154 - acc: 0.9632 - val_loss: 0.7878 - val_acc: 0.8741\n",
      "Epoch 608/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1157 - acc: 0.9648 - val_loss: 0.7662 - val_acc: 0.8794\n",
      "Epoch 609/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1148 - acc: 0.9656 - val_loss: 0.7634 - val_acc: 0.8759\n",
      "Epoch 610/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1165 - acc: 0.9634 - val_loss: 0.7618 - val_acc: 0.8762\n",
      "Epoch 611/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1192 - acc: 0.9620 - val_loss: 0.7618 - val_acc: 0.8769\n",
      "Epoch 612/1000\n",
      "34108/34108 [==============================] - ETA: 0s - loss: 0.1173 - acc: 0.964 - 1s 16us/step - loss: 0.1176 - acc: 0.9645 - val_loss: 0.7540 - val_acc: 0.8783\n",
      "Epoch 613/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1221 - acc: 0.9615 - val_loss: 0.7785 - val_acc: 0.8752\n",
      "Epoch 614/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1164 - acc: 0.9645 - val_loss: 0.7786 - val_acc: 0.8748\n",
      "Epoch 615/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1125 - acc: 0.9661 - val_loss: 0.7538 - val_acc: 0.8803\n",
      "Epoch 616/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1156 - acc: 0.9642 - val_loss: 0.7646 - val_acc: 0.8765\n",
      "Epoch 617/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1158 - acc: 0.9649 - val_loss: 0.7675 - val_acc: 0.8792\n",
      "Epoch 618/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1173 - acc: 0.9648 - val_loss: 0.7721 - val_acc: 0.8756\n",
      "Epoch 619/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1155 - acc: 0.9640 - val_loss: 0.7952 - val_acc: 0.8700\n",
      "Epoch 620/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1156 - acc: 0.9642 - val_loss: 0.8079 - val_acc: 0.8687\n",
      "Epoch 621/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1254 - acc: 0.9604 - val_loss: 0.7712 - val_acc: 0.8750\n",
      "Epoch 622/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1128 - acc: 0.9653 - val_loss: 0.7771 - val_acc: 0.8758\n",
      "Epoch 623/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1114 - acc: 0.9668 - val_loss: 0.7761 - val_acc: 0.8756\n",
      "Epoch 624/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1151 - acc: 0.9645 - val_loss: 0.7705 - val_acc: 0.8762\n",
      "Epoch 625/1000\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.1195 - acc: 0.9621 - val_loss: 0.7690 - val_acc: 0.8759\n",
      "Epoch 626/1000\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1137 - acc: 0.9643 - val_loss: 0.7652 - val_acc: 0.8776\n",
      "Epoch 627/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1103 - acc: 0.9658 - val_loss: 0.7601 - val_acc: 0.8796\n",
      "Epoch 628/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1165 - acc: 0.9639 - val_loss: 0.8033 - val_acc: 0.8699\n",
      "Epoch 629/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1156 - acc: 0.9650 - val_loss: 0.7767 - val_acc: 0.8761\n",
      "Epoch 630/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1117 - acc: 0.9651 - val_loss: 0.7781 - val_acc: 0.8751\n",
      "Epoch 631/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1156 - acc: 0.9641 - val_loss: 0.7719 - val_acc: 0.8795\n",
      "Epoch 632/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1099 - acc: 0.9665 - val_loss: 0.7672 - val_acc: 0.8785\n",
      "Epoch 633/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1157 - acc: 0.9650 - val_loss: 0.7691 - val_acc: 0.8786\n",
      "Epoch 634/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1210 - acc: 0.9623 - val_loss: 0.7789 - val_acc: 0.8758\n",
      "Epoch 635/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1122 - acc: 0.9665 - val_loss: 0.7859 - val_acc: 0.8740\n",
      "Epoch 636/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1165 - acc: 0.9639 - val_loss: 0.7849 - val_acc: 0.8753\n",
      "Epoch 637/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1150 - acc: 0.9640 - val_loss: 0.7644 - val_acc: 0.8784\n",
      "Epoch 638/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1126 - acc: 0.9656 - val_loss: 0.7765 - val_acc: 0.8763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 639/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1137 - acc: 0.9653 - val_loss: 0.7933 - val_acc: 0.8752\n",
      "Epoch 640/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1149 - acc: 0.9645 - val_loss: 0.7814 - val_acc: 0.8773\n",
      "Epoch 641/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1116 - acc: 0.9668 - val_loss: 0.7679 - val_acc: 0.8779\n",
      "Epoch 642/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1137 - acc: 0.9644 - val_loss: 0.8010 - val_acc: 0.8707\n",
      "Epoch 643/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1117 - acc: 0.9652 - val_loss: 0.7747 - val_acc: 0.8769\n",
      "Epoch 644/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1144 - acc: 0.9651 - val_loss: 0.7758 - val_acc: 0.8764\n",
      "Epoch 645/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1151 - acc: 0.9647 - val_loss: 0.7725 - val_acc: 0.8775\n",
      "Epoch 646/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1124 - acc: 0.9646 - val_loss: 0.7974 - val_acc: 0.8725\n",
      "Epoch 647/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1162 - acc: 0.9639 - val_loss: 0.7708 - val_acc: 0.8781\n",
      "Epoch 648/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1207 - acc: 0.9614 - val_loss: 0.8035 - val_acc: 0.8736\n",
      "Epoch 649/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1076 - acc: 0.9671 - val_loss: 0.7786 - val_acc: 0.8772\n",
      "Epoch 650/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1150 - acc: 0.9645 - val_loss: 0.7778 - val_acc: 0.8775\n",
      "Epoch 651/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1139 - acc: 0.9653 - val_loss: 0.7888 - val_acc: 0.8749\n",
      "Epoch 652/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1092 - acc: 0.9665 - val_loss: 0.7727 - val_acc: 0.8783\n",
      "Epoch 653/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1093 - acc: 0.9670 - val_loss: 0.7807 - val_acc: 0.8772\n",
      "Epoch 654/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1143 - acc: 0.9644 - val_loss: 0.7810 - val_acc: 0.8760\n",
      "Epoch 655/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1105 - acc: 0.9665 - val_loss: 0.7953 - val_acc: 0.8753\n",
      "Epoch 656/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1108 - acc: 0.9661 - val_loss: 0.8126 - val_acc: 0.8704\n",
      "Epoch 657/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1143 - acc: 0.9649 - val_loss: 0.7949 - val_acc: 0.8736\n",
      "Epoch 658/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1123 - acc: 0.9645 - val_loss: 0.7876 - val_acc: 0.8769\n",
      "Epoch 659/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1092 - acc: 0.9666 - val_loss: 0.7945 - val_acc: 0.8761\n",
      "Epoch 660/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1145 - acc: 0.9644 - val_loss: 0.7775 - val_acc: 0.8765\n",
      "Epoch 661/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1094 - acc: 0.9660 - val_loss: 0.7798 - val_acc: 0.8784\n",
      "Epoch 662/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1109 - acc: 0.9653 - val_loss: 0.7919 - val_acc: 0.8735\n",
      "Epoch 663/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1088 - acc: 0.9671 - val_loss: 0.7813 - val_acc: 0.8769\n",
      "Epoch 664/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1125 - acc: 0.9649 - val_loss: 0.8318 - val_acc: 0.8694\n",
      "Epoch 665/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1178 - acc: 0.9633 - val_loss: 0.7899 - val_acc: 0.8750\n",
      "Epoch 666/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1109 - acc: 0.9662 - val_loss: 0.8173 - val_acc: 0.8707\n",
      "Epoch 667/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1126 - acc: 0.9650 - val_loss: 0.7860 - val_acc: 0.8758\n",
      "Epoch 668/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1105 - acc: 0.9659 - val_loss: 0.7915 - val_acc: 0.8742\n",
      "Epoch 669/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1120 - acc: 0.9653 - val_loss: 0.7853 - val_acc: 0.8771\n",
      "Epoch 670/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1069 - acc: 0.9671 - val_loss: 0.8134 - val_acc: 0.8724\n",
      "Epoch 671/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1081 - acc: 0.9668 - val_loss: 0.7870 - val_acc: 0.8751\n",
      "Epoch 672/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1094 - acc: 0.9668 - val_loss: 0.7788 - val_acc: 0.8787\n",
      "Epoch 673/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1109 - acc: 0.9657 - val_loss: 0.7993 - val_acc: 0.8752\n",
      "Epoch 674/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1112 - acc: 0.9657 - val_loss: 0.8045 - val_acc: 0.8743\n",
      "Epoch 675/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1063 - acc: 0.9676 - val_loss: 0.7826 - val_acc: 0.8769\n",
      "Epoch 676/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1083 - acc: 0.9662 - val_loss: 0.7962 - val_acc: 0.8771\n",
      "Epoch 677/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1091 - acc: 0.9663 - val_loss: 0.7822 - val_acc: 0.8769\n",
      "Epoch 678/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1139 - acc: 0.9653 - val_loss: 0.8173 - val_acc: 0.8726\n",
      "Epoch 679/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1083 - acc: 0.9668 - val_loss: 0.7899 - val_acc: 0.8756\n",
      "Epoch 680/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1091 - acc: 0.9666 - val_loss: 0.7903 - val_acc: 0.8767\n",
      "Epoch 681/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1125 - acc: 0.9652 - val_loss: 0.8082 - val_acc: 0.8741\n",
      "Epoch 682/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1146 - acc: 0.9640 - val_loss: 0.7918 - val_acc: 0.8785\n",
      "Epoch 683/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1111 - acc: 0.9657 - val_loss: 0.7892 - val_acc: 0.8787\n",
      "Epoch 684/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1075 - acc: 0.9671 - val_loss: 0.7812 - val_acc: 0.8783\n",
      "Epoch 685/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1115 - acc: 0.9664 - val_loss: 0.7919 - val_acc: 0.8774\n",
      "Epoch 686/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1106 - acc: 0.9667 - val_loss: 0.8307 - val_acc: 0.8715\n",
      "Epoch 687/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1074 - acc: 0.9675 - val_loss: 0.8069 - val_acc: 0.8723\n",
      "Epoch 688/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1079 - acc: 0.9676 - val_loss: 0.7967 - val_acc: 0.8760\n",
      "Epoch 689/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1076 - acc: 0.9667 - val_loss: 0.7977 - val_acc: 0.8771\n",
      "Epoch 690/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1163 - acc: 0.9638 - val_loss: 0.8218 - val_acc: 0.8714\n",
      "Epoch 691/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1196 - acc: 0.9618 - val_loss: 0.7939 - val_acc: 0.8754\n",
      "Epoch 692/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1027 - acc: 0.9689 - val_loss: 0.8041 - val_acc: 0.8723\n",
      "Epoch 693/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1035 - acc: 0.9687 - val_loss: 0.8282 - val_acc: 0.8685\n",
      "Epoch 694/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1093 - acc: 0.9660 - val_loss: 0.7958 - val_acc: 0.8751\n",
      "Epoch 695/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1094 - acc: 0.9668 - val_loss: 0.7975 - val_acc: 0.8765\n",
      "Epoch 696/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1052 - acc: 0.9678 - val_loss: 0.7984 - val_acc: 0.8755\n",
      "Epoch 697/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1077 - acc: 0.9661 - val_loss: 0.8067 - val_acc: 0.8722\n",
      "Epoch 698/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1108 - acc: 0.9651 - val_loss: 0.7922 - val_acc: 0.8770\n",
      "Epoch 699/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1106 - acc: 0.9663 - val_loss: 0.8051 - val_acc: 0.8765\n",
      "Epoch 700/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1078 - acc: 0.9664 - val_loss: 0.8104 - val_acc: 0.8771\n",
      "Epoch 701/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1064 - acc: 0.9669 - val_loss: 0.7841 - val_acc: 0.8797\n",
      "Epoch 702/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1106 - acc: 0.9657 - val_loss: 0.8012 - val_acc: 0.8746\n",
      "Epoch 703/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1089 - acc: 0.9665 - val_loss: 0.7946 - val_acc: 0.8776\n",
      "Epoch 704/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1084 - acc: 0.9660 - val_loss: 0.8088 - val_acc: 0.8745\n",
      "Epoch 705/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1052 - acc: 0.9680 - val_loss: 0.8107 - val_acc: 0.8741\n",
      "Epoch 706/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1041 - acc: 0.9685 - val_loss: 0.7956 - val_acc: 0.8765\n",
      "Epoch 707/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1068 - acc: 0.9678 - val_loss: 0.8006 - val_acc: 0.8750\n",
      "Epoch 708/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1087 - acc: 0.9664 - val_loss: 0.8051 - val_acc: 0.8741\n",
      "Epoch 709/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1082 - acc: 0.9662 - val_loss: 0.8249 - val_acc: 0.8718\n",
      "Epoch 710/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1115 - acc: 0.9650 - val_loss: 0.7932 - val_acc: 0.8760\n",
      "Epoch 711/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1051 - acc: 0.9681 - val_loss: 0.8003 - val_acc: 0.8763\n",
      "Epoch 712/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1090 - acc: 0.9664 - val_loss: 0.8121 - val_acc: 0.8745\n",
      "Epoch 713/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1097 - acc: 0.9660 - val_loss: 0.7860 - val_acc: 0.8787\n",
      "Epoch 714/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1062 - acc: 0.9676 - val_loss: 0.7936 - val_acc: 0.8760\n",
      "Epoch 715/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1063 - acc: 0.9672 - val_loss: 0.8041 - val_acc: 0.8774\n",
      "Epoch 716/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1111 - acc: 0.9665 - val_loss: 0.8088 - val_acc: 0.8750\n",
      "Epoch 717/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1033 - acc: 0.9693 - val_loss: 0.7974 - val_acc: 0.8777\n",
      "Epoch 718/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1083 - acc: 0.9670 - val_loss: 0.8125 - val_acc: 0.8755\n",
      "Epoch 719/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1031 - acc: 0.9686 - val_loss: 0.8227 - val_acc: 0.8710\n",
      "Epoch 720/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1051 - acc: 0.9672 - val_loss: 0.8142 - val_acc: 0.8766\n",
      "Epoch 721/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1060 - acc: 0.9678 - val_loss: 0.8188 - val_acc: 0.8718\n",
      "Epoch 722/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1086 - acc: 0.9660 - val_loss: 0.7999 - val_acc: 0.8794\n",
      "Epoch 723/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1035 - acc: 0.9685 - val_loss: 0.8058 - val_acc: 0.8761\n",
      "Epoch 724/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1064 - acc: 0.9673 - val_loss: 0.8186 - val_acc: 0.8731\n",
      "Epoch 725/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1065 - acc: 0.9668 - val_loss: 0.8184 - val_acc: 0.8736\n",
      "Epoch 726/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1034 - acc: 0.9679 - val_loss: 0.8010 - val_acc: 0.8762\n",
      "Epoch 727/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1113 - acc: 0.9648 - val_loss: 0.8028 - val_acc: 0.8776\n",
      "Epoch 728/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1041 - acc: 0.9686 - val_loss: 0.8155 - val_acc: 0.8760\n",
      "Epoch 729/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1059 - acc: 0.9678 - val_loss: 0.7951 - val_acc: 0.8775\n",
      "Epoch 730/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1042 - acc: 0.9683 - val_loss: 0.8273 - val_acc: 0.8746\n",
      "Epoch 731/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1021 - acc: 0.9695 - val_loss: 0.8164 - val_acc: 0.8736\n",
      "Epoch 732/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1083 - acc: 0.9663 - val_loss: 0.8095 - val_acc: 0.8781\n",
      "Epoch 733/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1077 - acc: 0.9670 - val_loss: 0.8586 - val_acc: 0.8655\n",
      "Epoch 734/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1091 - acc: 0.9654 - val_loss: 0.8242 - val_acc: 0.8713\n",
      "Epoch 735/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1034 - acc: 0.9682 - val_loss: 0.8100 - val_acc: 0.8760\n",
      "Epoch 736/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1021 - acc: 0.9685 - val_loss: 0.8114 - val_acc: 0.8764\n",
      "Epoch 737/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1032 - acc: 0.9672 - val_loss: 0.8202 - val_acc: 0.8738\n",
      "Epoch 738/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1034 - acc: 0.9691 - val_loss: 0.8150 - val_acc: 0.8758\n",
      "Epoch 739/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1136 - acc: 0.9636 - val_loss: 0.8190 - val_acc: 0.8755\n",
      "Epoch 740/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1073 - acc: 0.9669 - val_loss: 0.8419 - val_acc: 0.8722\n",
      "Epoch 741/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1033 - acc: 0.9691 - val_loss: 0.8129 - val_acc: 0.8780\n",
      "Epoch 742/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1062 - acc: 0.9674 - val_loss: 0.8253 - val_acc: 0.8723\n",
      "Epoch 743/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1077 - acc: 0.9674 - val_loss: 0.8080 - val_acc: 0.8771\n",
      "Epoch 744/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1059 - acc: 0.9662 - val_loss: 0.8208 - val_acc: 0.8732\n",
      "Epoch 745/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1052 - acc: 0.9670 - val_loss: 0.7948 - val_acc: 0.8782\n",
      "Epoch 746/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1020 - acc: 0.9685 - val_loss: 0.8041 - val_acc: 0.8765\n",
      "Epoch 747/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1032 - acc: 0.9687 - val_loss: 0.8235 - val_acc: 0.8759\n",
      "Epoch 748/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1021 - acc: 0.9693 - val_loss: 0.8454 - val_acc: 0.8646\n",
      "Epoch 749/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1172 - acc: 0.9634 - val_loss: 0.8016 - val_acc: 0.8774\n",
      "Epoch 750/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1069 - acc: 0.9671 - val_loss: 0.8135 - val_acc: 0.8765\n",
      "Epoch 751/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1078 - acc: 0.9670 - val_loss: 0.8249 - val_acc: 0.8752\n",
      "Epoch 752/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1029 - acc: 0.9691 - val_loss: 0.8432 - val_acc: 0.8685\n",
      "Epoch 753/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1011 - acc: 0.9700 - val_loss: 0.8176 - val_acc: 0.8751\n",
      "Epoch 754/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.1037 - acc: 0.9678 - val_loss: 0.8222 - val_acc: 0.8760\n",
      "Epoch 755/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1079 - acc: 0.9667 - val_loss: 0.8102 - val_acc: 0.8756\n",
      "Epoch 756/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1030 - acc: 0.9686 - val_loss: 0.8395 - val_acc: 0.8725\n",
      "Epoch 757/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1029 - acc: 0.9684 - val_loss: 0.8329 - val_acc: 0.8738\n",
      "Epoch 758/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1056 - acc: 0.9675 - val_loss: 0.8066 - val_acc: 0.8784\n",
      "Epoch 759/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0999 - acc: 0.9703 - val_loss: 0.8127 - val_acc: 0.8765\n",
      "Epoch 760/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1037 - acc: 0.9685 - val_loss: 0.8453 - val_acc: 0.8725\n",
      "Epoch 761/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1104 - acc: 0.9644 - val_loss: 0.8377 - val_acc: 0.8721\n",
      "Epoch 762/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1038 - acc: 0.9683 - val_loss: 0.8147 - val_acc: 0.8777\n",
      "Epoch 763/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0996 - acc: 0.9694 - val_loss: 0.8285 - val_acc: 0.8760\n",
      "Epoch 764/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1069 - acc: 0.9662 - val_loss: 0.8209 - val_acc: 0.8775\n",
      "Epoch 765/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1024 - acc: 0.9687 - val_loss: 0.8166 - val_acc: 0.8784\n",
      "Epoch 766/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0987 - acc: 0.9701 - val_loss: 0.8321 - val_acc: 0.8760\n",
      "Epoch 767/1000\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1042 - acc: 0.9680 - val_loss: 0.8207 - val_acc: 0.8778\n",
      "Epoch 768/1000\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1061 - acc: 0.9674 - val_loss: 0.8371 - val_acc: 0.8730\n",
      "Epoch 769/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1026 - acc: 0.9679 - val_loss: 0.8225 - val_acc: 0.8755\n",
      "Epoch 770/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1041 - acc: 0.9683 - val_loss: 0.8239 - val_acc: 0.8746\n",
      "Epoch 771/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1012 - acc: 0.9692 - val_loss: 0.8396 - val_acc: 0.8746\n",
      "Epoch 772/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1028 - acc: 0.9684 - val_loss: 0.8168 - val_acc: 0.8756\n",
      "Epoch 773/1000\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0998 - acc: 0.9697 - val_loss: 0.8268 - val_acc: 0.8744\n",
      "Epoch 774/1000\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1030 - acc: 0.9678 - val_loss: 0.9020 - val_acc: 0.8630\n",
      "Epoch 775/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1035 - acc: 0.9689 - val_loss: 0.8169 - val_acc: 0.8796\n",
      "Epoch 776/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1025 - acc: 0.9686 - val_loss: 0.8275 - val_acc: 0.8764\n",
      "Epoch 777/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1036 - acc: 0.9687 - val_loss: 0.8640 - val_acc: 0.8686\n",
      "Epoch 778/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0993 - acc: 0.9705 - val_loss: 0.8165 - val_acc: 0.8768\n",
      "Epoch 779/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1010 - acc: 0.9697 - val_loss: 0.8392 - val_acc: 0.8736\n",
      "Epoch 780/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0992 - acc: 0.9702 - val_loss: 0.8384 - val_acc: 0.8741\n",
      "Epoch 781/1000\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1022 - acc: 0.9687 - val_loss: 0.8351 - val_acc: 0.8736\n",
      "Epoch 782/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1040 - acc: 0.9683 - val_loss: 0.8374 - val_acc: 0.8729\n",
      "Epoch 783/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1141 - acc: 0.9640 - val_loss: 0.8311 - val_acc: 0.8722\n",
      "Epoch 784/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1048 - acc: 0.9679 - val_loss: 0.8241 - val_acc: 0.8764\n",
      "Epoch 785/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1027 - acc: 0.9683 - val_loss: 0.8171 - val_acc: 0.8788\n",
      "Epoch 786/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1019 - acc: 0.9678 - val_loss: 0.8475 - val_acc: 0.8735\n",
      "Epoch 787/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0964 - acc: 0.9710 - val_loss: 0.8239 - val_acc: 0.8784\n",
      "Epoch 788/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0997 - acc: 0.9690 - val_loss: 0.8304 - val_acc: 0.8762\n",
      "Epoch 789/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1031 - acc: 0.9685 - val_loss: 0.8361 - val_acc: 0.8723\n",
      "Epoch 790/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1083 - acc: 0.9668 - val_loss: 0.8378 - val_acc: 0.8742\n",
      "Epoch 791/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1087 - acc: 0.9662 - val_loss: 0.8184 - val_acc: 0.8777\n",
      "Epoch 792/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1017 - acc: 0.9696 - val_loss: 0.8296 - val_acc: 0.8775\n",
      "Epoch 793/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0977 - acc: 0.9712 - val_loss: 0.8401 - val_acc: 0.8744\n",
      "Epoch 794/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0989 - acc: 0.9702 - val_loss: 0.8438 - val_acc: 0.8736\n",
      "Epoch 795/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1001 - acc: 0.9688 - val_loss: 0.8746 - val_acc: 0.8688\n",
      "Epoch 796/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0986 - acc: 0.9704 - val_loss: 0.8545 - val_acc: 0.8711\n",
      "Epoch 797/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1005 - acc: 0.9698 - val_loss: 0.8352 - val_acc: 0.8738\n",
      "Epoch 798/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0989 - acc: 0.9703 - val_loss: 0.8524 - val_acc: 0.8688\n",
      "Epoch 799/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1021 - acc: 0.9690 - val_loss: 0.8430 - val_acc: 0.8741\n",
      "Epoch 800/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1066 - acc: 0.9668 - val_loss: 0.8293 - val_acc: 0.8765\n",
      "Epoch 801/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1003 - acc: 0.9697 - val_loss: 0.8407 - val_acc: 0.8738\n",
      "Epoch 802/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1077 - acc: 0.9668 - val_loss: 0.8642 - val_acc: 0.8733\n",
      "Epoch 803/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1013 - acc: 0.9687 - val_loss: 0.8238 - val_acc: 0.8787\n",
      "Epoch 804/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0950 - acc: 0.9713 - val_loss: 0.8413 - val_acc: 0.8756\n",
      "Epoch 805/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1007 - acc: 0.9690 - val_loss: 0.8307 - val_acc: 0.8754\n",
      "Epoch 806/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1052 - acc: 0.9676 - val_loss: 0.8396 - val_acc: 0.8753\n",
      "Epoch 807/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1000 - acc: 0.9695 - val_loss: 0.8285 - val_acc: 0.8764\n",
      "Epoch 808/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0992 - acc: 0.9689 - val_loss: 0.8281 - val_acc: 0.8760\n",
      "Epoch 809/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0972 - acc: 0.9704 - val_loss: 0.8734 - val_acc: 0.8689\n",
      "Epoch 810/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0993 - acc: 0.9692 - val_loss: 0.8653 - val_acc: 0.8694\n",
      "Epoch 811/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1038 - acc: 0.9677 - val_loss: 0.8359 - val_acc: 0.8760\n",
      "Epoch 812/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1054 - acc: 0.9672 - val_loss: 0.8261 - val_acc: 0.8790\n",
      "Epoch 813/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0974 - acc: 0.9706 - val_loss: 0.8411 - val_acc: 0.8736\n",
      "Epoch 814/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0992 - acc: 0.9699 - val_loss: 0.8462 - val_acc: 0.8744\n",
      "Epoch 815/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1009 - acc: 0.9695 - val_loss: 0.8430 - val_acc: 0.8749\n",
      "Epoch 816/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1045 - acc: 0.9670 - val_loss: 0.8346 - val_acc: 0.8769\n",
      "Epoch 817/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0957 - acc: 0.9709 - val_loss: 0.8466 - val_acc: 0.8743\n",
      "Epoch 818/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0965 - acc: 0.9697 - val_loss: 0.8383 - val_acc: 0.8756\n",
      "Epoch 819/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1000 - acc: 0.9702 - val_loss: 0.8420 - val_acc: 0.8751\n",
      "Epoch 820/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1024 - acc: 0.9689 - val_loss: 0.8472 - val_acc: 0.8721\n",
      "Epoch 821/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0988 - acc: 0.9697 - val_loss: 0.8429 - val_acc: 0.8734\n",
      "Epoch 822/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1079 - acc: 0.9667 - val_loss: 0.8525 - val_acc: 0.8745\n",
      "Epoch 823/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0977 - acc: 0.9699 - val_loss: 0.8345 - val_acc: 0.8756\n",
      "Epoch 824/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1010 - acc: 0.9682 - val_loss: 0.8985 - val_acc: 0.8670\n",
      "Epoch 825/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1003 - acc: 0.9688 - val_loss: 0.8277 - val_acc: 0.8787\n",
      "Epoch 826/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0993 - acc: 0.9702 - val_loss: 0.8218 - val_acc: 0.8806\n",
      "Epoch 827/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1007 - acc: 0.9683 - val_loss: 0.8354 - val_acc: 0.8754\n",
      "Epoch 828/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0962 - acc: 0.9716 - val_loss: 0.8460 - val_acc: 0.8744\n",
      "Epoch 829/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0968 - acc: 0.9712 - val_loss: 0.8476 - val_acc: 0.8734\n",
      "Epoch 830/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0953 - acc: 0.9720 - val_loss: 0.8347 - val_acc: 0.8801\n",
      "Epoch 831/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1068 - acc: 0.9671 - val_loss: 0.8364 - val_acc: 0.8776\n",
      "Epoch 832/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1041 - acc: 0.9687 - val_loss: 0.8384 - val_acc: 0.8774\n",
      "Epoch 833/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1014 - acc: 0.9684 - val_loss: 0.8543 - val_acc: 0.8760\n",
      "Epoch 834/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1005 - acc: 0.9682 - val_loss: 0.8446 - val_acc: 0.8730\n",
      "Epoch 835/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0953 - acc: 0.9719 - val_loss: 0.8669 - val_acc: 0.8715\n",
      "Epoch 836/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0995 - acc: 0.9698 - val_loss: 0.8403 - val_acc: 0.8765\n",
      "Epoch 837/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0960 - acc: 0.9710 - val_loss: 0.8737 - val_acc: 0.8732\n",
      "Epoch 838/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1046 - acc: 0.9673 - val_loss: 0.8436 - val_acc: 0.8765\n",
      "Epoch 839/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0937 - acc: 0.9722 - val_loss: 0.8449 - val_acc: 0.8746\n",
      "Epoch 840/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0997 - acc: 0.9690 - val_loss: 0.8517 - val_acc: 0.8741\n",
      "Epoch 841/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0950 - acc: 0.9706 - val_loss: 0.8396 - val_acc: 0.8780\n",
      "Epoch 842/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0994 - acc: 0.9702 - val_loss: 0.8502 - val_acc: 0.8768\n",
      "Epoch 843/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0965 - acc: 0.9709 - val_loss: 0.8719 - val_acc: 0.8711\n",
      "Epoch 844/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0977 - acc: 0.9700 - val_loss: 0.8887 - val_acc: 0.8678\n",
      "Epoch 845/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0959 - acc: 0.9708 - val_loss: 0.8590 - val_acc: 0.8746\n",
      "Epoch 846/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0985 - acc: 0.9691 - val_loss: 0.8517 - val_acc: 0.8749\n",
      "Epoch 847/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1017 - acc: 0.9695 - val_loss: 0.8537 - val_acc: 0.8755\n",
      "Epoch 848/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0947 - acc: 0.9709 - val_loss: 0.8596 - val_acc: 0.8744\n",
      "Epoch 849/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0973 - acc: 0.9704 - val_loss: 0.8730 - val_acc: 0.8722\n",
      "Epoch 850/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0986 - acc: 0.9700 - val_loss: 0.8760 - val_acc: 0.8701\n",
      "Epoch 851/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1021 - acc: 0.9683 - val_loss: 0.8591 - val_acc: 0.8732\n",
      "Epoch 852/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0927 - acc: 0.9729 - val_loss: 0.8597 - val_acc: 0.8735\n",
      "Epoch 853/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0954 - acc: 0.9710 - val_loss: 0.8537 - val_acc: 0.8739\n",
      "Epoch 854/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0970 - acc: 0.9708 - val_loss: 0.8565 - val_acc: 0.8736\n",
      "Epoch 855/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0960 - acc: 0.9715 - val_loss: 0.8541 - val_acc: 0.8747\n",
      "Epoch 856/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1068 - acc: 0.9663 - val_loss: 0.8540 - val_acc: 0.8765\n",
      "Epoch 857/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0952 - acc: 0.9713 - val_loss: 0.8636 - val_acc: 0.8755\n",
      "Epoch 858/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0924 - acc: 0.9725 - val_loss: 0.8400 - val_acc: 0.8767\n",
      "Epoch 859/1000\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.0995 - acc: 0.9708 - val_loss: 0.8719 - val_acc: 0.8726\n",
      "Epoch 860/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0979 - acc: 0.9699 - val_loss: 0.8764 - val_acc: 0.8714\n",
      "Epoch 861/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0968 - acc: 0.9704 - val_loss: 0.8576 - val_acc: 0.8769\n",
      "Epoch 862/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0959 - acc: 0.9710 - val_loss: 0.8549 - val_acc: 0.8756\n",
      "Epoch 863/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1014 - acc: 0.9688 - val_loss: 0.8737 - val_acc: 0.8733\n",
      "Epoch 864/1000\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.0938 - acc: 0.9714 - val_loss: 0.8510 - val_acc: 0.8757\n",
      "Epoch 865/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0960 - acc: 0.9705 - val_loss: 0.8526 - val_acc: 0.8767\n",
      "Epoch 866/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0930 - acc: 0.9716 - val_loss: 0.8690 - val_acc: 0.8747\n",
      "Epoch 867/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0934 - acc: 0.9721 - val_loss: 0.8584 - val_acc: 0.8722\n",
      "Epoch 868/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0930 - acc: 0.9725 - val_loss: 0.8483 - val_acc: 0.8765\n",
      "Epoch 869/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1009 - acc: 0.9678 - val_loss: 0.8462 - val_acc: 0.8750\n",
      "Epoch 870/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0943 - acc: 0.9714 - val_loss: 0.8554 - val_acc: 0.8752\n",
      "Epoch 871/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0935 - acc: 0.9726 - val_loss: 0.8728 - val_acc: 0.8727\n",
      "Epoch 872/1000\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.0936 - acc: 0.9712 - val_loss: 0.8458 - val_acc: 0.8769\n",
      "Epoch 873/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0982 - acc: 0.9695 - val_loss: 0.8762 - val_acc: 0.8727\n",
      "Epoch 874/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1067 - acc: 0.9655 - val_loss: 0.8434 - val_acc: 0.8775\n",
      "Epoch 875/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0939 - acc: 0.9712 - val_loss: 0.8437 - val_acc: 0.8759\n",
      "Epoch 876/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0987 - acc: 0.9691 - val_loss: 0.8541 - val_acc: 0.8754\n",
      "Epoch 877/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0945 - acc: 0.9710 - val_loss: 0.8558 - val_acc: 0.8752\n",
      "Epoch 878/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0874 - acc: 0.9753 - val_loss: 0.8547 - val_acc: 0.8759\n",
      "Epoch 879/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0941 - acc: 0.9716 - val_loss: 0.8567 - val_acc: 0.8776\n",
      "Epoch 880/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1000 - acc: 0.9685 - val_loss: 0.8936 - val_acc: 0.8716\n",
      "Epoch 881/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0921 - acc: 0.9720 - val_loss: 0.8969 - val_acc: 0.8686\n",
      "Epoch 882/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0937 - acc: 0.9706 - val_loss: 0.8960 - val_acc: 0.8723\n",
      "Epoch 883/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1025 - acc: 0.9685 - val_loss: 0.8746 - val_acc: 0.8740\n",
      "Epoch 884/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0949 - acc: 0.9710 - val_loss: 0.8634 - val_acc: 0.8765\n",
      "Epoch 885/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0963 - acc: 0.9708 - val_loss: 0.8807 - val_acc: 0.8716\n",
      "Epoch 886/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0916 - acc: 0.9728 - val_loss: 0.8509 - val_acc: 0.8781\n",
      "Epoch 887/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1006 - acc: 0.9684 - val_loss: 0.8547 - val_acc: 0.8781\n",
      "Epoch 888/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0935 - acc: 0.9710 - val_loss: 0.8620 - val_acc: 0.8721\n",
      "Epoch 889/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0894 - acc: 0.9736 - val_loss: 0.8696 - val_acc: 0.8744\n",
      "Epoch 890/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0945 - acc: 0.9716 - val_loss: 0.8620 - val_acc: 0.8757\n",
      "Epoch 891/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1059 - acc: 0.9675 - val_loss: 0.8594 - val_acc: 0.8758\n",
      "Epoch 892/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0915 - acc: 0.9727 - val_loss: 0.8614 - val_acc: 0.8757\n",
      "Epoch 893/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1061 - acc: 0.9677 - val_loss: 0.8690 - val_acc: 0.8741\n",
      "Epoch 894/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0917 - acc: 0.9721 - val_loss: 0.8683 - val_acc: 0.8718\n",
      "Epoch 895/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0928 - acc: 0.9722 - val_loss: 0.8829 - val_acc: 0.8739\n",
      "Epoch 896/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0889 - acc: 0.9736 - val_loss: 0.8799 - val_acc: 0.8713\n",
      "Epoch 897/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1026 - acc: 0.9688 - val_loss: 0.9071 - val_acc: 0.8668\n",
      "Epoch 898/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0913 - acc: 0.9730 - val_loss: 0.8499 - val_acc: 0.8794\n",
      "Epoch 899/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0994 - acc: 0.9687 - val_loss: 0.8668 - val_acc: 0.8773\n",
      "Epoch 900/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0986 - acc: 0.9692 - val_loss: 0.8595 - val_acc: 0.8769\n",
      "Epoch 901/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0895 - acc: 0.9738 - val_loss: 0.8681 - val_acc: 0.8746\n",
      "Epoch 902/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0896 - acc: 0.9738 - val_loss: 0.8628 - val_acc: 0.8768\n",
      "Epoch 903/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0928 - acc: 0.9718 - val_loss: 0.8710 - val_acc: 0.8741\n",
      "Epoch 904/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0939 - acc: 0.9719 - val_loss: 0.8747 - val_acc: 0.8744\n",
      "Epoch 905/1000\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0927 - acc: 0.9714 - val_loss: 0.8472 - val_acc: 0.8784\n",
      "Epoch 906/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0963 - acc: 0.9708 - val_loss: 0.8607 - val_acc: 0.8762\n",
      "Epoch 907/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0887 - acc: 0.9739 - val_loss: 0.8881 - val_acc: 0.8727\n",
      "Epoch 908/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0950 - acc: 0.9704 - val_loss: 0.8633 - val_acc: 0.8755\n",
      "Epoch 909/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0952 - acc: 0.9712 - val_loss: 0.8531 - val_acc: 0.8787\n",
      "Epoch 910/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0935 - acc: 0.9715 - val_loss: 0.8653 - val_acc: 0.8746\n",
      "Epoch 911/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0935 - acc: 0.9717 - val_loss: 0.8710 - val_acc: 0.8753\n",
      "Epoch 912/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.0929 - acc: 0.9718 - val_loss: 0.8744 - val_acc: 0.8773\n",
      "Epoch 913/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.0953 - acc: 0.9714 - val_loss: 0.8693 - val_acc: 0.8768\n",
      "Epoch 914/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.0919 - acc: 0.9716 - val_loss: 0.8709 - val_acc: 0.8748\n",
      "Epoch 915/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.0903 - acc: 0.9727 - val_loss: 0.8888 - val_acc: 0.8712\n",
      "Epoch 916/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.1037 - acc: 0.9674 - val_loss: 0.8762 - val_acc: 0.8751\n",
      "Epoch 917/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.0993 - acc: 0.9691 - val_loss: 0.8542 - val_acc: 0.8757\n",
      "Epoch 918/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.0912 - acc: 0.9722 - val_loss: 0.8580 - val_acc: 0.8768\n",
      "Epoch 919/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.0866 - acc: 0.9746 - val_loss: 0.8680 - val_acc: 0.8746\n",
      "Epoch 920/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.0902 - acc: 0.9726 - val_loss: 0.8721 - val_acc: 0.8758\n",
      "Epoch 921/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.0954 - acc: 0.9707 - val_loss: 0.8876 - val_acc: 0.8738\n",
      "Epoch 922/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.0974 - acc: 0.9703 - val_loss: 0.8648 - val_acc: 0.8751\n",
      "Epoch 923/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0961 - acc: 0.9700 - val_loss: 0.9117 - val_acc: 0.8725\n",
      "Epoch 924/1000\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.0973 - acc: 0.9698 - val_loss: 0.8896 - val_acc: 0.8708\n",
      "Epoch 925/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.0867 - acc: 0.9736 - val_loss: 0.8619 - val_acc: 0.8768\n",
      "Epoch 926/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.0944 - acc: 0.9721 - val_loss: 0.8717 - val_acc: 0.8756\n",
      "Epoch 927/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.0935 - acc: 0.9713 - val_loss: 0.8797 - val_acc: 0.8760\n",
      "Epoch 928/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.0909 - acc: 0.9729 - val_loss: 0.8926 - val_acc: 0.8710\n",
      "Epoch 929/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.0937 - acc: 0.9715 - val_loss: 0.8856 - val_acc: 0.8724\n",
      "Epoch 930/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.0930 - acc: 0.9717 - val_loss: 0.8755 - val_acc: 0.8759\n",
      "Epoch 931/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.0895 - acc: 0.9731 - val_loss: 0.9026 - val_acc: 0.8694\n",
      "Epoch 932/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.0993 - acc: 0.9692 - val_loss: 0.8742 - val_acc: 0.8743\n",
      "Epoch 933/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.0900 - acc: 0.9727 - val_loss: 0.8649 - val_acc: 0.8771\n",
      "Epoch 934/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.0873 - acc: 0.9742 - val_loss: 0.8594 - val_acc: 0.8772\n",
      "Epoch 935/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.0941 - acc: 0.9712 - val_loss: 0.8735 - val_acc: 0.8760\n",
      "Epoch 936/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.0873 - acc: 0.9743 - val_loss: 0.8645 - val_acc: 0.8777\n",
      "Epoch 937/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.0928 - acc: 0.9716 - val_loss: 0.8595 - val_acc: 0.8801\n",
      "Epoch 938/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0882 - acc: 0.9731 - val_loss: 0.8780 - val_acc: 0.8738\n",
      "Epoch 939/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.0925 - acc: 0.9721 - val_loss: 0.8823 - val_acc: 0.8741\n",
      "Epoch 940/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.0977 - acc: 0.9695 - val_loss: 0.8757 - val_acc: 0.8746\n",
      "Epoch 941/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.0968 - acc: 0.9698 - val_loss: 0.8776 - val_acc: 0.8759\n",
      "Epoch 942/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.0903 - acc: 0.9730 - val_loss: 0.8770 - val_acc: 0.8753\n",
      "Epoch 943/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.0956 - acc: 0.9709 - val_loss: 0.8868 - val_acc: 0.8727\n",
      "Epoch 944/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.0918 - acc: 0.9719 - val_loss: 0.8717 - val_acc: 0.8759\n",
      "Epoch 945/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0928 - acc: 0.9715 - val_loss: 0.8821 - val_acc: 0.8732\n",
      "Epoch 946/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.0919 - acc: 0.9722 - val_loss: 0.8790 - val_acc: 0.8753\n",
      "Epoch 947/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0907 - acc: 0.9716 - val_loss: 0.8858 - val_acc: 0.8727\n",
      "Epoch 948/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0924 - acc: 0.9707 - val_loss: 0.8740 - val_acc: 0.8759\n",
      "Epoch 949/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0914 - acc: 0.9725 - val_loss: 0.8740 - val_acc: 0.8773\n",
      "Epoch 950/1000\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0974 - acc: 0.9702 - val_loss: 0.8877 - val_acc: 0.8738\n",
      "Epoch 951/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0894 - acc: 0.9726 - val_loss: 0.8742 - val_acc: 0.8747\n",
      "Epoch 952/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0904 - acc: 0.9723 - val_loss: 0.9006 - val_acc: 0.8709\n",
      "Epoch 953/1000\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0988 - acc: 0.9701 - val_loss: 0.8863 - val_acc: 0.8741\n",
      "Epoch 954/1000\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0871 - acc: 0.9741 - val_loss: 0.8808 - val_acc: 0.8759\n",
      "Epoch 955/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0925 - acc: 0.9722 - val_loss: 0.8786 - val_acc: 0.8774\n",
      "Epoch 956/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0943 - acc: 0.9709 - val_loss: 0.8705 - val_acc: 0.8775\n",
      "Epoch 957/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0970 - acc: 0.9696 - val_loss: 0.8800 - val_acc: 0.8770\n",
      "Epoch 958/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0875 - acc: 0.9736 - val_loss: 0.8792 - val_acc: 0.8769\n",
      "Epoch 959/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0897 - acc: 0.9730 - val_loss: 0.9153 - val_acc: 0.8697\n",
      "Epoch 960/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0922 - acc: 0.9712 - val_loss: 0.8855 - val_acc: 0.8756\n",
      "Epoch 961/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0896 - acc: 0.9740 - val_loss: 0.8769 - val_acc: 0.8746\n",
      "Epoch 962/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0928 - acc: 0.9722 - val_loss: 0.8779 - val_acc: 0.8741\n",
      "Epoch 963/1000\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0875 - acc: 0.9736 - val_loss: 0.8893 - val_acc: 0.8735\n",
      "Epoch 964/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0908 - acc: 0.9724 - val_loss: 0.8832 - val_acc: 0.8763\n",
      "Epoch 965/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0871 - acc: 0.9736 - val_loss: 0.8845 - val_acc: 0.8769\n",
      "Epoch 966/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0958 - acc: 0.9699 - val_loss: 0.8863 - val_acc: 0.8769\n",
      "Epoch 967/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0902 - acc: 0.9726 - val_loss: 0.8775 - val_acc: 0.8748\n",
      "Epoch 968/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0927 - acc: 0.9721 - val_loss: 0.8972 - val_acc: 0.8708\n",
      "Epoch 969/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0893 - acc: 0.9730 - val_loss: 0.8959 - val_acc: 0.8748\n",
      "Epoch 970/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0872 - acc: 0.9736 - val_loss: 0.8918 - val_acc: 0.8728\n",
      "Epoch 971/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1011 - acc: 0.9686 - val_loss: 0.8908 - val_acc: 0.8719\n",
      "Epoch 972/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0924 - acc: 0.9715 - val_loss: 0.8748 - val_acc: 0.8758\n",
      "Epoch 973/1000\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.0860 - acc: 0.9740 - val_loss: 0.8921 - val_acc: 0.8749\n",
      "Epoch 974/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0885 - acc: 0.9741 - val_loss: 0.8898 - val_acc: 0.8738\n",
      "Epoch 975/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0960 - acc: 0.9699 - val_loss: 0.9001 - val_acc: 0.8746\n",
      "Epoch 976/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0945 - acc: 0.9704 - val_loss: 0.9296 - val_acc: 0.8666\n",
      "Epoch 977/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0830 - acc: 0.9760 - val_loss: 0.8972 - val_acc: 0.8714\n",
      "Epoch 978/1000\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0941 - acc: 0.9707 - val_loss: 0.8899 - val_acc: 0.8738\n",
      "Epoch 979/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0932 - acc: 0.9712 - val_loss: 0.9102 - val_acc: 0.8713\n",
      "Epoch 980/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0897 - acc: 0.9736 - val_loss: 0.8880 - val_acc: 0.8732\n",
      "Epoch 981/1000\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0919 - acc: 0.9720 - val_loss: 0.9181 - val_acc: 0.8727\n",
      "Epoch 982/1000\n",
      "34108/34108 [==============================] - 1s 19us/step - loss: 0.0847 - acc: 0.9753 - val_loss: 0.9069 - val_acc: 0.8731\n",
      "Epoch 983/1000\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0915 - acc: 0.9723 - val_loss: 0.9017 - val_acc: 0.8756\n",
      "Epoch 984/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0880 - acc: 0.9740 - val_loss: 0.8842 - val_acc: 0.8751\n",
      "Epoch 985/1000\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0880 - acc: 0.9736 - val_loss: 0.8980 - val_acc: 0.8750\n",
      "Epoch 986/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.0921 - acc: 0.9713 - val_loss: 0.8916 - val_acc: 0.8753\n",
      "Epoch 987/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.0875 - acc: 0.9735 - val_loss: 0.8959 - val_acc: 0.8733\n",
      "Epoch 988/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.0925 - acc: 0.9717 - val_loss: 0.9029 - val_acc: 0.8710\n",
      "Epoch 989/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.0867 - acc: 0.9744 - val_loss: 0.9088 - val_acc: 0.8706\n",
      "Epoch 990/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.0896 - acc: 0.9724 - val_loss: 0.9095 - val_acc: 0.8728\n",
      "Epoch 991/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.0883 - acc: 0.9733 - val_loss: 0.8926 - val_acc: 0.8750\n",
      "Epoch 992/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.0877 - acc: 0.9737 - val_loss: 0.9008 - val_acc: 0.8729\n",
      "Epoch 993/1000\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.0868 - acc: 0.9738 - val_loss: 0.9074 - val_acc: 0.8736\n",
      "Epoch 994/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.0882 - acc: 0.9736 - val_loss: 0.9090 - val_acc: 0.8705\n",
      "Epoch 995/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.0986 - acc: 0.9693 - val_loss: 0.9087 - val_acc: 0.8738\n",
      "Epoch 996/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.0866 - acc: 0.9734 - val_loss: 0.8821 - val_acc: 0.8741\n",
      "Epoch 997/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.0873 - acc: 0.9729 - val_loss: 0.8989 - val_acc: 0.8744\n",
      "Epoch 998/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.0921 - acc: 0.9721 - val_loss: 0.8867 - val_acc: 0.8771\n",
      "Epoch 999/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.0858 - acc: 0.9746 - val_loss: 0.8929 - val_acc: 0.8746\n",
      "Epoch 1000/1000\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.0916 - acc: 0.9713 - val_loss: 0.8916 - val_acc: 0.8743\n"
     ]
    }
   ],
   "source": [
    "history = model_2.fit(x_train, y_train,\n",
    "           batch_size= 128,\n",
    "           epochs=1000,\n",
    "           verbose=1,\n",
    "           validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEdCAYAAABZtfMGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWPOzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x183030eba8>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEdCAYAAABZtfMGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWPOzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x183030eba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history,\"Overfit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1**: At which epoch (approximately) does the model start to overfit? Please answer with one full sentence.\n",
    "\n",
    "**Answer**: \n",
    "\n",
    "**Question 2**: Explain the qualitative difference between the loss curves and the accuracy curves with respect to signs of overfitting. Please answer with at most 3 full sentences.\n",
    "\n",
    "**Answer**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Model performance as a function of number of hidden neurons\n",
    "\n",
    "### Description\n",
    "\n",
    "Investigate how the best validation loss and accuracy depends on the number of hidden neurons in a single layer.\n",
    "\n",
    "1. Fit a reasonable number of models with different hidden layer size (between 10 and 1000 hidden neurons) for a fixed number of epochs well beyond the point of overfitting.\n",
    "2. Collect some statistics by fitting the same models as in 1. for multiple initial conditions. Hints: 1. If you don't reset the random seed, you get different initial conditions each time you create a new model. 2. Let your computer work while you are asleep.\n",
    "3. Plot summary statistics of the final validation loss and accuracy versus the number of hidden neurons. Hint: [boxplots](https://matplotlib.org/examples/pylab_examples/boxplot_demo.html) (also [here](https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.boxplot.html?highlight=boxplot#matplotlib.axes.Axes.boxplot)) are useful. You may also want to use the matplotlib method set_xticklabels.\n",
    "4. Plot summary statistics of the loss and accuracy for early stopping versus the number of hidden neurons.\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34108 samples, validate on 12117 samples\n",
      "Epoch 1/500\n",
      "34108/34108 [==============================] - 1s 23us/step - loss: 1.5049 - acc: 0.4036 - val_loss: 1.4223 - val_acc: 0.4348\n",
      "Epoch 2/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 1.3788 - acc: 0.4442 - val_loss: 1.2664 - val_acc: 0.4990\n",
      "Epoch 3/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 1.2497 - acc: 0.5025 - val_loss: 1.1573 - val_acc: 0.5651\n",
      "Epoch 4/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 1.1517 - acc: 0.5508 - val_loss: 1.0809 - val_acc: 0.5942\n",
      "Epoch 5/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 1.0852 - acc: 0.5938 - val_loss: 1.0438 - val_acc: 0.6227\n",
      "Epoch 6/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 1.0363 - acc: 0.6196 - val_loss: 1.0076 - val_acc: 0.6502\n",
      "Epoch 7/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.9994 - acc: 0.6384 - val_loss: 0.9757 - val_acc: 0.6580\n",
      "Epoch 8/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.9707 - acc: 0.6502 - val_loss: 0.9619 - val_acc: 0.6602\n",
      "Epoch 9/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.9497 - acc: 0.6598 - val_loss: 0.9500 - val_acc: 0.6675\n",
      "Epoch 10/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.9322 - acc: 0.6679 - val_loss: 0.9457 - val_acc: 0.6768\n",
      "Epoch 11/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.9203 - acc: 0.6759 - val_loss: 0.9354 - val_acc: 0.6795\n",
      "Epoch 12/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.9082 - acc: 0.6797 - val_loss: 0.9263 - val_acc: 0.6780\n",
      "Epoch 13/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.8984 - acc: 0.6834 - val_loss: 0.9306 - val_acc: 0.6848\n",
      "Epoch 14/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.8902 - acc: 0.6884 - val_loss: 0.9208 - val_acc: 0.6831\n",
      "Epoch 15/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.8812 - acc: 0.6923 - val_loss: 0.9094 - val_acc: 0.6887\n",
      "Epoch 16/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.8747 - acc: 0.6953 - val_loss: 0.9121 - val_acc: 0.6943\n",
      "Epoch 17/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.8692 - acc: 0.6966 - val_loss: 0.9010 - val_acc: 0.6903\n",
      "Epoch 18/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.8641 - acc: 0.7018 - val_loss: 0.8995 - val_acc: 0.6929\n",
      "Epoch 19/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.8593 - acc: 0.7024 - val_loss: 0.9079 - val_acc: 0.6923\n",
      "Epoch 20/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.8551 - acc: 0.7034 - val_loss: 0.9087 - val_acc: 0.6931\n",
      "Epoch 21/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.8516 - acc: 0.7061 - val_loss: 0.8960 - val_acc: 0.6960\n",
      "Epoch 22/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.8468 - acc: 0.7076 - val_loss: 0.8928 - val_acc: 0.6995\n",
      "Epoch 23/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.8436 - acc: 0.7088 - val_loss: 0.8925 - val_acc: 0.7012\n",
      "Epoch 24/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.8410 - acc: 0.7100 - val_loss: 0.8897 - val_acc: 0.7007\n",
      "Epoch 25/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.8368 - acc: 0.7109 - val_loss: 0.8857 - val_acc: 0.7028\n",
      "Epoch 26/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.8334 - acc: 0.7114 - val_loss: 0.8875 - val_acc: 0.6997\n",
      "Epoch 27/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.8327 - acc: 0.7135 - val_loss: 0.8896 - val_acc: 0.7037\n",
      "Epoch 28/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.8284 - acc: 0.7154 - val_loss: 0.8896 - val_acc: 0.7005\n",
      "Epoch 29/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.8264 - acc: 0.7168 - val_loss: 0.8867 - val_acc: 0.7057\n",
      "Epoch 30/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.8234 - acc: 0.7172 - val_loss: 0.8856 - val_acc: 0.7037\n",
      "Epoch 31/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.8207 - acc: 0.7200 - val_loss: 0.8797 - val_acc: 0.7088\n",
      "Epoch 32/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.8154 - acc: 0.7234 - val_loss: 0.8827 - val_acc: 0.7083\n",
      "Epoch 33/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.8114 - acc: 0.7261 - val_loss: 0.8777 - val_acc: 0.7125\n",
      "Epoch 34/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.8062 - acc: 0.7314 - val_loss: 0.8742 - val_acc: 0.7161\n",
      "Epoch 35/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.8011 - acc: 0.7341 - val_loss: 0.8623 - val_acc: 0.7219\n",
      "Epoch 36/500\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.7969 - acc: 0.7373 - val_loss: 0.8553 - val_acc: 0.7225\n",
      "Epoch 37/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7914 - acc: 0.7404 - val_loss: 0.8547 - val_acc: 0.7245\n",
      "Epoch 38/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7877 - acc: 0.7415 - val_loss: 0.8543 - val_acc: 0.7295\n",
      "Epoch 39/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7833 - acc: 0.7451 - val_loss: 0.8440 - val_acc: 0.7331\n",
      "Epoch 40/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7817 - acc: 0.7461 - val_loss: 0.8418 - val_acc: 0.7341\n",
      "Epoch 41/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7752 - acc: 0.7491 - val_loss: 0.8445 - val_acc: 0.7346\n",
      "Epoch 42/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7728 - acc: 0.7499 - val_loss: 0.8357 - val_acc: 0.7380\n",
      "Epoch 43/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7696 - acc: 0.7516 - val_loss: 0.8396 - val_acc: 0.7361\n",
      "Epoch 44/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7656 - acc: 0.7542 - val_loss: 0.8377 - val_acc: 0.7368\n",
      "Epoch 45/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7638 - acc: 0.7553 - val_loss: 0.8301 - val_acc: 0.7404\n",
      "Epoch 46/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7620 - acc: 0.7543 - val_loss: 0.8378 - val_acc: 0.7409\n",
      "Epoch 47/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7588 - acc: 0.7575 - val_loss: 0.8283 - val_acc: 0.7437\n",
      "Epoch 48/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7580 - acc: 0.7573 - val_loss: 0.8628 - val_acc: 0.7329\n",
      "Epoch 49/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7560 - acc: 0.7585 - val_loss: 0.8309 - val_acc: 0.7443\n",
      "Epoch 50/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7523 - acc: 0.7600 - val_loss: 0.8294 - val_acc: 0.7406\n",
      "Epoch 51/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7509 - acc: 0.7619 - val_loss: 0.8261 - val_acc: 0.7449\n",
      "Epoch 52/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7486 - acc: 0.7611 - val_loss: 0.8193 - val_acc: 0.7458\n",
      "Epoch 53/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7467 - acc: 0.7634 - val_loss: 0.8257 - val_acc: 0.7435\n",
      "Epoch 54/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7458 - acc: 0.7617 - val_loss: 0.8181 - val_acc: 0.7486\n",
      "Epoch 55/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7423 - acc: 0.7650 - val_loss: 0.8246 - val_acc: 0.7476\n",
      "Epoch 56/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7413 - acc: 0.7638 - val_loss: 0.8193 - val_acc: 0.7473\n",
      "Epoch 57/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7402 - acc: 0.7647 - val_loss: 0.8208 - val_acc: 0.7459\n",
      "Epoch 58/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7389 - acc: 0.7647 - val_loss: 0.8160 - val_acc: 0.7485\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.7385 - acc: 0.7664 - val_loss: 0.8248 - val_acc: 0.7461\n",
      "Epoch 60/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7366 - acc: 0.7648 - val_loss: 0.8178 - val_acc: 0.7484\n",
      "Epoch 61/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.7350 - acc: 0.7661 - val_loss: 0.8276 - val_acc: 0.7436\n",
      "Epoch 62/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.7353 - acc: 0.7670 - val_loss: 0.8253 - val_acc: 0.7466\n",
      "Epoch 63/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7331 - acc: 0.7675 - val_loss: 0.8201 - val_acc: 0.7453\n",
      "Epoch 64/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.7320 - acc: 0.7676 - val_loss: 0.8193 - val_acc: 0.7477\n",
      "Epoch 65/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7318 - acc: 0.7686 - val_loss: 0.8138 - val_acc: 0.7484\n",
      "Epoch 66/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7306 - acc: 0.7687 - val_loss: 0.8128 - val_acc: 0.7496\n",
      "Epoch 67/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.7284 - acc: 0.7695 - val_loss: 0.8103 - val_acc: 0.7500\n",
      "Epoch 68/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7273 - acc: 0.7706 - val_loss: 0.8194 - val_acc: 0.7490\n",
      "Epoch 69/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.7270 - acc: 0.7708 - val_loss: 0.8104 - val_acc: 0.7504\n",
      "Epoch 70/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.7249 - acc: 0.7711 - val_loss: 0.8052 - val_acc: 0.7531\n",
      "Epoch 71/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7263 - acc: 0.7706 - val_loss: 0.8132 - val_acc: 0.7504\n",
      "Epoch 72/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7238 - acc: 0.7696 - val_loss: 0.8065 - val_acc: 0.7533\n",
      "Epoch 73/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7223 - acc: 0.7701 - val_loss: 0.8103 - val_acc: 0.7527\n",
      "Epoch 74/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7215 - acc: 0.7713 - val_loss: 0.8131 - val_acc: 0.7494\n",
      "Epoch 75/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7212 - acc: 0.7716 - val_loss: 0.8179 - val_acc: 0.7473\n",
      "Epoch 76/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.7213 - acc: 0.7722 - val_loss: 0.8077 - val_acc: 0.7523\n",
      "Epoch 77/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7201 - acc: 0.7735 - val_loss: 0.8084 - val_acc: 0.7531\n",
      "Epoch 78/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.7200 - acc: 0.7733 - val_loss: 0.8045 - val_acc: 0.7532\n",
      "Epoch 79/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.7171 - acc: 0.7740 - val_loss: 0.8071 - val_acc: 0.7518\n",
      "Epoch 80/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7162 - acc: 0.7734 - val_loss: 0.8119 - val_acc: 0.7509\n",
      "Epoch 81/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7157 - acc: 0.7735 - val_loss: 0.8110 - val_acc: 0.7513\n",
      "Epoch 82/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7153 - acc: 0.7742 - val_loss: 0.8086 - val_acc: 0.7530\n",
      "Epoch 83/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7139 - acc: 0.7742 - val_loss: 0.8022 - val_acc: 0.7527\n",
      "Epoch 84/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7134 - acc: 0.7754 - val_loss: 0.8089 - val_acc: 0.7527\n",
      "Epoch 85/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7129 - acc: 0.7742 - val_loss: 0.8074 - val_acc: 0.7546\n",
      "Epoch 86/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7116 - acc: 0.7748 - val_loss: 0.8008 - val_acc: 0.7535\n",
      "Epoch 87/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7099 - acc: 0.7759 - val_loss: 0.8071 - val_acc: 0.7535\n",
      "Epoch 88/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7091 - acc: 0.7763 - val_loss: 0.8071 - val_acc: 0.7530\n",
      "Epoch 89/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.7123 - acc: 0.7762 - val_loss: 0.8079 - val_acc: 0.7531\n",
      "Epoch 90/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7084 - acc: 0.7754 - val_loss: 0.8086 - val_acc: 0.7553\n",
      "Epoch 91/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7081 - acc: 0.7766 - val_loss: 0.8062 - val_acc: 0.7527\n",
      "Epoch 92/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7081 - acc: 0.7769 - val_loss: 0.8145 - val_acc: 0.7514\n",
      "Epoch 93/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7084 - acc: 0.7758 - val_loss: 0.8149 - val_acc: 0.7510\n",
      "Epoch 94/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7074 - acc: 0.7765 - val_loss: 0.8002 - val_acc: 0.7556\n",
      "Epoch 95/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.7068 - acc: 0.7766 - val_loss: 0.8102 - val_acc: 0.7536\n",
      "Epoch 96/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7049 - acc: 0.7785 - val_loss: 0.8059 - val_acc: 0.7561\n",
      "Epoch 97/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7049 - acc: 0.7777 - val_loss: 0.8062 - val_acc: 0.7573\n",
      "Epoch 98/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7070 - acc: 0.7756 - val_loss: 0.8084 - val_acc: 0.7551\n",
      "Epoch 99/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7050 - acc: 0.7769 - val_loss: 0.8023 - val_acc: 0.7561\n",
      "Epoch 100/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7043 - acc: 0.7767 - val_loss: 0.8041 - val_acc: 0.7547\n",
      "Epoch 101/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7056 - acc: 0.7770 - val_loss: 0.8080 - val_acc: 0.7565\n",
      "Epoch 102/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7053 - acc: 0.7779 - val_loss: 0.8086 - val_acc: 0.7572\n",
      "Epoch 103/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7016 - acc: 0.7771 - val_loss: 0.8085 - val_acc: 0.7575\n",
      "Epoch 104/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7023 - acc: 0.7789 - val_loss: 0.8057 - val_acc: 0.7567\n",
      "Epoch 105/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6995 - acc: 0.7804 - val_loss: 0.7978 - val_acc: 0.7588\n",
      "Epoch 106/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7002 - acc: 0.7787 - val_loss: 0.8087 - val_acc: 0.7575\n",
      "Epoch 107/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7006 - acc: 0.7786 - val_loss: 0.8007 - val_acc: 0.7572\n",
      "Epoch 108/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6996 - acc: 0.7799 - val_loss: 0.8039 - val_acc: 0.7589\n",
      "Epoch 109/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6994 - acc: 0.7791 - val_loss: 0.7986 - val_acc: 0.7590\n",
      "Epoch 110/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6971 - acc: 0.7804 - val_loss: 0.8015 - val_acc: 0.7562\n",
      "Epoch 111/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.7001 - acc: 0.7783 - val_loss: 0.8026 - val_acc: 0.7575\n",
      "Epoch 112/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6974 - acc: 0.7796 - val_loss: 0.8112 - val_acc: 0.7560\n",
      "Epoch 113/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6962 - acc: 0.7795 - val_loss: 0.7993 - val_acc: 0.7567\n",
      "Epoch 114/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6958 - acc: 0.7787 - val_loss: 0.7970 - val_acc: 0.7586\n",
      "Epoch 115/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6968 - acc: 0.7794 - val_loss: 0.8049 - val_acc: 0.7565\n",
      "Epoch 116/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6980 - acc: 0.7784 - val_loss: 0.8042 - val_acc: 0.7590\n",
      "Epoch 117/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6985 - acc: 0.7800 - val_loss: 0.8042 - val_acc: 0.7599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6948 - acc: 0.7801 - val_loss: 0.8064 - val_acc: 0.7584\n",
      "Epoch 119/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6957 - acc: 0.7793 - val_loss: 0.8029 - val_acc: 0.7573\n",
      "Epoch 120/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6962 - acc: 0.7798 - val_loss: 0.7946 - val_acc: 0.7611\n",
      "Epoch 121/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6946 - acc: 0.7795 - val_loss: 0.8011 - val_acc: 0.7593\n",
      "Epoch 122/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6937 - acc: 0.7806 - val_loss: 0.8091 - val_acc: 0.7554\n",
      "Epoch 123/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6950 - acc: 0.7804 - val_loss: 0.8055 - val_acc: 0.7584\n",
      "Epoch 124/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6924 - acc: 0.7806 - val_loss: 0.7981 - val_acc: 0.7589\n",
      "Epoch 125/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6933 - acc: 0.7807 - val_loss: 0.8007 - val_acc: 0.7591\n",
      "Epoch 126/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6927 - acc: 0.7804 - val_loss: 0.8107 - val_acc: 0.7560\n",
      "Epoch 127/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6920 - acc: 0.7810 - val_loss: 0.8050 - val_acc: 0.7592\n",
      "Epoch 128/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6915 - acc: 0.7802 - val_loss: 0.8020 - val_acc: 0.7574\n",
      "Epoch 129/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6919 - acc: 0.7809 - val_loss: 0.7964 - val_acc: 0.7593\n",
      "Epoch 130/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6901 - acc: 0.7820 - val_loss: 0.8033 - val_acc: 0.7590\n",
      "Epoch 131/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6928 - acc: 0.7791 - val_loss: 0.8036 - val_acc: 0.7599\n",
      "Epoch 132/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6899 - acc: 0.7813 - val_loss: 0.8063 - val_acc: 0.7582\n",
      "Epoch 133/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6897 - acc: 0.7810 - val_loss: 0.8170 - val_acc: 0.7550\n",
      "Epoch 134/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6888 - acc: 0.7825 - val_loss: 0.8020 - val_acc: 0.7589\n",
      "Epoch 135/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6882 - acc: 0.7825 - val_loss: 0.8091 - val_acc: 0.7579\n",
      "Epoch 136/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6876 - acc: 0.7825 - val_loss: 0.8027 - val_acc: 0.7599\n",
      "Epoch 137/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6899 - acc: 0.7819 - val_loss: 0.8221 - val_acc: 0.7542\n",
      "Epoch 138/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6888 - acc: 0.7801 - val_loss: 0.8085 - val_acc: 0.7597\n",
      "Epoch 139/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6877 - acc: 0.7821 - val_loss: 0.8057 - val_acc: 0.7607\n",
      "Epoch 140/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6881 - acc: 0.7830 - val_loss: 0.8008 - val_acc: 0.7596\n",
      "Epoch 141/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6876 - acc: 0.7825 - val_loss: 0.8104 - val_acc: 0.7577\n",
      "Epoch 142/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6864 - acc: 0.7839 - val_loss: 0.7975 - val_acc: 0.7583\n",
      "Epoch 143/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6856 - acc: 0.7824 - val_loss: 0.7973 - val_acc: 0.7610\n",
      "Epoch 144/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6875 - acc: 0.7823 - val_loss: 0.8033 - val_acc: 0.7599\n",
      "Epoch 145/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6870 - acc: 0.7813 - val_loss: 0.8018 - val_acc: 0.7596\n",
      "Epoch 146/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6865 - acc: 0.7832 - val_loss: 0.8052 - val_acc: 0.7584\n",
      "Epoch 147/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6858 - acc: 0.7823 - val_loss: 0.8076 - val_acc: 0.7594\n",
      "Epoch 148/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6862 - acc: 0.7828 - val_loss: 0.8004 - val_acc: 0.7626\n",
      "Epoch 149/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6845 - acc: 0.7826 - val_loss: 0.8003 - val_acc: 0.7597\n",
      "Epoch 150/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6831 - acc: 0.7823 - val_loss: 0.7979 - val_acc: 0.7611\n",
      "Epoch 151/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6836 - acc: 0.7841 - val_loss: 0.8013 - val_acc: 0.7595\n",
      "Epoch 152/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6847 - acc: 0.7835 - val_loss: 0.8026 - val_acc: 0.7603\n",
      "Epoch 153/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6837 - acc: 0.7832 - val_loss: 0.8048 - val_acc: 0.7609\n",
      "Epoch 154/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6828 - acc: 0.7837 - val_loss: 0.7976 - val_acc: 0.7619\n",
      "Epoch 155/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6844 - acc: 0.7818 - val_loss: 0.8028 - val_acc: 0.7624\n",
      "Epoch 156/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6832 - acc: 0.7831 - val_loss: 0.8025 - val_acc: 0.7598\n",
      "Epoch 157/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6836 - acc: 0.7830 - val_loss: 0.8149 - val_acc: 0.7575\n",
      "Epoch 158/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6827 - acc: 0.7837 - val_loss: 0.8064 - val_acc: 0.7612\n",
      "Epoch 159/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6813 - acc: 0.7847 - val_loss: 0.8092 - val_acc: 0.7589\n",
      "Epoch 160/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6818 - acc: 0.7837 - val_loss: 0.8028 - val_acc: 0.7631\n",
      "Epoch 161/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6825 - acc: 0.7838 - val_loss: 0.8066 - val_acc: 0.7612\n",
      "Epoch 162/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6824 - acc: 0.7828 - val_loss: 0.8120 - val_acc: 0.7574\n",
      "Epoch 163/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6816 - acc: 0.7839 - val_loss: 0.7998 - val_acc: 0.7620\n",
      "Epoch 164/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6813 - acc: 0.7829 - val_loss: 0.8090 - val_acc: 0.7570\n",
      "Epoch 165/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6819 - acc: 0.7845 - val_loss: 0.8032 - val_acc: 0.7617\n",
      "Epoch 166/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6826 - acc: 0.7846 - val_loss: 0.7970 - val_acc: 0.7624\n",
      "Epoch 167/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6806 - acc: 0.7849 - val_loss: 0.8030 - val_acc: 0.7593\n",
      "Epoch 168/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6796 - acc: 0.7840 - val_loss: 0.8015 - val_acc: 0.7617\n",
      "Epoch 169/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6801 - acc: 0.7832 - val_loss: 0.8058 - val_acc: 0.7612\n",
      "Epoch 170/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6804 - acc: 0.7839 - val_loss: 0.8021 - val_acc: 0.7619\n",
      "Epoch 171/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6798 - acc: 0.7832 - val_loss: 0.8062 - val_acc: 0.7595\n",
      "Epoch 172/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6815 - acc: 0.7830 - val_loss: 0.8201 - val_acc: 0.7529\n",
      "Epoch 173/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6795 - acc: 0.7842 - val_loss: 0.8083 - val_acc: 0.7589\n",
      "Epoch 174/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6817 - acc: 0.7836 - val_loss: 0.8024 - val_acc: 0.7607\n",
      "Epoch 175/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6801 - acc: 0.7847 - val_loss: 0.8082 - val_acc: 0.7603\n",
      "Epoch 176/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6788 - acc: 0.7848 - val_loss: 0.8079 - val_acc: 0.7603\n",
      "Epoch 177/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6770 - acc: 0.7848 - val_loss: 0.8049 - val_acc: 0.7585\n",
      "Epoch 178/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6789 - acc: 0.7844 - val_loss: 0.8058 - val_acc: 0.7621\n",
      "Epoch 179/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6776 - acc: 0.7840 - val_loss: 0.8078 - val_acc: 0.7601\n",
      "Epoch 180/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6782 - acc: 0.7841 - val_loss: 0.8058 - val_acc: 0.7560\n",
      "Epoch 181/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6768 - acc: 0.7839 - val_loss: 0.8063 - val_acc: 0.7607\n",
      "Epoch 182/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6784 - acc: 0.7850 - val_loss: 0.8069 - val_acc: 0.7612\n",
      "Epoch 183/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6772 - acc: 0.7852 - val_loss: 0.8061 - val_acc: 0.7567\n",
      "Epoch 184/500\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.6769 - acc: 0.7852 - val_loss: 0.7990 - val_acc: 0.7622\n",
      "Epoch 185/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6771 - acc: 0.7847 - val_loss: 0.8009 - val_acc: 0.7617\n",
      "Epoch 186/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6759 - acc: 0.7856 - val_loss: 0.8065 - val_acc: 0.7608\n",
      "Epoch 187/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6754 - acc: 0.7849 - val_loss: 0.8077 - val_acc: 0.7595\n",
      "Epoch 188/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6771 - acc: 0.7859 - val_loss: 0.8107 - val_acc: 0.7614\n",
      "Epoch 189/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6758 - acc: 0.7861 - val_loss: 0.8120 - val_acc: 0.7584\n",
      "Epoch 190/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6762 - acc: 0.7842 - val_loss: 0.8033 - val_acc: 0.7609\n",
      "Epoch 191/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6741 - acc: 0.7853 - val_loss: 0.8000 - val_acc: 0.7638\n",
      "Epoch 192/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6766 - acc: 0.7854 - val_loss: 0.7968 - val_acc: 0.7626\n",
      "Epoch 193/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6756 - acc: 0.7854 - val_loss: 0.7971 - val_acc: 0.7644\n",
      "Epoch 194/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6755 - acc: 0.7861 - val_loss: 0.8102 - val_acc: 0.7568\n",
      "Epoch 195/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6766 - acc: 0.7854 - val_loss: 0.8040 - val_acc: 0.7625\n",
      "Epoch 196/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6737 - acc: 0.7854 - val_loss: 0.8017 - val_acc: 0.7631\n",
      "Epoch 197/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6753 - acc: 0.7853 - val_loss: 0.8002 - val_acc: 0.7642\n",
      "Epoch 198/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6731 - acc: 0.7873 - val_loss: 0.8062 - val_acc: 0.7617\n",
      "Epoch 199/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6736 - acc: 0.7855 - val_loss: 0.8041 - val_acc: 0.7632\n",
      "Epoch 200/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6721 - acc: 0.7872 - val_loss: 0.8008 - val_acc: 0.7634\n",
      "Epoch 201/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6729 - acc: 0.7868 - val_loss: 0.8055 - val_acc: 0.7633\n",
      "Epoch 202/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6730 - acc: 0.7867 - val_loss: 0.7977 - val_acc: 0.7640\n",
      "Epoch 203/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6730 - acc: 0.7871 - val_loss: 0.7966 - val_acc: 0.7644\n",
      "Epoch 204/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6736 - acc: 0.7863 - val_loss: 0.7964 - val_acc: 0.7648\n",
      "Epoch 205/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6720 - acc: 0.7856 - val_loss: 0.8552 - val_acc: 0.7471\n",
      "Epoch 206/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6736 - acc: 0.7852 - val_loss: 0.8028 - val_acc: 0.7621\n",
      "Epoch 207/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6721 - acc: 0.7858 - val_loss: 0.8080 - val_acc: 0.7615\n",
      "Epoch 208/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6741 - acc: 0.7855 - val_loss: 0.8031 - val_acc: 0.7625\n",
      "Epoch 209/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6700 - acc: 0.7871 - val_loss: 0.8128 - val_acc: 0.7579\n",
      "Epoch 210/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6730 - acc: 0.7852 - val_loss: 0.8129 - val_acc: 0.7596\n",
      "Epoch 211/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6720 - acc: 0.7861 - val_loss: 0.8067 - val_acc: 0.7621\n",
      "Epoch 212/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6725 - acc: 0.7858 - val_loss: 0.8046 - val_acc: 0.7617\n",
      "Epoch 213/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6707 - acc: 0.7869 - val_loss: 0.8063 - val_acc: 0.7598\n",
      "Epoch 214/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6722 - acc: 0.7858 - val_loss: 0.8150 - val_acc: 0.7564\n",
      "Epoch 215/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6723 - acc: 0.7857 - val_loss: 0.8027 - val_acc: 0.7614\n",
      "Epoch 216/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6727 - acc: 0.7868 - val_loss: 0.8040 - val_acc: 0.7610\n",
      "Epoch 217/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6713 - acc: 0.7864 - val_loss: 0.8032 - val_acc: 0.7616\n",
      "Epoch 218/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6686 - acc: 0.7877 - val_loss: 0.8039 - val_acc: 0.7645\n",
      "Epoch 219/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6709 - acc: 0.7875 - val_loss: 0.8059 - val_acc: 0.7612\n",
      "Epoch 220/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6729 - acc: 0.7863 - val_loss: 0.8016 - val_acc: 0.7628\n",
      "Epoch 221/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6709 - acc: 0.7870 - val_loss: 0.8022 - val_acc: 0.7646\n",
      "Epoch 222/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6701 - acc: 0.7871 - val_loss: 0.8055 - val_acc: 0.7598\n",
      "Epoch 223/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6698 - acc: 0.7864 - val_loss: 0.8016 - val_acc: 0.7603\n",
      "Epoch 224/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6683 - acc: 0.7881 - val_loss: 0.8007 - val_acc: 0.7628\n",
      "Epoch 225/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6715 - acc: 0.7864 - val_loss: 0.8074 - val_acc: 0.7615\n",
      "Epoch 226/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6688 - acc: 0.7870 - val_loss: 0.8058 - val_acc: 0.7629\n",
      "Epoch 227/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6688 - acc: 0.7864 - val_loss: 0.8034 - val_acc: 0.7628\n",
      "Epoch 228/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6700 - acc: 0.7866 - val_loss: 0.8136 - val_acc: 0.7577\n",
      "Epoch 229/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6698 - acc: 0.7869 - val_loss: 0.8018 - val_acc: 0.7649\n",
      "Epoch 230/500\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.6683 - acc: 0.7871 - val_loss: 0.7998 - val_acc: 0.7634\n",
      "Epoch 231/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6691 - acc: 0.7882 - val_loss: 0.8025 - val_acc: 0.7635\n",
      "Epoch 232/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6676 - acc: 0.7879 - val_loss: 0.8032 - val_acc: 0.7627\n",
      "Epoch 233/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6678 - acc: 0.7888 - val_loss: 0.8015 - val_acc: 0.7643\n",
      "Epoch 234/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6695 - acc: 0.7867 - val_loss: 0.8075 - val_acc: 0.7603\n",
      "Epoch 235/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6668 - acc: 0.7880 - val_loss: 0.8027 - val_acc: 0.7617\n",
      "Epoch 236/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6683 - acc: 0.7876 - val_loss: 0.8011 - val_acc: 0.7636\n",
      "Epoch 237/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6667 - acc: 0.7878 - val_loss: 0.8100 - val_acc: 0.7598\n",
      "Epoch 238/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6674 - acc: 0.7892 - val_loss: 0.8025 - val_acc: 0.7641\n",
      "Epoch 239/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6672 - acc: 0.7883 - val_loss: 0.8059 - val_acc: 0.7656\n",
      "Epoch 240/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6681 - acc: 0.7871 - val_loss: 0.8140 - val_acc: 0.7584\n",
      "Epoch 241/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6653 - acc: 0.7882 - val_loss: 0.8002 - val_acc: 0.7629\n",
      "Epoch 242/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6668 - acc: 0.7869 - val_loss: 0.8009 - val_acc: 0.7647\n",
      "Epoch 243/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6674 - acc: 0.7884 - val_loss: 0.7976 - val_acc: 0.7658\n",
      "Epoch 244/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6651 - acc: 0.7886 - val_loss: 0.8044 - val_acc: 0.7645\n",
      "Epoch 245/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6645 - acc: 0.7887 - val_loss: 0.8051 - val_acc: 0.7620\n",
      "Epoch 246/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6679 - acc: 0.7870 - val_loss: 0.8122 - val_acc: 0.7611\n",
      "Epoch 247/500\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.6667 - acc: 0.7870 - val_loss: 0.8023 - val_acc: 0.7659\n",
      "Epoch 248/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6647 - acc: 0.7880 - val_loss: 0.8090 - val_acc: 0.7595\n",
      "Epoch 249/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6648 - acc: 0.7890 - val_loss: 0.8047 - val_acc: 0.7633\n",
      "Epoch 250/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6669 - acc: 0.7868 - val_loss: 0.8034 - val_acc: 0.7618\n",
      "Epoch 251/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6659 - acc: 0.7878 - val_loss: 0.8010 - val_acc: 0.7644\n",
      "Epoch 252/500\n",
      "34108/34108 [==============================] - 0s 12us/step - loss: 0.6652 - acc: 0.7873 - val_loss: 0.8019 - val_acc: 0.7645\n",
      "Epoch 253/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6644 - acc: 0.7871 - val_loss: 0.8129 - val_acc: 0.7618\n",
      "Epoch 254/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6658 - acc: 0.7876 - val_loss: 0.8189 - val_acc: 0.7582\n",
      "Epoch 255/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6653 - acc: 0.7874 - val_loss: 0.8112 - val_acc: 0.7613\n",
      "Epoch 256/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6629 - acc: 0.7886 - val_loss: 0.8128 - val_acc: 0.7601\n",
      "Epoch 257/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6654 - acc: 0.7873 - val_loss: 0.8163 - val_acc: 0.7570\n",
      "Epoch 258/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6644 - acc: 0.7875 - val_loss: 0.8108 - val_acc: 0.7601\n",
      "Epoch 259/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6649 - acc: 0.7871 - val_loss: 0.8131 - val_acc: 0.7598\n",
      "Epoch 260/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6644 - acc: 0.7883 - val_loss: 0.8052 - val_acc: 0.7643\n",
      "Epoch 261/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6656 - acc: 0.7871 - val_loss: 0.7993 - val_acc: 0.7648\n",
      "Epoch 262/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6630 - acc: 0.7891 - val_loss: 0.8076 - val_acc: 0.7623\n",
      "Epoch 263/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6629 - acc: 0.7896 - val_loss: 0.8190 - val_acc: 0.7598\n",
      "Epoch 264/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6633 - acc: 0.7876 - val_loss: 0.8153 - val_acc: 0.7584\n",
      "Epoch 265/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6633 - acc: 0.7892 - val_loss: 0.7983 - val_acc: 0.7643\n",
      "Epoch 266/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6626 - acc: 0.7891 - val_loss: 0.7981 - val_acc: 0.7664\n",
      "Epoch 267/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6609 - acc: 0.7880 - val_loss: 0.7983 - val_acc: 0.7648\n",
      "Epoch 268/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6616 - acc: 0.7894 - val_loss: 0.8057 - val_acc: 0.7614\n",
      "Epoch 269/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6624 - acc: 0.7887 - val_loss: 0.8164 - val_acc: 0.7614\n",
      "Epoch 270/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6621 - acc: 0.7890 - val_loss: 0.8048 - val_acc: 0.7650\n",
      "Epoch 271/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6614 - acc: 0.7900 - val_loss: 0.8081 - val_acc: 0.7622\n",
      "Epoch 272/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6600 - acc: 0.7871 - val_loss: 0.8004 - val_acc: 0.7645\n",
      "Epoch 273/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6621 - acc: 0.7891 - val_loss: 0.8148 - val_acc: 0.7634\n",
      "Epoch 274/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6615 - acc: 0.7897 - val_loss: 0.8070 - val_acc: 0.7611\n",
      "Epoch 275/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6618 - acc: 0.7892 - val_loss: 0.8028 - val_acc: 0.7635\n",
      "Epoch 276/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6612 - acc: 0.7900 - val_loss: 0.7992 - val_acc: 0.7645\n",
      "Epoch 277/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6590 - acc: 0.7894 - val_loss: 0.8110 - val_acc: 0.7607\n",
      "Epoch 278/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6617 - acc: 0.7883 - val_loss: 0.7968 - val_acc: 0.7648\n",
      "Epoch 279/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6610 - acc: 0.7883 - val_loss: 0.7976 - val_acc: 0.7654\n",
      "Epoch 280/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6613 - acc: 0.7885 - val_loss: 0.8031 - val_acc: 0.7659\n",
      "Epoch 281/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6609 - acc: 0.7891 - val_loss: 0.8132 - val_acc: 0.7574\n",
      "Epoch 282/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6606 - acc: 0.7884 - val_loss: 0.8173 - val_acc: 0.7588\n",
      "Epoch 283/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6608 - acc: 0.7891 - val_loss: 0.8091 - val_acc: 0.7616\n",
      "Epoch 284/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6606 - acc: 0.7888 - val_loss: 0.8015 - val_acc: 0.7648\n",
      "Epoch 285/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6589 - acc: 0.7893 - val_loss: 0.8119 - val_acc: 0.7588\n",
      "Epoch 286/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6613 - acc: 0.7889 - val_loss: 0.7998 - val_acc: 0.7636\n",
      "Epoch 287/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6587 - acc: 0.7895 - val_loss: 0.8079 - val_acc: 0.7612\n",
      "Epoch 288/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6576 - acc: 0.7893 - val_loss: 0.8024 - val_acc: 0.7612\n",
      "Epoch 289/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6582 - acc: 0.7900 - val_loss: 0.8026 - val_acc: 0.7636\n",
      "Epoch 290/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6594 - acc: 0.7891 - val_loss: 0.8022 - val_acc: 0.7635\n",
      "Epoch 291/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6581 - acc: 0.7893 - val_loss: 0.8024 - val_acc: 0.7650\n",
      "Epoch 292/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6585 - acc: 0.7895 - val_loss: 0.8007 - val_acc: 0.7639\n",
      "Epoch 293/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6588 - acc: 0.7876 - val_loss: 0.7998 - val_acc: 0.7613\n",
      "Epoch 294/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6578 - acc: 0.7898 - val_loss: 0.7994 - val_acc: 0.7634\n",
      "Epoch 295/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6581 - acc: 0.7893 - val_loss: 0.8114 - val_acc: 0.7608\n",
      "Epoch 296/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6575 - acc: 0.7878 - val_loss: 0.8033 - val_acc: 0.7622\n",
      "Epoch 297/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6571 - acc: 0.7906 - val_loss: 0.8046 - val_acc: 0.7619\n",
      "Epoch 298/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6585 - acc: 0.7887 - val_loss: 0.8040 - val_acc: 0.7631\n",
      "Epoch 299/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6595 - acc: 0.7887 - val_loss: 0.8034 - val_acc: 0.7605\n",
      "Epoch 300/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6572 - acc: 0.7898 - val_loss: 0.8047 - val_acc: 0.7631\n",
      "Epoch 301/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6589 - acc: 0.7891 - val_loss: 0.8122 - val_acc: 0.7565\n",
      "Epoch 302/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6569 - acc: 0.7901 - val_loss: 0.7981 - val_acc: 0.7655\n",
      "Epoch 303/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6581 - acc: 0.7887 - val_loss: 0.8023 - val_acc: 0.7628\n",
      "Epoch 304/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6569 - acc: 0.7900 - val_loss: 0.8002 - val_acc: 0.7623\n",
      "Epoch 305/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6575 - acc: 0.7901 - val_loss: 0.8042 - val_acc: 0.7607\n",
      "Epoch 306/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6570 - acc: 0.7888 - val_loss: 0.8137 - val_acc: 0.7626\n",
      "Epoch 307/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6562 - acc: 0.7907 - val_loss: 0.8021 - val_acc: 0.7630\n",
      "Epoch 308/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6559 - acc: 0.7892 - val_loss: 0.7992 - val_acc: 0.7637\n",
      "Epoch 309/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6552 - acc: 0.7899 - val_loss: 0.8082 - val_acc: 0.7612\n",
      "Epoch 310/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6558 - acc: 0.7896 - val_loss: 0.8038 - val_acc: 0.7616\n",
      "Epoch 311/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6547 - acc: 0.7901 - val_loss: 0.8068 - val_acc: 0.7620\n",
      "Epoch 312/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6544 - acc: 0.7891 - val_loss: 0.8010 - val_acc: 0.7627\n",
      "Epoch 313/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6550 - acc: 0.7886 - val_loss: 0.7985 - val_acc: 0.7635\n",
      "Epoch 314/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6545 - acc: 0.7898 - val_loss: 0.8068 - val_acc: 0.7595\n",
      "Epoch 315/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6547 - acc: 0.7901 - val_loss: 0.7976 - val_acc: 0.7628\n",
      "Epoch 316/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6550 - acc: 0.7886 - val_loss: 0.8066 - val_acc: 0.7617\n",
      "Epoch 317/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6554 - acc: 0.7885 - val_loss: 0.8063 - val_acc: 0.7617\n",
      "Epoch 318/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6554 - acc: 0.7893 - val_loss: 0.8019 - val_acc: 0.7636\n",
      "Epoch 319/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6553 - acc: 0.7881 - val_loss: 0.8028 - val_acc: 0.7601\n",
      "Epoch 320/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6544 - acc: 0.7901 - val_loss: 0.8046 - val_acc: 0.7627\n",
      "Epoch 321/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6538 - acc: 0.7899 - val_loss: 0.8143 - val_acc: 0.7593\n",
      "Epoch 322/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6534 - acc: 0.7903 - val_loss: 0.8089 - val_acc: 0.7592\n",
      "Epoch 323/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6545 - acc: 0.7880 - val_loss: 0.8172 - val_acc: 0.7569\n",
      "Epoch 324/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6536 - acc: 0.7889 - val_loss: 0.8041 - val_acc: 0.7615\n",
      "Epoch 325/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6531 - acc: 0.7903 - val_loss: 0.8161 - val_acc: 0.7559\n",
      "Epoch 326/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6538 - acc: 0.7898 - val_loss: 0.8117 - val_acc: 0.7595\n",
      "Epoch 327/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6551 - acc: 0.7889 - val_loss: 0.8043 - val_acc: 0.7607\n",
      "Epoch 328/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6532 - acc: 0.7900 - val_loss: 0.8005 - val_acc: 0.7637\n",
      "Epoch 329/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6524 - acc: 0.7903 - val_loss: 0.8023 - val_acc: 0.7637\n",
      "Epoch 330/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6528 - acc: 0.7891 - val_loss: 0.8065 - val_acc: 0.7572\n",
      "Epoch 331/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6519 - acc: 0.7916 - val_loss: 0.8105 - val_acc: 0.7616\n",
      "Epoch 332/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6533 - acc: 0.7907 - val_loss: 0.8113 - val_acc: 0.7614\n",
      "Epoch 333/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6530 - acc: 0.7900 - val_loss: 0.8017 - val_acc: 0.7614\n",
      "Epoch 334/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6521 - acc: 0.7908 - val_loss: 0.8080 - val_acc: 0.7578\n",
      "Epoch 335/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6515 - acc: 0.7894 - val_loss: 0.8129 - val_acc: 0.7580\n",
      "Epoch 336/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6530 - acc: 0.7914 - val_loss: 0.8128 - val_acc: 0.7556\n",
      "Epoch 337/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6521 - acc: 0.7901 - val_loss: 0.8005 - val_acc: 0.7631\n",
      "Epoch 338/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6512 - acc: 0.7896 - val_loss: 0.8050 - val_acc: 0.7641\n",
      "Epoch 339/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6528 - acc: 0.7898 - val_loss: 0.8043 - val_acc: 0.7601\n",
      "Epoch 340/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6530 - acc: 0.7899 - val_loss: 0.7998 - val_acc: 0.7611\n",
      "Epoch 341/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6513 - acc: 0.7915 - val_loss: 0.7989 - val_acc: 0.7633\n",
      "Epoch 342/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6566 - acc: 0.7886 - val_loss: 0.8063 - val_acc: 0.7608\n",
      "Epoch 343/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6520 - acc: 0.7905 - val_loss: 0.8135 - val_acc: 0.7563\n",
      "Epoch 344/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6523 - acc: 0.7885 - val_loss: 0.8155 - val_acc: 0.7557\n",
      "Epoch 345/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6488 - acc: 0.7930 - val_loss: 0.8058 - val_acc: 0.7616\n",
      "Epoch 346/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6517 - acc: 0.7903 - val_loss: 0.8081 - val_acc: 0.7569\n",
      "Epoch 347/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6503 - acc: 0.7914 - val_loss: 0.8051 - val_acc: 0.7610\n",
      "Epoch 348/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6506 - acc: 0.7903 - val_loss: 0.7961 - val_acc: 0.7636\n",
      "Epoch 349/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6503 - acc: 0.7913 - val_loss: 0.8005 - val_acc: 0.7624\n",
      "Epoch 350/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6496 - acc: 0.7914 - val_loss: 0.8078 - val_acc: 0.7602\n",
      "Epoch 351/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6502 - acc: 0.7896 - val_loss: 0.7959 - val_acc: 0.7633\n",
      "Epoch 352/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6501 - acc: 0.7909 - val_loss: 0.8029 - val_acc: 0.7614\n",
      "Epoch 353/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6492 - acc: 0.7917 - val_loss: 0.8047 - val_acc: 0.7612\n",
      "Epoch 354/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6498 - acc: 0.7913 - val_loss: 0.8043 - val_acc: 0.7603\n",
      "Epoch 355/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6507 - acc: 0.7912 - val_loss: 0.7964 - val_acc: 0.7624\n",
      "Epoch 356/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6496 - acc: 0.7919 - val_loss: 0.8066 - val_acc: 0.7627\n",
      "Epoch 357/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6492 - acc: 0.7921 - val_loss: 0.8102 - val_acc: 0.7605\n",
      "Epoch 358/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6492 - acc: 0.7914 - val_loss: 0.8188 - val_acc: 0.7578\n",
      "Epoch 359/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6489 - acc: 0.7904 - val_loss: 0.8022 - val_acc: 0.7606\n",
      "Epoch 360/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6480 - acc: 0.7920 - val_loss: 0.8014 - val_acc: 0.7625\n",
      "Epoch 361/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6483 - acc: 0.7916 - val_loss: 0.8000 - val_acc: 0.7651\n",
      "Epoch 362/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6494 - acc: 0.7908 - val_loss: 0.7998 - val_acc: 0.7644\n",
      "Epoch 363/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6478 - acc: 0.7912 - val_loss: 0.8123 - val_acc: 0.7599\n",
      "Epoch 364/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6475 - acc: 0.7932 - val_loss: 0.8021 - val_acc: 0.7647\n",
      "Epoch 365/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6473 - acc: 0.7922 - val_loss: 0.8132 - val_acc: 0.7586\n",
      "Epoch 366/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6475 - acc: 0.7939 - val_loss: 0.7983 - val_acc: 0.7637\n",
      "Epoch 367/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6495 - acc: 0.7914 - val_loss: 0.8017 - val_acc: 0.7634\n",
      "Epoch 368/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6458 - acc: 0.7912 - val_loss: 0.8047 - val_acc: 0.7626\n",
      "Epoch 369/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6482 - acc: 0.7915 - val_loss: 0.8009 - val_acc: 0.7630\n",
      "Epoch 370/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6489 - acc: 0.7918 - val_loss: 0.8080 - val_acc: 0.7629\n",
      "Epoch 371/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6488 - acc: 0.7921 - val_loss: 0.8028 - val_acc: 0.7635\n",
      "Epoch 372/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6469 - acc: 0.7917 - val_loss: 0.8033 - val_acc: 0.7631\n",
      "Epoch 373/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6457 - acc: 0.7924 - val_loss: 0.8033 - val_acc: 0.7628\n",
      "Epoch 374/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6481 - acc: 0.7920 - val_loss: 0.8110 - val_acc: 0.7622\n",
      "Epoch 375/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6488 - acc: 0.7912 - val_loss: 0.8104 - val_acc: 0.7604\n",
      "Epoch 376/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6449 - acc: 0.7936 - val_loss: 0.8032 - val_acc: 0.7614\n",
      "Epoch 377/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6445 - acc: 0.7922 - val_loss: 0.8080 - val_acc: 0.7626\n",
      "Epoch 378/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6478 - acc: 0.7927 - val_loss: 0.8043 - val_acc: 0.7610\n",
      "Epoch 379/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6453 - acc: 0.7931 - val_loss: 0.8035 - val_acc: 0.7603\n",
      "Epoch 380/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6453 - acc: 0.7920 - val_loss: 0.8189 - val_acc: 0.7570\n",
      "Epoch 381/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6454 - acc: 0.7934 - val_loss: 0.8207 - val_acc: 0.7589\n",
      "Epoch 382/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6446 - acc: 0.7940 - val_loss: 0.7984 - val_acc: 0.7628\n",
      "Epoch 383/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6472 - acc: 0.7920 - val_loss: 0.8133 - val_acc: 0.7584\n",
      "Epoch 384/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6446 - acc: 0.7918 - val_loss: 0.8098 - val_acc: 0.7617\n",
      "Epoch 385/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6449 - acc: 0.7932 - val_loss: 0.8039 - val_acc: 0.7633\n",
      "Epoch 386/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6471 - acc: 0.7917 - val_loss: 0.8115 - val_acc: 0.7608\n",
      "Epoch 387/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6469 - acc: 0.7933 - val_loss: 0.8120 - val_acc: 0.7632\n",
      "Epoch 388/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6470 - acc: 0.7928 - val_loss: 0.7994 - val_acc: 0.7625\n",
      "Epoch 389/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6446 - acc: 0.7910 - val_loss: 0.8066 - val_acc: 0.7615\n",
      "Epoch 390/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6458 - acc: 0.7945 - val_loss: 0.8104 - val_acc: 0.7623\n",
      "Epoch 391/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6440 - acc: 0.7935 - val_loss: 0.8002 - val_acc: 0.7659\n",
      "Epoch 392/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6439 - acc: 0.7950 - val_loss: 0.8053 - val_acc: 0.7626\n",
      "Epoch 393/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6439 - acc: 0.7928 - val_loss: 0.8044 - val_acc: 0.7633\n",
      "Epoch 394/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6435 - acc: 0.7939 - val_loss: 0.7999 - val_acc: 0.7639\n",
      "Epoch 395/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6438 - acc: 0.7930 - val_loss: 0.8006 - val_acc: 0.7633\n",
      "Epoch 396/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6440 - acc: 0.7940 - val_loss: 0.8392 - val_acc: 0.7558\n",
      "Epoch 397/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6443 - acc: 0.7943 - val_loss: 0.8025 - val_acc: 0.7628\n",
      "Epoch 398/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6419 - acc: 0.7952 - val_loss: 0.8015 - val_acc: 0.7635\n",
      "Epoch 399/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6438 - acc: 0.7936 - val_loss: 0.8019 - val_acc: 0.7625\n",
      "Epoch 400/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6442 - acc: 0.7952 - val_loss: 0.8023 - val_acc: 0.7585\n",
      "Epoch 401/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6434 - acc: 0.7934 - val_loss: 0.8069 - val_acc: 0.7639\n",
      "Epoch 402/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6417 - acc: 0.7930 - val_loss: 0.8044 - val_acc: 0.7614\n",
      "Epoch 403/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6423 - acc: 0.7948 - val_loss: 0.8026 - val_acc: 0.7627\n",
      "Epoch 404/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6415 - acc: 0.7944 - val_loss: 0.8122 - val_acc: 0.7593\n",
      "Epoch 405/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6438 - acc: 0.7939 - val_loss: 0.8148 - val_acc: 0.7610\n",
      "Epoch 406/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6431 - acc: 0.7944 - val_loss: 0.8029 - val_acc: 0.7619\n",
      "Epoch 407/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6435 - acc: 0.7937 - val_loss: 0.8100 - val_acc: 0.7617\n",
      "Epoch 408/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6447 - acc: 0.7935 - val_loss: 0.8048 - val_acc: 0.7630\n",
      "Epoch 409/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6418 - acc: 0.7934 - val_loss: 0.8057 - val_acc: 0.7626\n",
      "Epoch 410/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6418 - acc: 0.7932 - val_loss: 0.8028 - val_acc: 0.7645\n",
      "Epoch 411/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6407 - acc: 0.7961 - val_loss: 0.8068 - val_acc: 0.7625\n",
      "Epoch 412/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6405 - acc: 0.7957 - val_loss: 0.8022 - val_acc: 0.7627\n",
      "Epoch 413/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6420 - acc: 0.7930 - val_loss: 0.8030 - val_acc: 0.7642\n",
      "Epoch 414/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6409 - acc: 0.7954 - val_loss: 0.8151 - val_acc: 0.7611\n",
      "Epoch 415/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6434 - acc: 0.7941 - val_loss: 0.8126 - val_acc: 0.7600\n",
      "Epoch 416/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6399 - acc: 0.7951 - val_loss: 0.8178 - val_acc: 0.7577\n",
      "Epoch 417/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6411 - acc: 0.7950 - val_loss: 0.8024 - val_acc: 0.7634\n",
      "Epoch 418/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6405 - acc: 0.7947 - val_loss: 0.8026 - val_acc: 0.7636\n",
      "Epoch 419/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6414 - acc: 0.7963 - val_loss: 0.8020 - val_acc: 0.7627\n",
      "Epoch 420/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6397 - acc: 0.7945 - val_loss: 0.8123 - val_acc: 0.7617\n",
      "Epoch 421/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6404 - acc: 0.7943 - val_loss: 0.8044 - val_acc: 0.7620\n",
      "Epoch 422/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6397 - acc: 0.7961 - val_loss: 0.8142 - val_acc: 0.7612\n",
      "Epoch 423/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6400 - acc: 0.7944 - val_loss: 0.8013 - val_acc: 0.7642\n",
      "Epoch 424/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6411 - acc: 0.7951 - val_loss: 0.8142 - val_acc: 0.7609\n",
      "Epoch 425/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6411 - acc: 0.7939 - val_loss: 0.8057 - val_acc: 0.7616\n",
      "Epoch 426/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6384 - acc: 0.7952 - val_loss: 0.7999 - val_acc: 0.7621\n",
      "Epoch 427/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6393 - acc: 0.7950 - val_loss: 0.8065 - val_acc: 0.7616\n",
      "Epoch 428/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6393 - acc: 0.7973 - val_loss: 0.8072 - val_acc: 0.7627\n",
      "Epoch 429/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6418 - acc: 0.7952 - val_loss: 0.8104 - val_acc: 0.7619\n",
      "Epoch 430/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6385 - acc: 0.7956 - val_loss: 0.8053 - val_acc: 0.7630\n",
      "Epoch 431/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6408 - acc: 0.7947 - val_loss: 0.8092 - val_acc: 0.7603\n",
      "Epoch 432/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6384 - acc: 0.7952 - val_loss: 0.7999 - val_acc: 0.7626\n",
      "Epoch 433/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6392 - acc: 0.7957 - val_loss: 0.8033 - val_acc: 0.7642\n",
      "Epoch 434/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6390 - acc: 0.7976 - val_loss: 0.7981 - val_acc: 0.7631\n",
      "Epoch 435/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6401 - acc: 0.7961 - val_loss: 0.8099 - val_acc: 0.7629\n",
      "Epoch 436/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6406 - acc: 0.7952 - val_loss: 0.8006 - val_acc: 0.7650\n",
      "Epoch 437/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6410 - acc: 0.7950 - val_loss: 0.8018 - val_acc: 0.7617\n",
      "Epoch 438/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6388 - acc: 0.7947 - val_loss: 0.8111 - val_acc: 0.7616\n",
      "Epoch 439/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6382 - acc: 0.7961 - val_loss: 0.8038 - val_acc: 0.7629\n",
      "Epoch 440/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6371 - acc: 0.7963 - val_loss: 0.8020 - val_acc: 0.7634\n",
      "Epoch 441/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6382 - acc: 0.7946 - val_loss: 0.8026 - val_acc: 0.7628\n",
      "Epoch 442/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6364 - acc: 0.7959 - val_loss: 0.8122 - val_acc: 0.7603\n",
      "Epoch 443/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6382 - acc: 0.7958 - val_loss: 0.8007 - val_acc: 0.7635\n",
      "Epoch 444/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6401 - acc: 0.7949 - val_loss: 0.8130 - val_acc: 0.7619\n",
      "Epoch 445/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6379 - acc: 0.7945 - val_loss: 0.8056 - val_acc: 0.7626\n",
      "Epoch 446/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6363 - acc: 0.7963 - val_loss: 0.8058 - val_acc: 0.7613\n",
      "Epoch 447/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6367 - acc: 0.7969 - val_loss: 0.8162 - val_acc: 0.7628\n",
      "Epoch 448/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6376 - acc: 0.7943 - val_loss: 0.7981 - val_acc: 0.7626\n",
      "Epoch 449/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6396 - acc: 0.7954 - val_loss: 0.8038 - val_acc: 0.7626\n",
      "Epoch 450/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6382 - acc: 0.7956 - val_loss: 0.8088 - val_acc: 0.7629\n",
      "Epoch 451/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6366 - acc: 0.7942 - val_loss: 0.8027 - val_acc: 0.7637\n",
      "Epoch 452/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6378 - acc: 0.7960 - val_loss: 0.8034 - val_acc: 0.7632\n",
      "Epoch 453/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6354 - acc: 0.7961 - val_loss: 0.8087 - val_acc: 0.7620\n",
      "Epoch 454/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6375 - acc: 0.7961 - val_loss: 0.8090 - val_acc: 0.7615\n",
      "Epoch 455/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6358 - acc: 0.7964 - val_loss: 0.7978 - val_acc: 0.7625\n",
      "Epoch 456/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6370 - acc: 0.7967 - val_loss: 0.8095 - val_acc: 0.7609\n",
      "Epoch 457/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6369 - acc: 0.7959 - val_loss: 0.8199 - val_acc: 0.7577\n",
      "Epoch 458/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6356 - acc: 0.7957 - val_loss: 0.8072 - val_acc: 0.7617\n",
      "Epoch 459/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6363 - acc: 0.7976 - val_loss: 0.8024 - val_acc: 0.7624\n",
      "Epoch 460/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6361 - acc: 0.7960 - val_loss: 0.8359 - val_acc: 0.7553\n",
      "Epoch 461/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6368 - acc: 0.7969 - val_loss: 0.8080 - val_acc: 0.7597\n",
      "Epoch 462/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6370 - acc: 0.7956 - val_loss: 0.8054 - val_acc: 0.7620\n",
      "Epoch 463/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6351 - acc: 0.7959 - val_loss: 0.8022 - val_acc: 0.7641\n",
      "Epoch 464/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6352 - acc: 0.7956 - val_loss: 0.8082 - val_acc: 0.7599\n",
      "Epoch 465/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6378 - acc: 0.7959 - val_loss: 0.8015 - val_acc: 0.7645\n",
      "Epoch 466/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6351 - acc: 0.7956 - val_loss: 0.8004 - val_acc: 0.7629\n",
      "Epoch 467/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6355 - acc: 0.7958 - val_loss: 0.8098 - val_acc: 0.7638\n",
      "Epoch 468/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6347 - acc: 0.7963 - val_loss: 0.8078 - val_acc: 0.7624\n",
      "Epoch 469/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6340 - acc: 0.7976 - val_loss: 0.8099 - val_acc: 0.7610\n",
      "Epoch 470/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6369 - acc: 0.7956 - val_loss: 0.8140 - val_acc: 0.7588\n",
      "Epoch 471/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6364 - acc: 0.7964 - val_loss: 0.8168 - val_acc: 0.7605\n",
      "Epoch 472/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6336 - acc: 0.7980 - val_loss: 0.8103 - val_acc: 0.7612\n",
      "Epoch 473/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6336 - acc: 0.7991 - val_loss: 0.8055 - val_acc: 0.7626\n",
      "Epoch 474/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6335 - acc: 0.7973 - val_loss: 0.8014 - val_acc: 0.7617\n",
      "Epoch 475/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6348 - acc: 0.7974 - val_loss: 0.8095 - val_acc: 0.7626\n",
      "Epoch 476/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6355 - acc: 0.7968 - val_loss: 0.8037 - val_acc: 0.7629\n",
      "Epoch 477/500\n",
      "34108/34108 [==============================] - ETA: 0s - loss: 0.6354 - acc: 0.796 - 0s 10us/step - loss: 0.6350 - acc: 0.7968 - val_loss: 0.8237 - val_acc: 0.7574\n",
      "Epoch 478/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6333 - acc: 0.7969 - val_loss: 0.8047 - val_acc: 0.7621\n",
      "Epoch 479/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6351 - acc: 0.7969 - val_loss: 0.8042 - val_acc: 0.7634\n",
      "Epoch 480/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6346 - acc: 0.7974 - val_loss: 0.8071 - val_acc: 0.7622\n",
      "Epoch 481/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6345 - acc: 0.7961 - val_loss: 0.8126 - val_acc: 0.7605\n",
      "Epoch 482/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6330 - acc: 0.7977 - val_loss: 0.8159 - val_acc: 0.7582\n",
      "Epoch 483/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6353 - acc: 0.7968 - val_loss: 0.8048 - val_acc: 0.7606\n",
      "Epoch 484/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6348 - acc: 0.7976 - val_loss: 0.8021 - val_acc: 0.7631\n",
      "Epoch 485/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6320 - acc: 0.7963 - val_loss: 0.8097 - val_acc: 0.7612\n",
      "Epoch 486/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6340 - acc: 0.7957 - val_loss: 0.8068 - val_acc: 0.7633\n",
      "Epoch 487/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6331 - acc: 0.7980 - val_loss: 0.8037 - val_acc: 0.7619\n",
      "Epoch 488/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6343 - acc: 0.7970 - val_loss: 0.8261 - val_acc: 0.7579\n",
      "Epoch 489/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6349 - acc: 0.7971 - val_loss: 0.8099 - val_acc: 0.7598\n",
      "Epoch 490/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6330 - acc: 0.7978 - val_loss: 0.8088 - val_acc: 0.7598\n",
      "Epoch 491/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6328 - acc: 0.7971 - val_loss: 0.8039 - val_acc: 0.7624\n",
      "Epoch 492/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6329 - acc: 0.7971 - val_loss: 0.8082 - val_acc: 0.7617\n",
      "Epoch 493/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6323 - acc: 0.7969 - val_loss: 0.8088 - val_acc: 0.7629\n",
      "Epoch 494/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6332 - acc: 0.7971 - val_loss: 0.8050 - val_acc: 0.7627\n",
      "Epoch 495/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6326 - acc: 0.7971 - val_loss: 0.8150 - val_acc: 0.7603\n",
      "Epoch 496/500\n",
      "34108/34108 [==============================] - 0s 10us/step - loss: 0.6340 - acc: 0.7965 - val_loss: 0.8047 - val_acc: 0.7638\n",
      "Epoch 497/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6332 - acc: 0.7966 - val_loss: 0.8029 - val_acc: 0.7618\n",
      "Epoch 498/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6326 - acc: 0.7959 - val_loss: 0.8006 - val_acc: 0.7631\n",
      "Epoch 499/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6338 - acc: 0.7972 - val_loss: 0.8081 - val_acc: 0.7616\n",
      "Epoch 500/500\n",
      "34108/34108 [==============================] - 0s 11us/step - loss: 0.6324 - acc: 0.7963 - val_loss: 0.8103 - val_acc: 0.7616\n",
      "Train on 34108 samples, validate on 12117 samples\n",
      "Epoch 1/500\n",
      "34108/34108 [==============================] - 1s 27us/step - loss: 1.3408 - acc: 0.4567 - val_loss: 1.1100 - val_acc: 0.5593\n",
      "Epoch 2/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.9965 - acc: 0.6535 - val_loss: 0.8837 - val_acc: 0.7023\n",
      "Epoch 3/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.8378 - acc: 0.7328 - val_loss: 0.7844 - val_acc: 0.7475\n",
      "Epoch 4/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.7483 - acc: 0.7687 - val_loss: 0.7398 - val_acc: 0.7730\n",
      "Epoch 5/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.6938 - acc: 0.7873 - val_loss: 0.7085 - val_acc: 0.7852\n",
      "Epoch 6/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.6551 - acc: 0.7989 - val_loss: 0.6858 - val_acc: 0.7945\n",
      "Epoch 7/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.6254 - acc: 0.8091 - val_loss: 0.6522 - val_acc: 0.8030\n",
      "Epoch 8/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.6000 - acc: 0.8164 - val_loss: 0.6844 - val_acc: 0.7962\n",
      "Epoch 9/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.5793 - acc: 0.8248 - val_loss: 0.6239 - val_acc: 0.8095\n",
      "Epoch 10/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.5596 - acc: 0.8298 - val_loss: 0.6267 - val_acc: 0.8107\n",
      "Epoch 11/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.5456 - acc: 0.8341 - val_loss: 0.6050 - val_acc: 0.8219\n",
      "Epoch 12/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.5312 - acc: 0.8385 - val_loss: 0.5886 - val_acc: 0.8239\n",
      "Epoch 13/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.5206 - acc: 0.8420 - val_loss: 0.5840 - val_acc: 0.8244\n",
      "Epoch 14/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.5084 - acc: 0.8464 - val_loss: 0.5870 - val_acc: 0.8287\n",
      "Epoch 15/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.4976 - acc: 0.8487 - val_loss: 0.5669 - val_acc: 0.8315\n",
      "Epoch 16/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.4872 - acc: 0.8523 - val_loss: 0.5659 - val_acc: 0.8322\n",
      "Epoch 17/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.4778 - acc: 0.8537 - val_loss: 0.5786 - val_acc: 0.8286\n",
      "Epoch 18/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.4727 - acc: 0.8555 - val_loss: 0.5625 - val_acc: 0.8332\n",
      "Epoch 19/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.4615 - acc: 0.8597 - val_loss: 0.5623 - val_acc: 0.8377\n",
      "Epoch 20/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.4542 - acc: 0.8616 - val_loss: 0.5389 - val_acc: 0.8434\n",
      "Epoch 21/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.4450 - acc: 0.8658 - val_loss: 0.5546 - val_acc: 0.8401\n",
      "Epoch 22/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.4389 - acc: 0.8656 - val_loss: 0.5326 - val_acc: 0.8481\n",
      "Epoch 23/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.4327 - acc: 0.8697 - val_loss: 0.5418 - val_acc: 0.8429\n",
      "Epoch 24/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.4252 - acc: 0.8714 - val_loss: 0.5412 - val_acc: 0.8431\n",
      "Epoch 25/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.4200 - acc: 0.8704 - val_loss: 0.5459 - val_acc: 0.8443\n",
      "Epoch 26/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.4121 - acc: 0.8746 - val_loss: 0.5267 - val_acc: 0.8500\n",
      "Epoch 27/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.4081 - acc: 0.8764 - val_loss: 0.5349 - val_acc: 0.8494\n",
      "Epoch 28/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.4035 - acc: 0.8784 - val_loss: 0.5190 - val_acc: 0.8537\n",
      "Epoch 29/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.3981 - acc: 0.8803 - val_loss: 0.5347 - val_acc: 0.8492\n",
      "Epoch 30/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.3923 - acc: 0.8807 - val_loss: 0.5181 - val_acc: 0.8543\n",
      "Epoch 31/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.3845 - acc: 0.8846 - val_loss: 0.5185 - val_acc: 0.8524\n",
      "Epoch 32/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.3815 - acc: 0.8844 - val_loss: 0.5012 - val_acc: 0.8576\n",
      "Epoch 33/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.3750 - acc: 0.8869 - val_loss: 0.5029 - val_acc: 0.8590\n",
      "Epoch 34/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.3696 - acc: 0.8907 - val_loss: 0.5063 - val_acc: 0.8559\n",
      "Epoch 35/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.3682 - acc: 0.8892 - val_loss: 0.5292 - val_acc: 0.8497\n",
      "Epoch 36/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.3650 - acc: 0.8892 - val_loss: 0.4926 - val_acc: 0.8607\n",
      "Epoch 37/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.3599 - acc: 0.8922 - val_loss: 0.5049 - val_acc: 0.8583\n",
      "Epoch 38/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.3589 - acc: 0.8913 - val_loss: 0.5019 - val_acc: 0.8587\n",
      "Epoch 39/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.3551 - acc: 0.8926 - val_loss: 0.5104 - val_acc: 0.8595\n",
      "Epoch 40/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.3494 - acc: 0.8943 - val_loss: 0.5096 - val_acc: 0.8631\n",
      "Epoch 41/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.3470 - acc: 0.8933 - val_loss: 0.4960 - val_acc: 0.8614\n",
      "Epoch 42/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.3429 - acc: 0.8965 - val_loss: 0.5204 - val_acc: 0.8586\n",
      "Epoch 43/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.3399 - acc: 0.8978 - val_loss: 0.5041 - val_acc: 0.8617\n",
      "Epoch 44/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.3383 - acc: 0.8967 - val_loss: 0.4961 - val_acc: 0.8653\n",
      "Epoch 45/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.3332 - acc: 0.8995 - val_loss: 0.5357 - val_acc: 0.8528\n",
      "Epoch 46/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.3320 - acc: 0.9011 - val_loss: 0.4870 - val_acc: 0.8672\n",
      "Epoch 47/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.3291 - acc: 0.9009 - val_loss: 0.4885 - val_acc: 0.8637\n",
      "Epoch 48/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.3253 - acc: 0.9025 - val_loss: 0.4833 - val_acc: 0.8671\n",
      "Epoch 49/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.3203 - acc: 0.9038 - val_loss: 0.4950 - val_acc: 0.8637\n",
      "Epoch 50/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.3192 - acc: 0.9049 - val_loss: 0.4843 - val_acc: 0.8694\n",
      "Epoch 51/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.3185 - acc: 0.9031 - val_loss: 0.4848 - val_acc: 0.8721\n",
      "Epoch 52/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.3144 - acc: 0.9058 - val_loss: 0.4829 - val_acc: 0.8693\n",
      "Epoch 53/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.3129 - acc: 0.9052 - val_loss: 0.4844 - val_acc: 0.8722\n",
      "Epoch 54/500\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.3121 - acc: 0.9066 - val_loss: 0.4913 - val_acc: 0.8667\n",
      "Epoch 55/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.3084 - acc: 0.9073 - val_loss: 0.4912 - val_acc: 0.8674\n",
      "Epoch 56/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.3018 - acc: 0.9101 - val_loss: 0.4842 - val_acc: 0.8694\n",
      "Epoch 57/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.3017 - acc: 0.9091 - val_loss: 0.5066 - val_acc: 0.8661\n",
      "Epoch 58/500\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.2993 - acc: 0.9104 - val_loss: 0.4913 - val_acc: 0.8697\n",
      "Epoch 59/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.3001 - acc: 0.9092 - val_loss: 0.4881 - val_acc: 0.8708\n",
      "Epoch 60/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2965 - acc: 0.9102 - val_loss: 0.4744 - val_acc: 0.8766\n",
      "Epoch 61/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2957 - acc: 0.9111 - val_loss: 0.4929 - val_acc: 0.8709\n",
      "Epoch 62/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2911 - acc: 0.9126 - val_loss: 0.4819 - val_acc: 0.8713\n",
      "Epoch 63/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2919 - acc: 0.9129 - val_loss: 0.4921 - val_acc: 0.8699\n",
      "Epoch 64/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2888 - acc: 0.9137 - val_loss: 0.4840 - val_acc: 0.8728\n",
      "Epoch 65/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2866 - acc: 0.9141 - val_loss: 0.4889 - val_acc: 0.8728\n",
      "Epoch 66/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2837 - acc: 0.9152 - val_loss: 0.4793 - val_acc: 0.8732\n",
      "Epoch 67/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2855 - acc: 0.9140 - val_loss: 0.5209 - val_acc: 0.8649\n",
      "Epoch 68/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2788 - acc: 0.9154 - val_loss: 0.4872 - val_acc: 0.8724\n",
      "Epoch 69/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2803 - acc: 0.9153 - val_loss: 0.4796 - val_acc: 0.8753\n",
      "Epoch 70/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2782 - acc: 0.9166 - val_loss: 0.4803 - val_acc: 0.8762\n",
      "Epoch 71/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.2765 - acc: 0.9162 - val_loss: 0.4854 - val_acc: 0.8732\n",
      "Epoch 72/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2755 - acc: 0.9156 - val_loss: 0.4857 - val_acc: 0.8750\n",
      "Epoch 73/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2707 - acc: 0.9191 - val_loss: 0.4787 - val_acc: 0.8760\n",
      "Epoch 74/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2724 - acc: 0.9179 - val_loss: 0.4840 - val_acc: 0.8721\n",
      "Epoch 75/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2709 - acc: 0.9181 - val_loss: 0.5122 - val_acc: 0.8718\n",
      "Epoch 76/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2681 - acc: 0.9193 - val_loss: 0.5004 - val_acc: 0.8709\n",
      "Epoch 77/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2643 - acc: 0.9217 - val_loss: 0.4839 - val_acc: 0.8768\n",
      "Epoch 78/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.2639 - acc: 0.9211 - val_loss: 0.4974 - val_acc: 0.8741\n",
      "Epoch 79/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2614 - acc: 0.9200 - val_loss: 0.4890 - val_acc: 0.8765\n",
      "Epoch 80/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2596 - acc: 0.9213 - val_loss: 0.4952 - val_acc: 0.8738\n",
      "Epoch 81/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2599 - acc: 0.9221 - val_loss: 0.4817 - val_acc: 0.8765\n",
      "Epoch 82/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2575 - acc: 0.9231 - val_loss: 0.4951 - val_acc: 0.8737\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.2540 - acc: 0.9238 - val_loss: 0.4856 - val_acc: 0.8781\n",
      "Epoch 84/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2559 - acc: 0.9246 - val_loss: 0.4828 - val_acc: 0.8773\n",
      "Epoch 85/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.2539 - acc: 0.9237 - val_loss: 0.4952 - val_acc: 0.8744\n",
      "Epoch 86/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2539 - acc: 0.9211 - val_loss: 0.4838 - val_acc: 0.8790\n",
      "Epoch 87/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2553 - acc: 0.9230 - val_loss: 0.4949 - val_acc: 0.8757\n",
      "Epoch 88/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2507 - acc: 0.9249 - val_loss: 0.4906 - val_acc: 0.8729\n",
      "Epoch 89/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2482 - acc: 0.9265 - val_loss: 0.4854 - val_acc: 0.8788\n",
      "Epoch 90/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2470 - acc: 0.9264 - val_loss: 0.4833 - val_acc: 0.8786\n",
      "Epoch 91/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2452 - acc: 0.9259 - val_loss: 0.5092 - val_acc: 0.8745\n",
      "Epoch 92/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2430 - acc: 0.9265 - val_loss: 0.4829 - val_acc: 0.8801\n",
      "Epoch 93/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.2431 - acc: 0.9265 - val_loss: 0.4894 - val_acc: 0.8769\n",
      "Epoch 94/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2440 - acc: 0.9262 - val_loss: 0.4870 - val_acc: 0.8800\n",
      "Epoch 95/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2412 - acc: 0.9272 - val_loss: 0.4868 - val_acc: 0.8795\n",
      "Epoch 96/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2382 - acc: 0.9278 - val_loss: 0.5010 - val_acc: 0.8739\n",
      "Epoch 97/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2406 - acc: 0.9273 - val_loss: 0.4854 - val_acc: 0.8815\n",
      "Epoch 98/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2364 - acc: 0.9290 - val_loss: 0.5008 - val_acc: 0.8797\n",
      "Epoch 99/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2354 - acc: 0.9288 - val_loss: 0.4959 - val_acc: 0.8757\n",
      "Epoch 100/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2341 - acc: 0.9295 - val_loss: 0.5063 - val_acc: 0.8785\n",
      "Epoch 101/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2339 - acc: 0.9298 - val_loss: 0.4895 - val_acc: 0.8794\n",
      "Epoch 102/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2336 - acc: 0.9288 - val_loss: 0.4969 - val_acc: 0.8789\n",
      "Epoch 103/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.2335 - acc: 0.9284 - val_loss: 0.4811 - val_acc: 0.8825\n",
      "Epoch 104/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2297 - acc: 0.9300 - val_loss: 0.5042 - val_acc: 0.8757\n",
      "Epoch 105/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2286 - acc: 0.9310 - val_loss: 0.5167 - val_acc: 0.8735\n",
      "Epoch 106/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2280 - acc: 0.9306 - val_loss: 0.5251 - val_acc: 0.8772\n",
      "Epoch 107/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2271 - acc: 0.9312 - val_loss: 0.5060 - val_acc: 0.8796\n",
      "Epoch 108/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.2280 - acc: 0.9305 - val_loss: 0.4954 - val_acc: 0.8812\n",
      "Epoch 109/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2251 - acc: 0.9325 - val_loss: 0.5003 - val_acc: 0.8793\n",
      "Epoch 110/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2252 - acc: 0.9324 - val_loss: 0.5135 - val_acc: 0.8786\n",
      "Epoch 111/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2198 - acc: 0.9341 - val_loss: 0.5341 - val_acc: 0.8725\n",
      "Epoch 112/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2222 - acc: 0.9328 - val_loss: 0.5104 - val_acc: 0.8778\n",
      "Epoch 113/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2195 - acc: 0.9331 - val_loss: 0.5126 - val_acc: 0.8785\n",
      "Epoch 114/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2168 - acc: 0.9342 - val_loss: 0.5214 - val_acc: 0.8755\n",
      "Epoch 115/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2188 - acc: 0.9346 - val_loss: 0.5221 - val_acc: 0.8758\n",
      "Epoch 116/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.2189 - acc: 0.9344 - val_loss: 0.5220 - val_acc: 0.8746\n",
      "Epoch 117/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.2175 - acc: 0.9345 - val_loss: 0.5132 - val_acc: 0.8799\n",
      "Epoch 118/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2147 - acc: 0.9351 - val_loss: 0.5123 - val_acc: 0.8801\n",
      "Epoch 119/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2143 - acc: 0.9338 - val_loss: 0.5275 - val_acc: 0.8782\n",
      "Epoch 120/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2133 - acc: 0.9348 - val_loss: 0.5160 - val_acc: 0.8766\n",
      "Epoch 121/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2127 - acc: 0.9367 - val_loss: 0.5300 - val_acc: 0.8763\n",
      "Epoch 122/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2127 - acc: 0.9361 - val_loss: 0.5034 - val_acc: 0.8820\n",
      "Epoch 123/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2118 - acc: 0.9354 - val_loss: 0.5273 - val_acc: 0.8783\n",
      "Epoch 124/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.2135 - acc: 0.9339 - val_loss: 0.5087 - val_acc: 0.8812\n",
      "Epoch 125/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.2074 - acc: 0.9376 - val_loss: 0.5272 - val_acc: 0.8803\n",
      "Epoch 126/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.2088 - acc: 0.9369 - val_loss: 0.5223 - val_acc: 0.8774\n",
      "Epoch 127/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2059 - acc: 0.9364 - val_loss: 0.5255 - val_acc: 0.8797\n",
      "Epoch 128/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.2059 - acc: 0.9371 - val_loss: 0.5590 - val_acc: 0.8741\n",
      "Epoch 129/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2073 - acc: 0.9372 - val_loss: 0.5418 - val_acc: 0.8744\n",
      "Epoch 130/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2070 - acc: 0.9363 - val_loss: 0.5423 - val_acc: 0.8759\n",
      "Epoch 131/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2030 - acc: 0.9389 - val_loss: 0.5267 - val_acc: 0.8766\n",
      "Epoch 132/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.2060 - acc: 0.9370 - val_loss: 0.5199 - val_acc: 0.8813\n",
      "Epoch 133/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2029 - acc: 0.9373 - val_loss: 0.5301 - val_acc: 0.8798\n",
      "Epoch 134/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1990 - acc: 0.9397 - val_loss: 0.5155 - val_acc: 0.8812\n",
      "Epoch 135/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2008 - acc: 0.9388 - val_loss: 0.5283 - val_acc: 0.8775\n",
      "Epoch 136/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.2028 - acc: 0.9387 - val_loss: 0.5205 - val_acc: 0.8797\n",
      "Epoch 137/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2029 - acc: 0.9377 - val_loss: 0.5293 - val_acc: 0.8798\n",
      "Epoch 138/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.2021 - acc: 0.9387 - val_loss: 0.5365 - val_acc: 0.8774\n",
      "Epoch 139/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1954 - acc: 0.9408 - val_loss: 0.5318 - val_acc: 0.8803\n",
      "Epoch 140/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1964 - acc: 0.9401 - val_loss: 0.5510 - val_acc: 0.8786\n",
      "Epoch 141/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1944 - acc: 0.9408 - val_loss: 0.5378 - val_acc: 0.8799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1975 - acc: 0.9391 - val_loss: 0.5283 - val_acc: 0.8815\n",
      "Epoch 143/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1933 - acc: 0.9408 - val_loss: 0.5141 - val_acc: 0.8842\n",
      "Epoch 144/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1981 - acc: 0.9390 - val_loss: 0.5260 - val_acc: 0.8806\n",
      "Epoch 145/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1915 - acc: 0.9412 - val_loss: 0.5366 - val_acc: 0.8793\n",
      "Epoch 146/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1912 - acc: 0.9424 - val_loss: 0.5255 - val_acc: 0.8839\n",
      "Epoch 147/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1879 - acc: 0.9426 - val_loss: 0.5395 - val_acc: 0.8787\n",
      "Epoch 148/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1912 - acc: 0.9420 - val_loss: 0.5597 - val_acc: 0.8760\n",
      "Epoch 149/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1888 - acc: 0.9427 - val_loss: 0.5315 - val_acc: 0.8797\n",
      "Epoch 150/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1890 - acc: 0.9426 - val_loss: 0.5556 - val_acc: 0.8778\n",
      "Epoch 151/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1863 - acc: 0.9433 - val_loss: 0.5343 - val_acc: 0.8817\n",
      "Epoch 152/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1877 - acc: 0.9433 - val_loss: 0.5411 - val_acc: 0.8807\n",
      "Epoch 153/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1887 - acc: 0.9414 - val_loss: 0.5496 - val_acc: 0.8770\n",
      "Epoch 154/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1850 - acc: 0.9429 - val_loss: 0.5359 - val_acc: 0.8817\n",
      "Epoch 155/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1835 - acc: 0.9446 - val_loss: 0.5318 - val_acc: 0.8841\n",
      "Epoch 156/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1883 - acc: 0.9419 - val_loss: 0.5370 - val_acc: 0.8802\n",
      "Epoch 157/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1866 - acc: 0.9434 - val_loss: 0.5418 - val_acc: 0.8788\n",
      "Epoch 158/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1848 - acc: 0.9439 - val_loss: 0.5476 - val_acc: 0.8814\n",
      "Epoch 159/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1812 - acc: 0.9457 - val_loss: 0.5381 - val_acc: 0.8831\n",
      "Epoch 160/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1845 - acc: 0.9432 - val_loss: 0.5428 - val_acc: 0.8841\n",
      "Epoch 161/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1809 - acc: 0.9458 - val_loss: 0.5321 - val_acc: 0.8831\n",
      "Epoch 162/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1780 - acc: 0.9457 - val_loss: 0.5501 - val_acc: 0.8786\n",
      "Epoch 163/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1828 - acc: 0.9444 - val_loss: 0.5443 - val_acc: 0.8808\n",
      "Epoch 164/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1787 - acc: 0.9454 - val_loss: 0.5659 - val_acc: 0.8751\n",
      "Epoch 165/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1773 - acc: 0.9455 - val_loss: 0.5682 - val_acc: 0.8744\n",
      "Epoch 166/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1808 - acc: 0.9449 - val_loss: 0.5500 - val_acc: 0.8825\n",
      "Epoch 167/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1757 - acc: 0.9467 - val_loss: 0.5629 - val_acc: 0.8790\n",
      "Epoch 168/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1770 - acc: 0.9462 - val_loss: 0.5402 - val_acc: 0.8835\n",
      "Epoch 169/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1795 - acc: 0.9446 - val_loss: 0.5520 - val_acc: 0.8803\n",
      "Epoch 170/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1740 - acc: 0.9478 - val_loss: 0.5404 - val_acc: 0.8836\n",
      "Epoch 171/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1743 - acc: 0.9467 - val_loss: 0.5642 - val_acc: 0.8803\n",
      "Epoch 172/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1725 - acc: 0.9470 - val_loss: 0.5451 - val_acc: 0.8817\n",
      "Epoch 173/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1746 - acc: 0.9470 - val_loss: 0.5870 - val_acc: 0.8740\n",
      "Epoch 174/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1763 - acc: 0.9465 - val_loss: 0.5635 - val_acc: 0.8790\n",
      "Epoch 175/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1781 - acc: 0.9461 - val_loss: 0.5600 - val_acc: 0.8797\n",
      "Epoch 176/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1759 - acc: 0.9452 - val_loss: 0.5494 - val_acc: 0.8796\n",
      "Epoch 177/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1716 - acc: 0.9478 - val_loss: 0.5584 - val_acc: 0.8796\n",
      "Epoch 178/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1688 - acc: 0.9491 - val_loss: 0.5596 - val_acc: 0.8828\n",
      "Epoch 179/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1706 - acc: 0.9478 - val_loss: 0.5735 - val_acc: 0.8813\n",
      "Epoch 180/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1712 - acc: 0.9471 - val_loss: 0.5555 - val_acc: 0.8827\n",
      "Epoch 181/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1728 - acc: 0.9473 - val_loss: 0.5558 - val_acc: 0.8815\n",
      "Epoch 182/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1686 - acc: 0.9485 - val_loss: 0.5673 - val_acc: 0.8811\n",
      "Epoch 183/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1668 - acc: 0.9493 - val_loss: 0.5618 - val_acc: 0.8798\n",
      "Epoch 184/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1672 - acc: 0.9501 - val_loss: 0.5576 - val_acc: 0.8798\n",
      "Epoch 185/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1720 - acc: 0.9465 - val_loss: 0.5778 - val_acc: 0.8771\n",
      "Epoch 186/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1657 - acc: 0.9497 - val_loss: 0.5846 - val_acc: 0.8717\n",
      "Epoch 187/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1675 - acc: 0.9480 - val_loss: 0.5693 - val_acc: 0.8797\n",
      "Epoch 188/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1668 - acc: 0.9485 - val_loss: 0.5679 - val_acc: 0.8804\n",
      "Epoch 189/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1669 - acc: 0.9485 - val_loss: 0.5857 - val_acc: 0.8773\n",
      "Epoch 190/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1651 - acc: 0.9501 - val_loss: 0.5718 - val_acc: 0.8791\n",
      "Epoch 191/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1649 - acc: 0.9505 - val_loss: 0.5771 - val_acc: 0.8790\n",
      "Epoch 192/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1653 - acc: 0.9490 - val_loss: 0.5712 - val_acc: 0.8809\n",
      "Epoch 193/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1627 - acc: 0.9502 - val_loss: 0.5690 - val_acc: 0.8822\n",
      "Epoch 194/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1645 - acc: 0.9500 - val_loss: 0.5705 - val_acc: 0.8796\n",
      "Epoch 195/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1631 - acc: 0.9506 - val_loss: 0.5720 - val_acc: 0.8831\n",
      "Epoch 196/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1649 - acc: 0.9495 - val_loss: 0.5795 - val_acc: 0.8812\n",
      "Epoch 197/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1627 - acc: 0.9501 - val_loss: 0.5786 - val_acc: 0.8775\n",
      "Epoch 198/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1602 - acc: 0.9509 - val_loss: 0.5732 - val_acc: 0.8840\n",
      "Epoch 199/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1592 - acc: 0.9509 - val_loss: 0.5920 - val_acc: 0.8792\n",
      "Epoch 200/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1589 - acc: 0.9512 - val_loss: 0.6070 - val_acc: 0.8741\n",
      "Epoch 201/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1617 - acc: 0.9496 - val_loss: 0.5739 - val_acc: 0.8812\n",
      "Epoch 202/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1590 - acc: 0.9515 - val_loss: 0.6221 - val_acc: 0.8686\n",
      "Epoch 203/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1638 - acc: 0.9499 - val_loss: 0.5937 - val_acc: 0.8774\n",
      "Epoch 204/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1550 - acc: 0.9529 - val_loss: 0.5943 - val_acc: 0.8751\n",
      "Epoch 205/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1575 - acc: 0.9509 - val_loss: 0.5758 - val_acc: 0.8823\n",
      "Epoch 206/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1648 - acc: 0.9484 - val_loss: 0.5791 - val_acc: 0.8820\n",
      "Epoch 207/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1560 - acc: 0.9534 - val_loss: 0.5784 - val_acc: 0.8822\n",
      "Epoch 208/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1595 - acc: 0.9510 - val_loss: 0.6169 - val_acc: 0.8723\n",
      "Epoch 209/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1585 - acc: 0.9512 - val_loss: 0.5778 - val_acc: 0.8845\n",
      "Epoch 210/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1512 - acc: 0.9542 - val_loss: 0.5750 - val_acc: 0.8825\n",
      "Epoch 211/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1576 - acc: 0.9504 - val_loss: 0.5878 - val_acc: 0.8807\n",
      "Epoch 212/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1560 - acc: 0.9521 - val_loss: 0.5906 - val_acc: 0.8812\n",
      "Epoch 213/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1523 - acc: 0.9536 - val_loss: 0.6161 - val_acc: 0.8740\n",
      "Epoch 214/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1518 - acc: 0.9539 - val_loss: 0.5887 - val_acc: 0.8825\n",
      "Epoch 215/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1538 - acc: 0.9540 - val_loss: 0.5872 - val_acc: 0.8839\n",
      "Epoch 216/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1538 - acc: 0.9538 - val_loss: 0.5859 - val_acc: 0.8820\n",
      "Epoch 217/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1504 - acc: 0.9542 - val_loss: 0.5894 - val_acc: 0.8805\n",
      "Epoch 218/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1557 - acc: 0.9515 - val_loss: 0.5980 - val_acc: 0.8782\n",
      "Epoch 219/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1554 - acc: 0.9513 - val_loss: 0.6022 - val_acc: 0.8784\n",
      "Epoch 220/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1497 - acc: 0.9547 - val_loss: 0.5903 - val_acc: 0.8826\n",
      "Epoch 221/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1522 - acc: 0.9523 - val_loss: 0.5895 - val_acc: 0.8834\n",
      "Epoch 222/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1542 - acc: 0.9519 - val_loss: 0.6022 - val_acc: 0.8763\n",
      "Epoch 223/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1493 - acc: 0.9547 - val_loss: 0.5847 - val_acc: 0.8846\n",
      "Epoch 224/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1442 - acc: 0.9573 - val_loss: 0.5940 - val_acc: 0.8830\n",
      "Epoch 225/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1520 - acc: 0.9531 - val_loss: 0.6112 - val_acc: 0.8814\n",
      "Epoch 226/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1502 - acc: 0.9551 - val_loss: 0.6012 - val_acc: 0.8798\n",
      "Epoch 227/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1469 - acc: 0.9555 - val_loss: 0.6065 - val_acc: 0.8806\n",
      "Epoch 228/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1486 - acc: 0.9545 - val_loss: 0.6044 - val_acc: 0.8790\n",
      "Epoch 229/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1464 - acc: 0.9557 - val_loss: 0.5937 - val_acc: 0.8834\n",
      "Epoch 230/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1476 - acc: 0.9547 - val_loss: 0.5970 - val_acc: 0.8801\n",
      "Epoch 231/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1512 - acc: 0.9531 - val_loss: 0.6168 - val_acc: 0.8773\n",
      "Epoch 232/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1497 - acc: 0.9530 - val_loss: 0.6115 - val_acc: 0.8793\n",
      "Epoch 233/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1454 - acc: 0.9557 - val_loss: 0.6182 - val_acc: 0.8792\n",
      "Epoch 234/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1484 - acc: 0.9536 - val_loss: 0.6236 - val_acc: 0.8766\n",
      "Epoch 235/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1460 - acc: 0.9546 - val_loss: 0.6132 - val_acc: 0.8796\n",
      "Epoch 236/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1458 - acc: 0.9557 - val_loss: 0.6389 - val_acc: 0.8743\n",
      "Epoch 237/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1444 - acc: 0.9550 - val_loss: 0.6277 - val_acc: 0.8758\n",
      "Epoch 238/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1407 - acc: 0.9578 - val_loss: 0.6101 - val_acc: 0.8789\n",
      "Epoch 239/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1392 - acc: 0.9575 - val_loss: 0.6035 - val_acc: 0.8824\n",
      "Epoch 240/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1413 - acc: 0.9570 - val_loss: 0.6153 - val_acc: 0.8816\n",
      "Epoch 241/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1427 - acc: 0.9571 - val_loss: 0.6071 - val_acc: 0.8802\n",
      "Epoch 242/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1451 - acc: 0.9561 - val_loss: 0.6439 - val_acc: 0.8761\n",
      "Epoch 243/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1419 - acc: 0.9561 - val_loss: 0.6033 - val_acc: 0.8851\n",
      "Epoch 244/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1420 - acc: 0.9568 - val_loss: 0.6096 - val_acc: 0.8798\n",
      "Epoch 245/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1420 - acc: 0.9570 - val_loss: 0.6250 - val_acc: 0.8770\n",
      "Epoch 246/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1404 - acc: 0.9570 - val_loss: 0.6398 - val_acc: 0.8727\n",
      "Epoch 247/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1471 - acc: 0.9535 - val_loss: 0.6316 - val_acc: 0.8790\n",
      "Epoch 248/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1435 - acc: 0.9557 - val_loss: 0.6130 - val_acc: 0.8812\n",
      "Epoch 249/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1387 - acc: 0.9571 - val_loss: 0.6276 - val_acc: 0.8803\n",
      "Epoch 250/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1385 - acc: 0.9573 - val_loss: 0.6229 - val_acc: 0.8795\n",
      "Epoch 251/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1388 - acc: 0.9574 - val_loss: 0.6100 - val_acc: 0.8830\n",
      "Epoch 252/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1404 - acc: 0.9568 - val_loss: 0.6220 - val_acc: 0.8798\n",
      "Epoch 253/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1369 - acc: 0.9577 - val_loss: 0.6294 - val_acc: 0.8815\n",
      "Epoch 254/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1423 - acc: 0.9562 - val_loss: 0.6561 - val_acc: 0.8736\n",
      "Epoch 255/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1363 - acc: 0.9577 - val_loss: 0.6180 - val_acc: 0.8809\n",
      "Epoch 256/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1353 - acc: 0.9588 - val_loss: 0.6060 - val_acc: 0.8838\n",
      "Epoch 257/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1421 - acc: 0.9561 - val_loss: 0.6149 - val_acc: 0.8821\n",
      "Epoch 258/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1355 - acc: 0.9591 - val_loss: 0.6286 - val_acc: 0.8805\n",
      "Epoch 259/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1401 - acc: 0.9569 - val_loss: 0.6436 - val_acc: 0.8776\n",
      "Epoch 260/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1404 - acc: 0.9569 - val_loss: 0.6377 - val_acc: 0.8789\n",
      "Epoch 261/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1372 - acc: 0.9580 - val_loss: 0.6685 - val_acc: 0.8701\n",
      "Epoch 262/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1373 - acc: 0.9583 - val_loss: 0.6259 - val_acc: 0.8821\n",
      "Epoch 263/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1342 - acc: 0.9592 - val_loss: 0.6408 - val_acc: 0.8750\n",
      "Epoch 264/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1313 - acc: 0.9597 - val_loss: 0.6290 - val_acc: 0.8812\n",
      "Epoch 265/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1441 - acc: 0.9552 - val_loss: 0.6386 - val_acc: 0.8776\n",
      "Epoch 266/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1333 - acc: 0.9593 - val_loss: 0.6291 - val_acc: 0.8827\n",
      "Epoch 267/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1354 - acc: 0.9581 - val_loss: 0.6279 - val_acc: 0.8815\n",
      "Epoch 268/500\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1335 - acc: 0.9595 - val_loss: 0.6201 - val_acc: 0.8819\n",
      "Epoch 269/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1398 - acc: 0.9565 - val_loss: 0.6266 - val_acc: 0.8831\n",
      "Epoch 270/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1330 - acc: 0.9595 - val_loss: 0.6381 - val_acc: 0.8793\n",
      "Epoch 271/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1353 - acc: 0.9586 - val_loss: 0.6435 - val_acc: 0.8774\n",
      "Epoch 272/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1328 - acc: 0.9583 - val_loss: 0.6464 - val_acc: 0.8769\n",
      "Epoch 273/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1332 - acc: 0.9594 - val_loss: 0.6268 - val_acc: 0.8833\n",
      "Epoch 274/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1283 - acc: 0.9609 - val_loss: 0.6275 - val_acc: 0.8793\n",
      "Epoch 275/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1395 - acc: 0.9566 - val_loss: 0.7025 - val_acc: 0.8689\n",
      "Epoch 276/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1321 - acc: 0.9607 - val_loss: 0.6334 - val_acc: 0.8792\n",
      "Epoch 277/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1323 - acc: 0.9590 - val_loss: 0.6478 - val_acc: 0.8776\n",
      "Epoch 278/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1333 - acc: 0.9596 - val_loss: 0.6414 - val_acc: 0.8810\n",
      "Epoch 279/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1320 - acc: 0.9593 - val_loss: 0.6412 - val_acc: 0.8817\n",
      "Epoch 280/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1275 - acc: 0.9614 - val_loss: 0.6287 - val_acc: 0.8830\n",
      "Epoch 281/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1304 - acc: 0.9609 - val_loss: 0.6489 - val_acc: 0.8751\n",
      "Epoch 282/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1304 - acc: 0.9599 - val_loss: 0.6429 - val_acc: 0.8809\n",
      "Epoch 283/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1280 - acc: 0.9610 - val_loss: 0.6298 - val_acc: 0.8845\n",
      "Epoch 284/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1323 - acc: 0.9581 - val_loss: 0.6558 - val_acc: 0.8751\n",
      "Epoch 285/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1316 - acc: 0.9594 - val_loss: 0.6573 - val_acc: 0.8812\n",
      "Epoch 286/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1238 - acc: 0.9621 - val_loss: 0.6458 - val_acc: 0.8816\n",
      "Epoch 287/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1261 - acc: 0.9617 - val_loss: 0.6509 - val_acc: 0.8781\n",
      "Epoch 288/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1272 - acc: 0.9612 - val_loss: 0.6707 - val_acc: 0.8738\n",
      "Epoch 289/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1281 - acc: 0.9620 - val_loss: 0.6456 - val_acc: 0.8795\n",
      "Epoch 290/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1255 - acc: 0.9618 - val_loss: 0.6658 - val_acc: 0.8769\n",
      "Epoch 291/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1328 - acc: 0.9600 - val_loss: 0.6708 - val_acc: 0.8779\n",
      "Epoch 292/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1328 - acc: 0.9598 - val_loss: 0.6534 - val_acc: 0.8795\n",
      "Epoch 293/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1271 - acc: 0.9619 - val_loss: 0.6764 - val_acc: 0.8799\n",
      "Epoch 294/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1260 - acc: 0.9621 - val_loss: 0.6671 - val_acc: 0.8774\n",
      "Epoch 295/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1263 - acc: 0.9612 - val_loss: 0.6443 - val_acc: 0.8810\n",
      "Epoch 296/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1264 - acc: 0.9617 - val_loss: 0.6768 - val_acc: 0.8761\n",
      "Epoch 297/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1244 - acc: 0.9621 - val_loss: 0.7066 - val_acc: 0.8696\n",
      "Epoch 298/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1241 - acc: 0.9613 - val_loss: 0.6537 - val_acc: 0.8802\n",
      "Epoch 299/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1280 - acc: 0.9613 - val_loss: 0.6654 - val_acc: 0.8777\n",
      "Epoch 300/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1270 - acc: 0.9597 - val_loss: 0.6927 - val_acc: 0.8729\n",
      "Epoch 301/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1266 - acc: 0.9612 - val_loss: 0.6784 - val_acc: 0.8735\n",
      "Epoch 302/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1213 - acc: 0.9627 - val_loss: 0.6532 - val_acc: 0.8803\n",
      "Epoch 303/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1256 - acc: 0.9616 - val_loss: 0.6619 - val_acc: 0.8774\n",
      "Epoch 304/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1244 - acc: 0.9614 - val_loss: 0.6523 - val_acc: 0.8839\n",
      "Epoch 305/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1190 - acc: 0.9640 - val_loss: 0.6586 - val_acc: 0.8816\n",
      "Epoch 306/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1257 - acc: 0.9607 - val_loss: 0.6541 - val_acc: 0.8840\n",
      "Epoch 307/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1236 - acc: 0.9624 - val_loss: 0.6673 - val_acc: 0.8775\n",
      "Epoch 308/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1259 - acc: 0.9618 - val_loss: 0.6910 - val_acc: 0.8732\n",
      "Epoch 309/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1237 - acc: 0.9609 - val_loss: 0.6714 - val_acc: 0.8773\n",
      "Epoch 310/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1177 - acc: 0.9648 - val_loss: 0.6841 - val_acc: 0.8738\n",
      "Epoch 311/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1195 - acc: 0.9634 - val_loss: 0.6795 - val_acc: 0.8786\n",
      "Epoch 312/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1190 - acc: 0.9638 - val_loss: 0.6917 - val_acc: 0.8730\n",
      "Epoch 313/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1235 - acc: 0.9636 - val_loss: 0.6815 - val_acc: 0.8763\n",
      "Epoch 314/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1192 - acc: 0.9643 - val_loss: 0.6572 - val_acc: 0.8809\n",
      "Epoch 315/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1219 - acc: 0.9629 - val_loss: 0.6675 - val_acc: 0.8818\n",
      "Epoch 316/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1141 - acc: 0.9663 - val_loss: 0.6853 - val_acc: 0.8748\n",
      "Epoch 317/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1182 - acc: 0.9647 - val_loss: 0.6745 - val_acc: 0.8785\n",
      "Epoch 318/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1197 - acc: 0.9641 - val_loss: 0.6634 - val_acc: 0.8812\n",
      "Epoch 319/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1234 - acc: 0.9620 - val_loss: 0.6826 - val_acc: 0.8772\n",
      "Epoch 320/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1187 - acc: 0.9639 - val_loss: 0.6677 - val_acc: 0.8812\n",
      "Epoch 321/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1196 - acc: 0.9636 - val_loss: 0.6779 - val_acc: 0.8774\n",
      "Epoch 322/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1211 - acc: 0.9623 - val_loss: 0.6831 - val_acc: 0.8788\n",
      "Epoch 323/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1170 - acc: 0.9643 - val_loss: 0.6916 - val_acc: 0.8757\n",
      "Epoch 324/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1194 - acc: 0.9645 - val_loss: 0.7064 - val_acc: 0.8735\n",
      "Epoch 325/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1204 - acc: 0.9623 - val_loss: 0.6733 - val_acc: 0.8797\n",
      "Epoch 326/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1156 - acc: 0.9643 - val_loss: 0.6730 - val_acc: 0.8783\n",
      "Epoch 327/500\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1107 - acc: 0.9678 - val_loss: 0.6852 - val_acc: 0.8751\n",
      "Epoch 328/500\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1144 - acc: 0.9663 - val_loss: 0.6694 - val_acc: 0.8808\n",
      "Epoch 329/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1185 - acc: 0.9643 - val_loss: 0.6670 - val_acc: 0.8806\n",
      "Epoch 330/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1163 - acc: 0.9641 - val_loss: 0.6673 - val_acc: 0.8818\n",
      "Epoch 331/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1164 - acc: 0.9644 - val_loss: 0.6826 - val_acc: 0.8793\n",
      "Epoch 332/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1141 - acc: 0.9648 - val_loss: 0.6860 - val_acc: 0.8801\n",
      "Epoch 333/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1187 - acc: 0.9638 - val_loss: 0.7048 - val_acc: 0.8751\n",
      "Epoch 334/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1139 - acc: 0.9657 - val_loss: 0.6880 - val_acc: 0.8768\n",
      "Epoch 335/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1145 - acc: 0.9660 - val_loss: 0.6766 - val_acc: 0.8811\n",
      "Epoch 336/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1154 - acc: 0.9645 - val_loss: 0.6823 - val_acc: 0.8787\n",
      "Epoch 337/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1137 - acc: 0.9657 - val_loss: 0.6825 - val_acc: 0.8774\n",
      "Epoch 338/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1129 - acc: 0.9653 - val_loss: 0.6762 - val_acc: 0.8831\n",
      "Epoch 339/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1161 - acc: 0.9639 - val_loss: 0.7093 - val_acc: 0.8753\n",
      "Epoch 340/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1145 - acc: 0.9646 - val_loss: 0.7217 - val_acc: 0.8738\n",
      "Epoch 341/500\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1129 - acc: 0.9661 - val_loss: 0.6884 - val_acc: 0.8823\n",
      "Epoch 342/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1145 - acc: 0.9656 - val_loss: 0.7084 - val_acc: 0.8759\n",
      "Epoch 343/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1123 - acc: 0.9656 - val_loss: 0.7122 - val_acc: 0.8723\n",
      "Epoch 344/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1131 - acc: 0.9660 - val_loss: 0.7068 - val_acc: 0.8735\n",
      "Epoch 345/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1186 - acc: 0.9638 - val_loss: 0.7179 - val_acc: 0.8767\n",
      "Epoch 346/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1101 - acc: 0.9674 - val_loss: 0.7002 - val_acc: 0.8760\n",
      "Epoch 347/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1133 - acc: 0.9658 - val_loss: 0.7109 - val_acc: 0.8742\n",
      "Epoch 348/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1119 - acc: 0.9660 - val_loss: 0.6900 - val_acc: 0.8797\n",
      "Epoch 349/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1132 - acc: 0.9649 - val_loss: 0.7246 - val_acc: 0.8738\n",
      "Epoch 350/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1109 - acc: 0.9670 - val_loss: 0.7150 - val_acc: 0.8779\n",
      "Epoch 351/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1119 - acc: 0.9663 - val_loss: 0.6942 - val_acc: 0.8773\n",
      "Epoch 352/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1102 - acc: 0.9662 - val_loss: 0.6870 - val_acc: 0.8794\n",
      "Epoch 353/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1088 - acc: 0.9670 - val_loss: 0.6987 - val_acc: 0.8814\n",
      "Epoch 354/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1100 - acc: 0.9669 - val_loss: 0.6872 - val_acc: 0.8812\n",
      "Epoch 355/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1059 - acc: 0.9687 - val_loss: 0.6916 - val_acc: 0.8788\n",
      "Epoch 356/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1129 - acc: 0.9655 - val_loss: 0.7019 - val_acc: 0.8790\n",
      "Epoch 357/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1121 - acc: 0.9644 - val_loss: 0.6944 - val_acc: 0.8791\n",
      "Epoch 358/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1105 - acc: 0.9664 - val_loss: 0.6856 - val_acc: 0.8812\n",
      "Epoch 359/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1075 - acc: 0.9674 - val_loss: 0.6950 - val_acc: 0.8796\n",
      "Epoch 360/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1117 - acc: 0.9653 - val_loss: 0.6897 - val_acc: 0.8819\n",
      "Epoch 361/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1087 - acc: 0.9669 - val_loss: 0.7395 - val_acc: 0.8721\n",
      "Epoch 362/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1054 - acc: 0.9678 - val_loss: 0.7103 - val_acc: 0.8757\n",
      "Epoch 363/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1110 - acc: 0.9652 - val_loss: 0.7069 - val_acc: 0.8783\n",
      "Epoch 364/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1031 - acc: 0.9699 - val_loss: 0.7035 - val_acc: 0.8803\n",
      "Epoch 365/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1101 - acc: 0.9663 - val_loss: 0.7159 - val_acc: 0.8765\n",
      "Epoch 366/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1077 - acc: 0.9671 - val_loss: 0.7044 - val_acc: 0.8806\n",
      "Epoch 367/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1107 - acc: 0.9664 - val_loss: 0.7145 - val_acc: 0.8759\n",
      "Epoch 368/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1077 - acc: 0.9666 - val_loss: 0.7177 - val_acc: 0.8769\n",
      "Epoch 369/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1084 - acc: 0.9664 - val_loss: 0.7138 - val_acc: 0.8795\n",
      "Epoch 370/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1049 - acc: 0.9680 - val_loss: 0.7034 - val_acc: 0.8787\n",
      "Epoch 371/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1064 - acc: 0.9677 - val_loss: 0.7186 - val_acc: 0.8773\n",
      "Epoch 372/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1032 - acc: 0.9683 - val_loss: 0.7221 - val_acc: 0.8766\n",
      "Epoch 373/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1097 - acc: 0.9658 - val_loss: 0.7048 - val_acc: 0.8795\n",
      "Epoch 374/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1031 - acc: 0.9695 - val_loss: 0.7356 - val_acc: 0.8733\n",
      "Epoch 375/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1084 - acc: 0.9675 - val_loss: 0.7197 - val_acc: 0.8790\n",
      "Epoch 376/500\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1093 - acc: 0.9662 - val_loss: 0.7208 - val_acc: 0.8757\n",
      "Epoch 377/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1038 - acc: 0.9687 - val_loss: 0.7234 - val_acc: 0.8789\n",
      "Epoch 378/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1018 - acc: 0.9700 - val_loss: 0.7077 - val_acc: 0.8793\n",
      "Epoch 379/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1043 - acc: 0.9684 - val_loss: 0.7248 - val_acc: 0.8807\n",
      "Epoch 380/500\n",
      "34108/34108 [==============================] - 0s 13us/step - loss: 0.1058 - acc: 0.9682 - val_loss: 0.7065 - val_acc: 0.8798\n",
      "Epoch 381/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1041 - acc: 0.9693 - val_loss: 0.7125 - val_acc: 0.8791\n",
      "Epoch 382/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1077 - acc: 0.9666 - val_loss: 0.7239 - val_acc: 0.8767\n",
      "Epoch 383/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1020 - acc: 0.9694 - val_loss: 0.7112 - val_acc: 0.8808\n",
      "Epoch 384/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1061 - acc: 0.9678 - val_loss: 0.7193 - val_acc: 0.8769\n",
      "Epoch 385/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1067 - acc: 0.9670 - val_loss: 0.7045 - val_acc: 0.8819\n",
      "Epoch 386/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1029 - acc: 0.9684 - val_loss: 0.7207 - val_acc: 0.8784\n",
      "Epoch 387/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1062 - acc: 0.9673 - val_loss: 0.7143 - val_acc: 0.8783\n",
      "Epoch 388/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1028 - acc: 0.9687 - val_loss: 0.7494 - val_acc: 0.8752\n",
      "Epoch 389/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1119 - acc: 0.9657 - val_loss: 0.7038 - val_acc: 0.8814\n",
      "Epoch 390/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1043 - acc: 0.9690 - val_loss: 0.7365 - val_acc: 0.8760\n",
      "Epoch 391/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0953 - acc: 0.9724 - val_loss: 0.7104 - val_acc: 0.8817\n",
      "Epoch 392/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1011 - acc: 0.9696 - val_loss: 0.7155 - val_acc: 0.8817\n",
      "Epoch 393/500\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.1009 - acc: 0.9696 - val_loss: 0.7136 - val_acc: 0.8817\n",
      "Epoch 394/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1008 - acc: 0.9696 - val_loss: 0.7522 - val_acc: 0.8732\n",
      "Epoch 395/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1030 - acc: 0.9692 - val_loss: 0.7258 - val_acc: 0.8804\n",
      "Epoch 396/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1067 - acc: 0.9670 - val_loss: 0.7270 - val_acc: 0.8793\n",
      "Epoch 397/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.0985 - acc: 0.9709 - val_loss: 0.7576 - val_acc: 0.8727\n",
      "Epoch 398/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1004 - acc: 0.9691 - val_loss: 0.7243 - val_acc: 0.8799\n",
      "Epoch 399/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1015 - acc: 0.9686 - val_loss: 0.7299 - val_acc: 0.8778\n",
      "Epoch 400/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0974 - acc: 0.9704 - val_loss: 0.7277 - val_acc: 0.8771\n",
      "Epoch 401/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1042 - acc: 0.9681 - val_loss: 0.7367 - val_acc: 0.8784\n",
      "Epoch 402/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1031 - acc: 0.9689 - val_loss: 0.7269 - val_acc: 0.8771\n",
      "Epoch 403/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0998 - acc: 0.9708 - val_loss: 0.7313 - val_acc: 0.8777\n",
      "Epoch 404/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0995 - acc: 0.9703 - val_loss: 0.7237 - val_acc: 0.8809\n",
      "Epoch 405/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0999 - acc: 0.9692 - val_loss: 0.7371 - val_acc: 0.8765\n",
      "Epoch 406/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0967 - acc: 0.9712 - val_loss: 0.7384 - val_acc: 0.8799\n",
      "Epoch 407/500\n",
      "34108/34108 [==============================] - ETA: 0s - loss: 0.1005 - acc: 0.968 - 1s 15us/step - loss: 0.1005 - acc: 0.9691 - val_loss: 0.7299 - val_acc: 0.8800\n",
      "Epoch 408/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1042 - acc: 0.9684 - val_loss: 0.7388 - val_acc: 0.8780\n",
      "Epoch 409/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0986 - acc: 0.9697 - val_loss: 0.7423 - val_acc: 0.8788\n",
      "Epoch 410/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.0995 - acc: 0.9696 - val_loss: 0.7748 - val_acc: 0.8782\n",
      "Epoch 411/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0972 - acc: 0.9713 - val_loss: 0.7298 - val_acc: 0.8814\n",
      "Epoch 412/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.1057 - acc: 0.9678 - val_loss: 0.7529 - val_acc: 0.8730\n",
      "Epoch 413/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.0963 - acc: 0.9714 - val_loss: 0.7246 - val_acc: 0.8812\n",
      "Epoch 414/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.0912 - acc: 0.9738 - val_loss: 0.7331 - val_acc: 0.8786\n",
      "Epoch 415/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0938 - acc: 0.9724 - val_loss: 0.7381 - val_acc: 0.8811\n",
      "Epoch 416/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1026 - acc: 0.9684 - val_loss: 0.7488 - val_acc: 0.8750\n",
      "Epoch 417/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1002 - acc: 0.9691 - val_loss: 0.7507 - val_acc: 0.8750\n",
      "Epoch 418/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0910 - acc: 0.9738 - val_loss: 0.7313 - val_acc: 0.8800\n",
      "Epoch 419/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.1013 - acc: 0.9700 - val_loss: 0.7385 - val_acc: 0.8796\n",
      "Epoch 420/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.0955 - acc: 0.9714 - val_loss: 0.7258 - val_acc: 0.8821\n",
      "Epoch 421/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.0931 - acc: 0.9725 - val_loss: 0.7447 - val_acc: 0.8778\n",
      "Epoch 422/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.0939 - acc: 0.9715 - val_loss: 0.7475 - val_acc: 0.8797\n",
      "Epoch 423/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0988 - acc: 0.9695 - val_loss: 0.7300 - val_acc: 0.8817\n",
      "Epoch 424/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.0920 - acc: 0.9732 - val_loss: 0.7392 - val_acc: 0.8801\n",
      "Epoch 425/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.0991 - acc: 0.9695 - val_loss: 0.7541 - val_acc: 0.8779\n",
      "Epoch 426/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0971 - acc: 0.9714 - val_loss: 0.7368 - val_acc: 0.8798\n",
      "Epoch 427/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0969 - acc: 0.9703 - val_loss: 0.7432 - val_acc: 0.8797\n",
      "Epoch 428/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0916 - acc: 0.9735 - val_loss: 0.7394 - val_acc: 0.8779\n",
      "Epoch 429/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0964 - acc: 0.9703 - val_loss: 0.7301 - val_acc: 0.8826\n",
      "Epoch 430/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.0973 - acc: 0.9705 - val_loss: 0.7442 - val_acc: 0.8782\n",
      "Epoch 431/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0964 - acc: 0.9709 - val_loss: 0.7946 - val_acc: 0.8689\n",
      "Epoch 432/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0986 - acc: 0.9704 - val_loss: 0.7508 - val_acc: 0.8784\n",
      "Epoch 433/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0949 - acc: 0.9713 - val_loss: 0.7664 - val_acc: 0.8761\n",
      "Epoch 434/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0955 - acc: 0.9711 - val_loss: 0.7348 - val_acc: 0.8820\n",
      "Epoch 435/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0932 - acc: 0.9723 - val_loss: 0.7428 - val_acc: 0.8802\n",
      "Epoch 436/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0983 - acc: 0.9701 - val_loss: 0.7454 - val_acc: 0.8815\n",
      "Epoch 437/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0894 - acc: 0.9743 - val_loss: 0.7501 - val_acc: 0.8800\n",
      "Epoch 438/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.0967 - acc: 0.9705 - val_loss: 0.7462 - val_acc: 0.8793\n",
      "Epoch 439/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0961 - acc: 0.9712 - val_loss: 0.7646 - val_acc: 0.8751\n",
      "Epoch 440/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0886 - acc: 0.9743 - val_loss: 0.7521 - val_acc: 0.8800\n",
      "Epoch 441/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0921 - acc: 0.9721 - val_loss: 0.7510 - val_acc: 0.8783\n",
      "Epoch 442/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0926 - acc: 0.9722 - val_loss: 0.7606 - val_acc: 0.8784\n",
      "Epoch 443/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.0941 - acc: 0.9714 - val_loss: 0.7788 - val_acc: 0.8732\n",
      "Epoch 444/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0881 - acc: 0.9744 - val_loss: 0.7429 - val_acc: 0.8826\n",
      "Epoch 445/500\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0949 - acc: 0.9713 - val_loss: 0.7481 - val_acc: 0.8803\n",
      "Epoch 446/500\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0943 - acc: 0.9719 - val_loss: 0.7666 - val_acc: 0.8773\n",
      "Epoch 447/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0916 - acc: 0.9722 - val_loss: 0.7612 - val_acc: 0.8767\n",
      "Epoch 448/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0974 - acc: 0.9701 - val_loss: 0.7753 - val_acc: 0.8747\n",
      "Epoch 449/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0932 - acc: 0.9724 - val_loss: 0.7629 - val_acc: 0.8773\n",
      "Epoch 450/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.0956 - acc: 0.9708 - val_loss: 0.7875 - val_acc: 0.8788\n",
      "Epoch 451/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0931 - acc: 0.9714 - val_loss: 0.7844 - val_acc: 0.8746\n",
      "Epoch 452/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0954 - acc: 0.9712 - val_loss: 0.7772 - val_acc: 0.8744\n",
      "Epoch 453/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0920 - acc: 0.9731 - val_loss: 0.7706 - val_acc: 0.8751\n",
      "Epoch 454/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0897 - acc: 0.9726 - val_loss: 0.7525 - val_acc: 0.8793\n",
      "Epoch 455/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0916 - acc: 0.9725 - val_loss: 0.7593 - val_acc: 0.8784\n",
      "Epoch 456/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0855 - acc: 0.9757 - val_loss: 0.7600 - val_acc: 0.8780\n",
      "Epoch 457/500\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0887 - acc: 0.9735 - val_loss: 0.8070 - val_acc: 0.8727\n",
      "Epoch 458/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0893 - acc: 0.9741 - val_loss: 0.7676 - val_acc: 0.8765\n",
      "Epoch 459/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0957 - acc: 0.9706 - val_loss: 0.7590 - val_acc: 0.8807\n",
      "Epoch 460/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0930 - acc: 0.9714 - val_loss: 0.7632 - val_acc: 0.8824\n",
      "Epoch 461/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0953 - acc: 0.9718 - val_loss: 0.7645 - val_acc: 0.8808\n",
      "Epoch 462/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0921 - acc: 0.9726 - val_loss: 0.7593 - val_acc: 0.8811\n",
      "Epoch 463/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.0843 - acc: 0.9751 - val_loss: 0.8190 - val_acc: 0.8690\n",
      "Epoch 464/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.0880 - acc: 0.9732 - val_loss: 0.7911 - val_acc: 0.8737\n",
      "Epoch 465/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.1018 - acc: 0.9693 - val_loss: 0.7672 - val_acc: 0.8790\n",
      "Epoch 466/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0874 - acc: 0.9746 - val_loss: 0.7731 - val_acc: 0.8769\n",
      "Epoch 467/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0824 - acc: 0.9762 - val_loss: 0.7860 - val_acc: 0.8747\n",
      "Epoch 468/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0846 - acc: 0.9765 - val_loss: 0.7636 - val_acc: 0.8804\n",
      "Epoch 469/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.0868 - acc: 0.9747 - val_loss: 0.8061 - val_acc: 0.8722\n",
      "Epoch 470/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.0890 - acc: 0.9734 - val_loss: 0.7639 - val_acc: 0.8809\n",
      "Epoch 471/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0930 - acc: 0.9712 - val_loss: 0.7767 - val_acc: 0.8791\n",
      "Epoch 472/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0929 - acc: 0.9700 - val_loss: 0.7971 - val_acc: 0.8750\n",
      "Epoch 473/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.0875 - acc: 0.9746 - val_loss: 0.7678 - val_acc: 0.8792\n",
      "Epoch 474/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0956 - acc: 0.9705 - val_loss: 0.7873 - val_acc: 0.8733\n",
      "Epoch 475/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0878 - acc: 0.9735 - val_loss: 0.7882 - val_acc: 0.8728\n",
      "Epoch 476/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0839 - acc: 0.9748 - val_loss: 0.7799 - val_acc: 0.8795\n",
      "Epoch 477/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0850 - acc: 0.9748 - val_loss: 0.7833 - val_acc: 0.8752\n",
      "Epoch 478/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0857 - acc: 0.9746 - val_loss: 0.8040 - val_acc: 0.8765\n",
      "Epoch 479/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.0898 - acc: 0.9716 - val_loss: 0.8038 - val_acc: 0.8742\n",
      "Epoch 480/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0883 - acc: 0.9741 - val_loss: 0.7821 - val_acc: 0.8772\n",
      "Epoch 481/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0859 - acc: 0.9745 - val_loss: 0.7880 - val_acc: 0.8783\n",
      "Epoch 482/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.0837 - acc: 0.9758 - val_loss: 0.7974 - val_acc: 0.8738\n",
      "Epoch 483/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0884 - acc: 0.9734 - val_loss: 0.8101 - val_acc: 0.8701\n",
      "Epoch 484/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0889 - acc: 0.9726 - val_loss: 0.7980 - val_acc: 0.8763\n",
      "Epoch 485/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.0855 - acc: 0.9748 - val_loss: 0.8000 - val_acc: 0.8727\n",
      "Epoch 486/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0821 - acc: 0.9756 - val_loss: 0.7966 - val_acc: 0.8753\n",
      "Epoch 487/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0864 - acc: 0.9744 - val_loss: 0.7905 - val_acc: 0.8769\n",
      "Epoch 488/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0893 - acc: 0.9733 - val_loss: 0.7966 - val_acc: 0.8769\n",
      "Epoch 489/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0812 - acc: 0.9768 - val_loss: 0.7949 - val_acc: 0.8756\n",
      "Epoch 490/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0869 - acc: 0.9747 - val_loss: 0.7828 - val_acc: 0.8778\n",
      "Epoch 491/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0880 - acc: 0.9734 - val_loss: 0.8128 - val_acc: 0.8707\n",
      "Epoch 492/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0888 - acc: 0.9725 - val_loss: 0.8004 - val_acc: 0.8774\n",
      "Epoch 493/500\n",
      "34108/34108 [==============================] - 0s 15us/step - loss: 0.0844 - acc: 0.9745 - val_loss: 0.7878 - val_acc: 0.8785\n",
      "Epoch 494/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0829 - acc: 0.9754 - val_loss: 0.7895 - val_acc: 0.8776\n",
      "Epoch 495/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0860 - acc: 0.9745 - val_loss: 0.7854 - val_acc: 0.8757\n",
      "Epoch 496/500\n",
      "34108/34108 [==============================] - 0s 14us/step - loss: 0.0878 - acc: 0.9735 - val_loss: 0.7929 - val_acc: 0.8766\n",
      "Epoch 497/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0869 - acc: 0.9739 - val_loss: 0.7769 - val_acc: 0.8812\n",
      "Epoch 498/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0846 - acc: 0.9749 - val_loss: 0.7711 - val_acc: 0.8816\n",
      "Epoch 499/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0844 - acc: 0.9743 - val_loss: 0.7893 - val_acc: 0.8774\n",
      "Epoch 500/500\n",
      "34108/34108 [==============================] - 1s 15us/step - loss: 0.0792 - acc: 0.9772 - val_loss: 0.7895 - val_acc: 0.8785\n",
      "Train on 34108 samples, validate on 12117 samples\n",
      "Epoch 1/500\n",
      "34108/34108 [==============================] - 1s 37us/step - loss: 1.2905 - acc: 0.4875 - val_loss: 1.0029 - val_acc: 0.6402\n",
      "Epoch 2/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.9142 - acc: 0.6976 - val_loss: 0.8160 - val_acc: 0.7445\n",
      "Epoch 3/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.7689 - acc: 0.7596 - val_loss: 0.7851 - val_acc: 0.7606\n",
      "Epoch 4/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.6923 - acc: 0.7876 - val_loss: 0.6841 - val_acc: 0.7886\n",
      "Epoch 5/500\n",
      "34108/34108 [==============================] - 1s 19us/step - loss: 0.6439 - acc: 0.8031 - val_loss: 0.6541 - val_acc: 0.7966\n",
      "Epoch 6/500\n",
      "34108/34108 [==============================] - 1s 20us/step - loss: 0.6069 - acc: 0.8139 - val_loss: 0.6363 - val_acc: 0.8056\n",
      "Epoch 7/500\n",
      "34108/34108 [==============================] - 1s 19us/step - loss: 0.5805 - acc: 0.8224 - val_loss: 0.6358 - val_acc: 0.8072\n",
      "Epoch 8/500\n",
      "34108/34108 [==============================] - 1s 20us/step - loss: 0.5581 - acc: 0.8275 - val_loss: 0.6122 - val_acc: 0.8170\n",
      "Epoch 9/500\n",
      "34108/34108 [==============================] - 1s 19us/step - loss: 0.5383 - acc: 0.8357 - val_loss: 0.5869 - val_acc: 0.8240\n",
      "Epoch 10/500\n",
      "34108/34108 [==============================] - 1s 20us/step - loss: 0.5145 - acc: 0.8444 - val_loss: 0.5680 - val_acc: 0.8292\n",
      "Epoch 11/500\n",
      "34108/34108 [==============================] - 1s 22us/step - loss: 0.4990 - acc: 0.8470 - val_loss: 0.5628 - val_acc: 0.8303\n",
      "Epoch 12/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.4837 - acc: 0.8509 - val_loss: 0.5795 - val_acc: 0.8271\n",
      "Epoch 13/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.4678 - acc: 0.8581 - val_loss: 0.5562 - val_acc: 0.8346\n",
      "Epoch 14/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.4616 - acc: 0.8593 - val_loss: 0.5307 - val_acc: 0.8410\n",
      "Epoch 15/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.4492 - acc: 0.8625 - val_loss: 0.5280 - val_acc: 0.8445\n",
      "Epoch 16/500\n",
      "34108/34108 [==============================] - 1s 19us/step - loss: 0.4367 - acc: 0.8663 - val_loss: 0.5369 - val_acc: 0.8434\n",
      "Epoch 17/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.4287 - acc: 0.8689 - val_loss: 0.5136 - val_acc: 0.8506\n",
      "Epoch 18/500\n",
      "34108/34108 [==============================] - 1s 19us/step - loss: 0.4140 - acc: 0.8737 - val_loss: 0.5461 - val_acc: 0.8439\n",
      "Epoch 19/500\n",
      "34108/34108 [==============================] - 1s 20us/step - loss: 0.4087 - acc: 0.8759 - val_loss: 0.5265 - val_acc: 0.8434\n",
      "Epoch 20/500\n",
      "34108/34108 [==============================] - 1s 19us/step - loss: 0.4008 - acc: 0.8783 - val_loss: 0.5012 - val_acc: 0.8547\n",
      "Epoch 21/500\n",
      "34108/34108 [==============================] - 1s 22us/step - loss: 0.3919 - acc: 0.8823 - val_loss: 0.5044 - val_acc: 0.8539\n",
      "Epoch 22/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.3826 - acc: 0.8841 - val_loss: 0.5041 - val_acc: 0.8579\n",
      "Epoch 23/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.3808 - acc: 0.8854 - val_loss: 0.5540 - val_acc: 0.8444\n",
      "Epoch 24/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.3722 - acc: 0.8870 - val_loss: 0.5128 - val_acc: 0.8523\n",
      "Epoch 25/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.3626 - acc: 0.8906 - val_loss: 0.4889 - val_acc: 0.8620\n",
      "Epoch 26/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.3586 - acc: 0.8912 - val_loss: 0.4805 - val_acc: 0.8658\n",
      "Epoch 27/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.3495 - acc: 0.8935 - val_loss: 0.4938 - val_acc: 0.8605\n",
      "Epoch 28/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.3450 - acc: 0.8947 - val_loss: 0.4916 - val_acc: 0.8597\n",
      "Epoch 29/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.3419 - acc: 0.8965 - val_loss: 0.4793 - val_acc: 0.8680\n",
      "Epoch 30/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.3313 - acc: 0.9002 - val_loss: 0.4891 - val_acc: 0.8639\n",
      "Epoch 31/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.3283 - acc: 0.9006 - val_loss: 0.5103 - val_acc: 0.8604\n",
      "Epoch 32/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.3234 - acc: 0.9020 - val_loss: 0.4945 - val_acc: 0.8675\n",
      "Epoch 33/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.3188 - acc: 0.9052 - val_loss: 0.4853 - val_acc: 0.8679\n",
      "Epoch 34/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.3175 - acc: 0.9034 - val_loss: 0.4779 - val_acc: 0.8708\n",
      "Epoch 35/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.3098 - acc: 0.9062 - val_loss: 0.4703 - val_acc: 0.8724\n",
      "Epoch 36/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.3049 - acc: 0.9070 - val_loss: 0.4842 - val_acc: 0.8700\n",
      "Epoch 37/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.3054 - acc: 0.9077 - val_loss: 0.4952 - val_acc: 0.8691\n",
      "Epoch 38/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.3014 - acc: 0.9090 - val_loss: 0.4886 - val_acc: 0.8712\n",
      "Epoch 39/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.2979 - acc: 0.9093 - val_loss: 0.4694 - val_acc: 0.8741\n",
      "Epoch 40/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2924 - acc: 0.9108 - val_loss: 0.4735 - val_acc: 0.8727\n",
      "Epoch 41/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2904 - acc: 0.9108 - val_loss: 0.4647 - val_acc: 0.8751\n",
      "Epoch 42/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2813 - acc: 0.9144 - val_loss: 0.4802 - val_acc: 0.8747\n",
      "Epoch 43/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2821 - acc: 0.9153 - val_loss: 0.4678 - val_acc: 0.8781\n",
      "Epoch 44/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2784 - acc: 0.9167 - val_loss: 0.4647 - val_acc: 0.8762\n",
      "Epoch 45/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2764 - acc: 0.9162 - val_loss: 0.4943 - val_acc: 0.8701\n",
      "Epoch 46/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2705 - acc: 0.9187 - val_loss: 0.4658 - val_acc: 0.8784\n",
      "Epoch 47/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2662 - acc: 0.9189 - val_loss: 0.4758 - val_acc: 0.8767\n",
      "Epoch 48/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2673 - acc: 0.9198 - val_loss: 0.4824 - val_acc: 0.8735\n",
      "Epoch 49/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2629 - acc: 0.9199 - val_loss: 0.4986 - val_acc: 0.8716\n",
      "Epoch 50/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2647 - acc: 0.9205 - val_loss: 0.4800 - val_acc: 0.8753\n",
      "Epoch 51/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2558 - acc: 0.9241 - val_loss: 0.4874 - val_acc: 0.8756\n",
      "Epoch 52/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2542 - acc: 0.9236 - val_loss: 0.4792 - val_acc: 0.8795\n",
      "Epoch 53/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.2550 - acc: 0.9213 - val_loss: 0.4914 - val_acc: 0.8758\n",
      "Epoch 54/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2519 - acc: 0.9234 - val_loss: 0.4776 - val_acc: 0.8779\n",
      "Epoch 55/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2500 - acc: 0.9244 - val_loss: 0.5015 - val_acc: 0.8714\n",
      "Epoch 56/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2468 - acc: 0.9258 - val_loss: 0.4795 - val_acc: 0.8807\n",
      "Epoch 57/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2417 - acc: 0.9273 - val_loss: 0.4858 - val_acc: 0.8788\n",
      "Epoch 58/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2384 - acc: 0.9291 - val_loss: 0.4860 - val_acc: 0.8775\n",
      "Epoch 59/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2358 - acc: 0.9283 - val_loss: 0.4864 - val_acc: 0.8793\n",
      "Epoch 60/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2353 - acc: 0.9281 - val_loss: 0.4892 - val_acc: 0.8774\n",
      "Epoch 61/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2330 - acc: 0.9302 - val_loss: 0.4735 - val_acc: 0.8813\n",
      "Epoch 62/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2323 - acc: 0.9293 - val_loss: 0.4829 - val_acc: 0.8779\n",
      "Epoch 63/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2274 - acc: 0.9316 - val_loss: 0.4739 - val_acc: 0.8815\n",
      "Epoch 64/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2253 - acc: 0.9309 - val_loss: 0.4990 - val_acc: 0.8760\n",
      "Epoch 65/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2260 - acc: 0.9317 - val_loss: 0.5019 - val_acc: 0.8751\n",
      "Epoch 66/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2211 - acc: 0.9321 - val_loss: 0.4743 - val_acc: 0.8864\n",
      "Epoch 67/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2213 - acc: 0.9326 - val_loss: 0.4750 - val_acc: 0.8850\n",
      "Epoch 68/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.2168 - acc: 0.9331 - val_loss: 0.4781 - val_acc: 0.8878\n",
      "Epoch 69/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2147 - acc: 0.9355 - val_loss: 0.4811 - val_acc: 0.8844\n",
      "Epoch 70/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2123 - acc: 0.9363 - val_loss: 0.5123 - val_acc: 0.8760\n",
      "Epoch 71/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2098 - acc: 0.9374 - val_loss: 0.5202 - val_acc: 0.8712\n",
      "Epoch 72/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2088 - acc: 0.9373 - val_loss: 0.4767 - val_acc: 0.8853\n",
      "Epoch 73/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.2055 - acc: 0.9388 - val_loss: 0.5026 - val_acc: 0.8771\n",
      "Epoch 74/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2087 - acc: 0.9356 - val_loss: 0.4969 - val_acc: 0.8835\n",
      "Epoch 75/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2026 - acc: 0.9391 - val_loss: 0.5056 - val_acc: 0.8821\n",
      "Epoch 76/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2049 - acc: 0.9381 - val_loss: 0.4967 - val_acc: 0.8835\n",
      "Epoch 77/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.1991 - acc: 0.9398 - val_loss: 0.5036 - val_acc: 0.8796\n",
      "Epoch 78/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2000 - acc: 0.9389 - val_loss: 0.4986 - val_acc: 0.8811\n",
      "Epoch 79/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1983 - acc: 0.9394 - val_loss: 0.5003 - val_acc: 0.8839\n",
      "Epoch 80/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.2002 - acc: 0.9394 - val_loss: 0.5059 - val_acc: 0.8831\n",
      "Epoch 81/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.1941 - acc: 0.9416 - val_loss: 0.5016 - val_acc: 0.8821\n",
      "Epoch 82/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1923 - acc: 0.9416 - val_loss: 0.5174 - val_acc: 0.8793\n",
      "Epoch 83/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1909 - acc: 0.9410 - val_loss: 0.5069 - val_acc: 0.8817\n",
      "Epoch 84/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1923 - acc: 0.9412 - val_loss: 0.5074 - val_acc: 0.8822\n",
      "Epoch 85/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1899 - acc: 0.9421 - val_loss: 0.5020 - val_acc: 0.8845\n",
      "Epoch 86/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1859 - acc: 0.9446 - val_loss: 0.5022 - val_acc: 0.8845\n",
      "Epoch 87/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1858 - acc: 0.9430 - val_loss: 0.5192 - val_acc: 0.8812\n",
      "Epoch 88/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1833 - acc: 0.9450 - val_loss: 0.5128 - val_acc: 0.8822\n",
      "Epoch 89/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1818 - acc: 0.9440 - val_loss: 0.5231 - val_acc: 0.8800\n",
      "Epoch 90/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1820 - acc: 0.9440 - val_loss: 0.5044 - val_acc: 0.8843\n",
      "Epoch 91/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1800 - acc: 0.9449 - val_loss: 0.5259 - val_acc: 0.8799\n",
      "Epoch 92/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1830 - acc: 0.9442 - val_loss: 0.5448 - val_acc: 0.8755\n",
      "Epoch 93/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1771 - acc: 0.9456 - val_loss: 0.5255 - val_acc: 0.8800\n",
      "Epoch 94/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1757 - acc: 0.9460 - val_loss: 0.5147 - val_acc: 0.8837\n",
      "Epoch 95/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1733 - acc: 0.9478 - val_loss: 0.5045 - val_acc: 0.8896\n",
      "Epoch 96/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1719 - acc: 0.9481 - val_loss: 0.5246 - val_acc: 0.8826\n",
      "Epoch 97/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1725 - acc: 0.9475 - val_loss: 0.5071 - val_acc: 0.8839\n",
      "Epoch 98/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1680 - acc: 0.9504 - val_loss: 0.5176 - val_acc: 0.8877\n",
      "Epoch 99/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1643 - acc: 0.9501 - val_loss: 0.5264 - val_acc: 0.8848\n",
      "Epoch 100/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1680 - acc: 0.9493 - val_loss: 0.5315 - val_acc: 0.8807\n",
      "Epoch 101/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1678 - acc: 0.9494 - val_loss: 0.5239 - val_acc: 0.8814\n",
      "Epoch 102/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1653 - acc: 0.9502 - val_loss: 0.5331 - val_acc: 0.8810\n",
      "Epoch 103/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1654 - acc: 0.9489 - val_loss: 0.5299 - val_acc: 0.8817\n",
      "Epoch 104/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1596 - acc: 0.9511 - val_loss: 0.5306 - val_acc: 0.8842\n",
      "Epoch 105/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1604 - acc: 0.9518 - val_loss: 0.5258 - val_acc: 0.8855\n",
      "Epoch 106/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1601 - acc: 0.9514 - val_loss: 0.5602 - val_acc: 0.8783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1563 - acc: 0.9522 - val_loss: 0.5325 - val_acc: 0.8835\n",
      "Epoch 108/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1563 - acc: 0.9533 - val_loss: 0.5180 - val_acc: 0.8870\n",
      "Epoch 109/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1565 - acc: 0.9529 - val_loss: 0.5425 - val_acc: 0.8827\n",
      "Epoch 110/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1568 - acc: 0.9516 - val_loss: 0.5457 - val_acc: 0.8826\n",
      "Epoch 111/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1545 - acc: 0.9527 - val_loss: 0.5464 - val_acc: 0.8817\n",
      "Epoch 112/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1566 - acc: 0.9529 - val_loss: 0.5383 - val_acc: 0.8807\n",
      "Epoch 113/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.1528 - acc: 0.9534 - val_loss: 0.5467 - val_acc: 0.8822\n",
      "Epoch 114/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.1485 - acc: 0.9562 - val_loss: 0.5586 - val_acc: 0.8806\n",
      "Epoch 115/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1502 - acc: 0.9551 - val_loss: 0.5593 - val_acc: 0.8798\n",
      "Epoch 116/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1485 - acc: 0.9544 - val_loss: 0.5564 - val_acc: 0.8814\n",
      "Epoch 117/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1475 - acc: 0.9550 - val_loss: 0.5604 - val_acc: 0.8749\n",
      "Epoch 118/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1489 - acc: 0.9543 - val_loss: 0.5624 - val_acc: 0.8782\n",
      "Epoch 119/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1440 - acc: 0.9569 - val_loss: 0.5596 - val_acc: 0.8809\n",
      "Epoch 120/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1438 - acc: 0.9560 - val_loss: 0.5631 - val_acc: 0.8821\n",
      "Epoch 121/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1407 - acc: 0.9573 - val_loss: 0.5456 - val_acc: 0.8848\n",
      "Epoch 122/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1447 - acc: 0.9566 - val_loss: 0.5607 - val_acc: 0.8816\n",
      "Epoch 123/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1391 - acc: 0.9586 - val_loss: 0.5486 - val_acc: 0.8855\n",
      "Epoch 124/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.1359 - acc: 0.9597 - val_loss: 0.5812 - val_acc: 0.8822\n",
      "Epoch 125/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1426 - acc: 0.9560 - val_loss: 0.5579 - val_acc: 0.8862\n",
      "Epoch 126/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1411 - acc: 0.9572 - val_loss: 0.5593 - val_acc: 0.8832\n",
      "Epoch 127/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.1375 - acc: 0.9595 - val_loss: 0.5515 - val_acc: 0.8836\n",
      "Epoch 128/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1415 - acc: 0.9563 - val_loss: 0.5573 - val_acc: 0.8853\n",
      "Epoch 129/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1345 - acc: 0.9601 - val_loss: 0.5642 - val_acc: 0.8828\n",
      "Epoch 130/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1303 - acc: 0.9621 - val_loss: 0.5809 - val_acc: 0.8784\n",
      "Epoch 131/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1355 - acc: 0.9596 - val_loss: 0.6046 - val_acc: 0.8735\n",
      "Epoch 132/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1379 - acc: 0.9589 - val_loss: 0.5646 - val_acc: 0.8829\n",
      "Epoch 133/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1339 - acc: 0.9602 - val_loss: 0.5738 - val_acc: 0.8810\n",
      "Epoch 134/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1332 - acc: 0.9594 - val_loss: 0.5675 - val_acc: 0.8837\n",
      "Epoch 135/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1301 - acc: 0.9609 - val_loss: 0.6141 - val_acc: 0.8704\n",
      "Epoch 136/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1279 - acc: 0.9623 - val_loss: 0.5601 - val_acc: 0.8865\n",
      "Epoch 137/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1273 - acc: 0.9624 - val_loss: 0.5724 - val_acc: 0.8827\n",
      "Epoch 138/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1265 - acc: 0.9628 - val_loss: 0.6015 - val_acc: 0.8755\n",
      "Epoch 139/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1263 - acc: 0.9626 - val_loss: 0.5778 - val_acc: 0.8838\n",
      "Epoch 140/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1229 - acc: 0.9639 - val_loss: 0.5896 - val_acc: 0.8808\n",
      "Epoch 141/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.1251 - acc: 0.9621 - val_loss: 0.5796 - val_acc: 0.8852\n",
      "Epoch 142/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1277 - acc: 0.9619 - val_loss: 0.5921 - val_acc: 0.8797\n",
      "Epoch 143/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1231 - acc: 0.9631 - val_loss: 0.5834 - val_acc: 0.8840\n",
      "Epoch 144/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.1216 - acc: 0.9646 - val_loss: 0.5744 - val_acc: 0.8826\n",
      "Epoch 145/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1265 - acc: 0.9600 - val_loss: 0.5905 - val_acc: 0.8845\n",
      "Epoch 146/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1226 - acc: 0.9640 - val_loss: 0.5799 - val_acc: 0.8845\n",
      "Epoch 147/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.1200 - acc: 0.9641 - val_loss: 0.5938 - val_acc: 0.8814\n",
      "Epoch 148/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1182 - acc: 0.9644 - val_loss: 0.5957 - val_acc: 0.8834\n",
      "Epoch 149/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1198 - acc: 0.9646 - val_loss: 0.5924 - val_acc: 0.8820\n",
      "Epoch 150/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1185 - acc: 0.9650 - val_loss: 0.5936 - val_acc: 0.8838\n",
      "Epoch 151/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.1254 - acc: 0.9614 - val_loss: 0.5863 - val_acc: 0.8825\n",
      "Epoch 152/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1169 - acc: 0.9647 - val_loss: 0.5920 - val_acc: 0.8833\n",
      "Epoch 153/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1139 - acc: 0.9663 - val_loss: 0.5971 - val_acc: 0.8822\n",
      "Epoch 154/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.1142 - acc: 0.9665 - val_loss: 0.5917 - val_acc: 0.8855\n",
      "Epoch 155/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.1156 - acc: 0.9659 - val_loss: 0.5971 - val_acc: 0.8829\n",
      "Epoch 156/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.1119 - acc: 0.9672 - val_loss: 0.6002 - val_acc: 0.8824\n",
      "Epoch 157/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1103 - acc: 0.9680 - val_loss: 0.5970 - val_acc: 0.8845\n",
      "Epoch 158/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.1128 - acc: 0.9665 - val_loss: 0.5982 - val_acc: 0.8827\n",
      "Epoch 159/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1146 - acc: 0.9659 - val_loss: 0.6097 - val_acc: 0.8831\n",
      "Epoch 160/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1172 - acc: 0.9637 - val_loss: 0.6319 - val_acc: 0.8807\n",
      "Epoch 161/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1158 - acc: 0.9651 - val_loss: 0.6107 - val_acc: 0.8816\n",
      "Epoch 162/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.1078 - acc: 0.9667 - val_loss: 0.6198 - val_acc: 0.8803\n",
      "Epoch 163/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.1098 - acc: 0.9667 - val_loss: 0.6062 - val_acc: 0.8799\n",
      "Epoch 164/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.1086 - acc: 0.9673 - val_loss: 0.6084 - val_acc: 0.8847\n",
      "Epoch 165/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.1022 - acc: 0.9704 - val_loss: 0.6158 - val_acc: 0.8815\n",
      "Epoch 166/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1068 - acc: 0.9677 - val_loss: 0.6012 - val_acc: 0.8860\n",
      "Epoch 167/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1082 - acc: 0.9676 - val_loss: 0.6245 - val_acc: 0.8832\n",
      "Epoch 168/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1077 - acc: 0.9681 - val_loss: 0.6080 - val_acc: 0.8817\n",
      "Epoch 169/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.1053 - acc: 0.9684 - val_loss: 0.6100 - val_acc: 0.8869\n",
      "Epoch 170/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.1132 - acc: 0.9652 - val_loss: 0.6278 - val_acc: 0.8807\n",
      "Epoch 171/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1019 - acc: 0.9709 - val_loss: 0.6329 - val_acc: 0.8836\n",
      "Epoch 172/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1017 - acc: 0.9692 - val_loss: 0.6180 - val_acc: 0.8823\n",
      "Epoch 173/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1072 - acc: 0.9674 - val_loss: 0.6157 - val_acc: 0.8859\n",
      "Epoch 174/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1053 - acc: 0.9682 - val_loss: 0.6375 - val_acc: 0.8807\n",
      "Epoch 175/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.1017 - acc: 0.9699 - val_loss: 0.6174 - val_acc: 0.8833\n",
      "Epoch 176/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1017 - acc: 0.9700 - val_loss: 0.6277 - val_acc: 0.8844\n",
      "Epoch 177/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0979 - acc: 0.9715 - val_loss: 0.6568 - val_acc: 0.8814\n",
      "Epoch 178/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1041 - acc: 0.9695 - val_loss: 0.7021 - val_acc: 0.8644\n",
      "Epoch 179/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.1030 - acc: 0.9684 - val_loss: 0.6275 - val_acc: 0.8864\n",
      "Epoch 180/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0990 - acc: 0.9708 - val_loss: 0.6404 - val_acc: 0.8788\n",
      "Epoch 181/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0971 - acc: 0.9719 - val_loss: 0.6342 - val_acc: 0.8810\n",
      "Epoch 182/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0980 - acc: 0.9703 - val_loss: 0.6318 - val_acc: 0.8805\n",
      "Epoch 183/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0990 - acc: 0.9697 - val_loss: 0.6407 - val_acc: 0.8806\n",
      "Epoch 184/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0948 - acc: 0.9726 - val_loss: 0.6570 - val_acc: 0.8767\n",
      "Epoch 185/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0980 - acc: 0.9703 - val_loss: 0.6424 - val_acc: 0.8803\n",
      "Epoch 186/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0945 - acc: 0.9730 - val_loss: 0.6343 - val_acc: 0.8834\n",
      "Epoch 187/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0950 - acc: 0.9711 - val_loss: 0.6418 - val_acc: 0.8830\n",
      "Epoch 188/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0968 - acc: 0.9716 - val_loss: 0.6364 - val_acc: 0.8866\n",
      "Epoch 189/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0973 - acc: 0.9712 - val_loss: 0.6465 - val_acc: 0.8807\n",
      "Epoch 190/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0917 - acc: 0.9729 - val_loss: 0.6474 - val_acc: 0.8788\n",
      "Epoch 191/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0946 - acc: 0.9725 - val_loss: 0.6500 - val_acc: 0.8827\n",
      "Epoch 192/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0983 - acc: 0.9709 - val_loss: 0.6386 - val_acc: 0.8807\n",
      "Epoch 193/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0933 - acc: 0.9725 - val_loss: 0.6489 - val_acc: 0.8855\n",
      "Epoch 194/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0925 - acc: 0.9733 - val_loss: 0.7023 - val_acc: 0.8719\n",
      "Epoch 195/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0919 - acc: 0.9726 - val_loss: 0.6570 - val_acc: 0.8830\n",
      "Epoch 196/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0964 - acc: 0.9709 - val_loss: 0.6686 - val_acc: 0.8801\n",
      "Epoch 197/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0865 - acc: 0.9764 - val_loss: 0.6576 - val_acc: 0.8809\n",
      "Epoch 198/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0912 - acc: 0.9728 - val_loss: 0.6596 - val_acc: 0.8802\n",
      "Epoch 199/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0910 - acc: 0.9733 - val_loss: 0.6515 - val_acc: 0.8818\n",
      "Epoch 200/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0855 - acc: 0.9751 - val_loss: 0.6451 - val_acc: 0.8838\n",
      "Epoch 201/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0866 - acc: 0.9746 - val_loss: 0.6490 - val_acc: 0.8838\n",
      "Epoch 202/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0902 - acc: 0.9724 - val_loss: 0.6768 - val_acc: 0.8787\n",
      "Epoch 203/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0912 - acc: 0.9727 - val_loss: 0.6481 - val_acc: 0.8864\n",
      "Epoch 204/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0870 - acc: 0.9745 - val_loss: 0.6713 - val_acc: 0.8816\n",
      "Epoch 205/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0867 - acc: 0.9747 - val_loss: 0.6986 - val_acc: 0.8774\n",
      "Epoch 206/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0881 - acc: 0.9745 - val_loss: 0.6491 - val_acc: 0.8850\n",
      "Epoch 207/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0882 - acc: 0.9735 - val_loss: 0.6798 - val_acc: 0.8765\n",
      "Epoch 208/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0844 - acc: 0.9757 - val_loss: 0.6755 - val_acc: 0.8810\n",
      "Epoch 209/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0899 - acc: 0.9733 - val_loss: 0.6571 - val_acc: 0.8845\n",
      "Epoch 210/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0853 - acc: 0.9748 - val_loss: 0.6655 - val_acc: 0.8806\n",
      "Epoch 211/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0879 - acc: 0.9739 - val_loss: 0.6704 - val_acc: 0.8836\n",
      "Epoch 212/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0824 - acc: 0.9752 - val_loss: 0.6786 - val_acc: 0.8814\n",
      "Epoch 213/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0803 - acc: 0.9774 - val_loss: 0.6779 - val_acc: 0.8830\n",
      "Epoch 214/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0800 - acc: 0.9764 - val_loss: 0.7232 - val_acc: 0.8723\n",
      "Epoch 215/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0835 - acc: 0.9750 - val_loss: 0.6947 - val_acc: 0.8786\n",
      "Epoch 216/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0881 - acc: 0.9734 - val_loss: 0.6882 - val_acc: 0.8798\n",
      "Epoch 217/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0832 - acc: 0.9755 - val_loss: 0.7069 - val_acc: 0.8786\n",
      "Epoch 218/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0820 - acc: 0.9763 - val_loss: 0.6746 - val_acc: 0.8834\n",
      "Epoch 219/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0790 - acc: 0.9775 - val_loss: 0.6864 - val_acc: 0.8800\n",
      "Epoch 220/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0799 - acc: 0.9762 - val_loss: 0.7192 - val_acc: 0.8756\n",
      "Epoch 221/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0804 - acc: 0.9762 - val_loss: 0.6774 - val_acc: 0.8836\n",
      "Epoch 222/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0813 - acc: 0.9759 - val_loss: 0.6855 - val_acc: 0.8785\n",
      "Epoch 223/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0822 - acc: 0.9763 - val_loss: 0.6973 - val_acc: 0.8809\n",
      "Epoch 224/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0822 - acc: 0.9761 - val_loss: 0.7100 - val_acc: 0.8774\n",
      "Epoch 225/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0768 - acc: 0.9773 - val_loss: 0.7348 - val_acc: 0.8751\n",
      "Epoch 226/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0843 - acc: 0.9748 - val_loss: 0.6789 - val_acc: 0.8864\n",
      "Epoch 227/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0723 - acc: 0.9795 - val_loss: 0.6803 - val_acc: 0.8818\n",
      "Epoch 228/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0806 - acc: 0.9763 - val_loss: 0.6776 - val_acc: 0.8817\n",
      "Epoch 229/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0741 - acc: 0.9792 - val_loss: 0.7137 - val_acc: 0.8765\n",
      "Epoch 230/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0849 - acc: 0.9752 - val_loss: 0.7339 - val_acc: 0.8786\n",
      "Epoch 231/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0853 - acc: 0.9740 - val_loss: 0.6843 - val_acc: 0.8837\n",
      "Epoch 232/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0711 - acc: 0.9794 - val_loss: 0.7028 - val_acc: 0.8796\n",
      "Epoch 233/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0709 - acc: 0.9800 - val_loss: 0.6813 - val_acc: 0.8850\n",
      "Epoch 234/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0714 - acc: 0.9792 - val_loss: 0.6945 - val_acc: 0.8815\n",
      "Epoch 235/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0774 - acc: 0.9780 - val_loss: 0.6899 - val_acc: 0.8820\n",
      "Epoch 236/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0769 - acc: 0.9771 - val_loss: 0.6866 - val_acc: 0.8858\n",
      "Epoch 237/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0735 - acc: 0.9791 - val_loss: 0.7159 - val_acc: 0.8808\n",
      "Epoch 238/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0796 - acc: 0.9766 - val_loss: 0.7027 - val_acc: 0.8800\n",
      "Epoch 239/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0714 - acc: 0.9798 - val_loss: 0.7200 - val_acc: 0.8777\n",
      "Epoch 240/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0803 - acc: 0.9755 - val_loss: 0.7043 - val_acc: 0.8825\n",
      "Epoch 241/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0739 - acc: 0.9781 - val_loss: 0.7169 - val_acc: 0.8809\n",
      "Epoch 242/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0807 - acc: 0.9754 - val_loss: 0.7268 - val_acc: 0.8750\n",
      "Epoch 243/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0715 - acc: 0.9791 - val_loss: 0.7030 - val_acc: 0.8840\n",
      "Epoch 244/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0690 - acc: 0.9804 - val_loss: 0.7181 - val_acc: 0.8812\n",
      "Epoch 245/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0677 - acc: 0.9811 - val_loss: 0.7202 - val_acc: 0.8817\n",
      "Epoch 246/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0705 - acc: 0.9801 - val_loss: 0.7276 - val_acc: 0.8772\n",
      "Epoch 247/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0729 - acc: 0.9790 - val_loss: 0.7106 - val_acc: 0.8813\n",
      "Epoch 248/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0721 - acc: 0.9790 - val_loss: 0.7364 - val_acc: 0.8764\n",
      "Epoch 249/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0759 - acc: 0.9780 - val_loss: 0.7143 - val_acc: 0.8812\n",
      "Epoch 250/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0692 - acc: 0.9801 - val_loss: 0.7156 - val_acc: 0.8807\n",
      "Epoch 251/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0741 - acc: 0.9775 - val_loss: 0.7317 - val_acc: 0.8792\n",
      "Epoch 252/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0732 - acc: 0.9784 - val_loss: 0.7100 - val_acc: 0.8812\n",
      "Epoch 253/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0649 - acc: 0.9814 - val_loss: 0.7164 - val_acc: 0.8806\n",
      "Epoch 254/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0651 - acc: 0.9814 - val_loss: 0.7428 - val_acc: 0.8798\n",
      "Epoch 255/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0753 - acc: 0.9780 - val_loss: 0.7187 - val_acc: 0.8842\n",
      "Epoch 256/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0712 - acc: 0.9784 - val_loss: 0.7298 - val_acc: 0.8790\n",
      "Epoch 257/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0696 - acc: 0.9793 - val_loss: 0.7073 - val_acc: 0.8838\n",
      "Epoch 258/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0646 - acc: 0.9823 - val_loss: 0.7024 - val_acc: 0.8831\n",
      "Epoch 259/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0632 - acc: 0.9824 - val_loss: 0.7160 - val_acc: 0.8841\n",
      "Epoch 260/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0639 - acc: 0.9829 - val_loss: 0.7996 - val_acc: 0.8691\n",
      "Epoch 261/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0744 - acc: 0.9779 - val_loss: 0.7407 - val_acc: 0.8813\n",
      "Epoch 262/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0673 - acc: 0.9801 - val_loss: 0.7344 - val_acc: 0.8807\n",
      "Epoch 263/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0774 - acc: 0.9766 - val_loss: 0.7462 - val_acc: 0.8779\n",
      "Epoch 264/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0634 - acc: 0.9823 - val_loss: 0.7358 - val_acc: 0.8802\n",
      "Epoch 265/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0632 - acc: 0.9825 - val_loss: 0.7626 - val_acc: 0.8730\n",
      "Epoch 266/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0695 - acc: 0.9805 - val_loss: 0.7384 - val_acc: 0.8812\n",
      "Epoch 267/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0649 - acc: 0.9818 - val_loss: 0.7299 - val_acc: 0.8812\n",
      "Epoch 268/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0620 - acc: 0.9826 - val_loss: 0.7443 - val_acc: 0.8785\n",
      "Epoch 269/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0642 - acc: 0.9821 - val_loss: 0.7400 - val_acc: 0.8789\n",
      "Epoch 270/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0646 - acc: 0.9814 - val_loss: 0.7310 - val_acc: 0.8832\n",
      "Epoch 271/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0681 - acc: 0.9798 - val_loss: 0.7388 - val_acc: 0.8789\n",
      "Epoch 272/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0594 - acc: 0.9841 - val_loss: 0.7499 - val_acc: 0.8785\n",
      "Epoch 273/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0652 - acc: 0.9812 - val_loss: 0.7353 - val_acc: 0.8810\n",
      "Epoch 274/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0623 - acc: 0.9824 - val_loss: 0.7679 - val_acc: 0.8784\n",
      "Epoch 275/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0670 - acc: 0.9811 - val_loss: 0.7700 - val_acc: 0.8770\n",
      "Epoch 276/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0606 - acc: 0.9836 - val_loss: 0.7381 - val_acc: 0.8818\n",
      "Epoch 277/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0582 - acc: 0.9839 - val_loss: 0.7259 - val_acc: 0.8807\n",
      "Epoch 278/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0704 - acc: 0.9791 - val_loss: 0.7534 - val_acc: 0.8762\n",
      "Epoch 279/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0652 - acc: 0.9807 - val_loss: 0.7711 - val_acc: 0.8789\n",
      "Epoch 280/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0552 - acc: 0.9851 - val_loss: 0.7412 - val_acc: 0.8849\n",
      "Epoch 281/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0707 - acc: 0.9789 - val_loss: 0.7520 - val_acc: 0.8815\n",
      "Epoch 282/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0573 - acc: 0.9836 - val_loss: 0.7387 - val_acc: 0.8842\n",
      "Epoch 283/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0599 - acc: 0.9829 - val_loss: 0.7496 - val_acc: 0.8812\n",
      "Epoch 284/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0680 - acc: 0.9798 - val_loss: 0.7776 - val_acc: 0.8800\n",
      "Epoch 285/500\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0620 - acc: 0.9822 - val_loss: 0.7431 - val_acc: 0.8859\n",
      "Epoch 286/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0521 - acc: 0.9863 - val_loss: 0.7683 - val_acc: 0.8784\n",
      "Epoch 287/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0607 - acc: 0.9831 - val_loss: 0.7754 - val_acc: 0.8758\n",
      "Epoch 288/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0645 - acc: 0.9809 - val_loss: 0.7546 - val_acc: 0.8821\n",
      "Epoch 289/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0648 - acc: 0.9811 - val_loss: 0.8399 - val_acc: 0.8694\n",
      "Epoch 290/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0577 - acc: 0.9840 - val_loss: 0.7688 - val_acc: 0.8818\n",
      "Epoch 291/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0545 - acc: 0.9855 - val_loss: 0.7866 - val_acc: 0.8790\n",
      "Epoch 292/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0710 - acc: 0.9780 - val_loss: 0.7706 - val_acc: 0.8782\n",
      "Epoch 293/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0541 - acc: 0.9857 - val_loss: 0.7445 - val_acc: 0.8862\n",
      "Epoch 294/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0567 - acc: 0.9842 - val_loss: 0.7817 - val_acc: 0.8795\n",
      "Epoch 295/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0515 - acc: 0.9866 - val_loss: 0.7724 - val_acc: 0.8775\n",
      "Epoch 296/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0620 - acc: 0.9818 - val_loss: 0.7741 - val_acc: 0.8805\n",
      "Epoch 297/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0548 - acc: 0.9852 - val_loss: 0.7898 - val_acc: 0.8765\n",
      "Epoch 298/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0566 - acc: 0.9835 - val_loss: 0.7571 - val_acc: 0.8850\n",
      "Epoch 299/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0542 - acc: 0.9857 - val_loss: 0.8106 - val_acc: 0.8753\n",
      "Epoch 300/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0699 - acc: 0.9785 - val_loss: 0.7737 - val_acc: 0.8817\n",
      "Epoch 301/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0555 - acc: 0.9839 - val_loss: 0.7924 - val_acc: 0.8769\n",
      "Epoch 302/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0541 - acc: 0.9854 - val_loss: 0.7636 - val_acc: 0.8836\n",
      "Epoch 303/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0500 - acc: 0.9876 - val_loss: 0.7731 - val_acc: 0.8821\n",
      "Epoch 304/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0659 - acc: 0.9794 - val_loss: 0.7733 - val_acc: 0.8819\n",
      "Epoch 305/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0573 - acc: 0.9839 - val_loss: 0.8071 - val_acc: 0.8747\n",
      "Epoch 306/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0554 - acc: 0.9846 - val_loss: 0.7942 - val_acc: 0.8811\n",
      "Epoch 307/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0547 - acc: 0.9847 - val_loss: 0.7715 - val_acc: 0.8854\n",
      "Epoch 308/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0460 - acc: 0.9876 - val_loss: 0.7722 - val_acc: 0.8826\n",
      "Epoch 309/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0550 - acc: 0.9847 - val_loss: 0.8207 - val_acc: 0.8727\n",
      "Epoch 310/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0631 - acc: 0.9813 - val_loss: 0.7795 - val_acc: 0.8806\n",
      "Epoch 311/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0526 - acc: 0.9856 - val_loss: 0.7789 - val_acc: 0.8824\n",
      "Epoch 312/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0522 - acc: 0.9852 - val_loss: 0.7870 - val_acc: 0.8804\n",
      "Epoch 313/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0500 - acc: 0.9867 - val_loss: 0.7891 - val_acc: 0.8819\n",
      "Epoch 314/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0504 - acc: 0.9867 - val_loss: 0.8299 - val_acc: 0.8724\n",
      "Epoch 315/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0583 - acc: 0.9832 - val_loss: 0.8110 - val_acc: 0.8803\n",
      "Epoch 316/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0499 - acc: 0.9868 - val_loss: 0.8452 - val_acc: 0.8696\n",
      "Epoch 317/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0672 - acc: 0.9794 - val_loss: 0.7831 - val_acc: 0.8842\n",
      "Epoch 318/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0472 - acc: 0.9884 - val_loss: 0.7875 - val_acc: 0.8836\n",
      "Epoch 319/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0556 - acc: 0.9850 - val_loss: 0.8042 - val_acc: 0.8785\n",
      "Epoch 320/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0597 - acc: 0.9830 - val_loss: 0.8083 - val_acc: 0.8812\n",
      "Epoch 321/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0442 - acc: 0.9890 - val_loss: 0.7741 - val_acc: 0.8873\n",
      "Epoch 322/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0520 - acc: 0.9861 - val_loss: 0.7874 - val_acc: 0.8788\n",
      "Epoch 323/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0616 - acc: 0.9811 - val_loss: 0.7925 - val_acc: 0.8827\n",
      "Epoch 324/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0445 - acc: 0.9887 - val_loss: 0.8321 - val_acc: 0.8745\n",
      "Epoch 325/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0518 - acc: 0.9858 - val_loss: 0.7830 - val_acc: 0.8838\n",
      "Epoch 326/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0536 - acc: 0.9852 - val_loss: 0.8029 - val_acc: 0.8784\n",
      "Epoch 327/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0519 - acc: 0.9853 - val_loss: 0.7897 - val_acc: 0.8833\n",
      "Epoch 328/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0484 - acc: 0.9878 - val_loss: 0.8032 - val_acc: 0.8819\n",
      "Epoch 329/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0570 - acc: 0.9831 - val_loss: 0.8422 - val_acc: 0.8736\n",
      "Epoch 330/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0518 - acc: 0.9855 - val_loss: 0.7990 - val_acc: 0.8821\n",
      "Epoch 331/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0539 - acc: 0.9850 - val_loss: 0.8082 - val_acc: 0.8821\n",
      "Epoch 332/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0511 - acc: 0.9862 - val_loss: 0.8193 - val_acc: 0.8793\n",
      "Epoch 333/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0535 - acc: 0.9852 - val_loss: 0.8300 - val_acc: 0.8774\n",
      "Epoch 334/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0580 - acc: 0.9829 - val_loss: 0.8051 - val_acc: 0.8820\n",
      "Epoch 335/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0603 - acc: 0.9821 - val_loss: 0.8344 - val_acc: 0.8765\n",
      "Epoch 336/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0452 - acc: 0.9886 - val_loss: 0.8080 - val_acc: 0.8791\n",
      "Epoch 337/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0418 - acc: 0.9897 - val_loss: 0.8126 - val_acc: 0.8790\n",
      "Epoch 338/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0438 - acc: 0.9888 - val_loss: 0.8292 - val_acc: 0.8775\n",
      "Epoch 339/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0602 - acc: 0.9820 - val_loss: 0.9029 - val_acc: 0.8691\n",
      "Epoch 340/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0498 - acc: 0.9859 - val_loss: 0.8202 - val_acc: 0.8811\n",
      "Epoch 341/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0490 - acc: 0.9867 - val_loss: 0.8028 - val_acc: 0.8823\n",
      "Epoch 342/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0399 - acc: 0.9907 - val_loss: 0.8073 - val_acc: 0.8822\n",
      "Epoch 343/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0478 - acc: 0.9868 - val_loss: 0.7908 - val_acc: 0.8833\n",
      "Epoch 344/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0448 - acc: 0.9885 - val_loss: 0.8048 - val_acc: 0.8849\n",
      "Epoch 345/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0520 - acc: 0.9847 - val_loss: 0.8282 - val_acc: 0.8803\n",
      "Epoch 346/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0531 - acc: 0.9851 - val_loss: 0.8216 - val_acc: 0.8778\n",
      "Epoch 347/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0492 - acc: 0.9861 - val_loss: 0.8260 - val_acc: 0.8812\n",
      "Epoch 348/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0433 - acc: 0.9883 - val_loss: 0.8536 - val_acc: 0.8748\n",
      "Epoch 349/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0512 - acc: 0.9853 - val_loss: 0.8089 - val_acc: 0.8822\n",
      "Epoch 350/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0411 - acc: 0.9898 - val_loss: 0.8580 - val_acc: 0.8750\n",
      "Epoch 351/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0479 - acc: 0.9867 - val_loss: 0.8637 - val_acc: 0.8713\n",
      "Epoch 352/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0568 - acc: 0.9833 - val_loss: 0.8370 - val_acc: 0.8801\n",
      "Epoch 353/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0539 - acc: 0.9845 - val_loss: 0.8219 - val_acc: 0.8815\n",
      "Epoch 354/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0418 - acc: 0.9893 - val_loss: 0.8397 - val_acc: 0.8769\n",
      "Epoch 355/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0431 - acc: 0.9891 - val_loss: 0.8523 - val_acc: 0.8755\n",
      "Epoch 356/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0491 - acc: 0.9869 - val_loss: 0.8602 - val_acc: 0.8775\n",
      "Epoch 357/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0507 - acc: 0.9859 - val_loss: 0.8715 - val_acc: 0.8727\n",
      "Epoch 358/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0436 - acc: 0.9882 - val_loss: 0.8411 - val_acc: 0.8784\n",
      "Epoch 359/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0675 - acc: 0.9791 - val_loss: 0.8588 - val_acc: 0.8777\n",
      "Epoch 360/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0517 - acc: 0.9851 - val_loss: 0.8149 - val_acc: 0.8838\n",
      "Epoch 361/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0359 - acc: 0.9923 - val_loss: 0.8253 - val_acc: 0.8796\n",
      "Epoch 362/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0370 - acc: 0.9916 - val_loss: 0.8183 - val_acc: 0.8834\n",
      "Epoch 363/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0362 - acc: 0.9915 - val_loss: 0.8316 - val_acc: 0.8824\n",
      "Epoch 364/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0503 - acc: 0.9860 - val_loss: 0.8392 - val_acc: 0.8793\n",
      "Epoch 365/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0572 - acc: 0.9835 - val_loss: 0.8435 - val_acc: 0.8807\n",
      "Epoch 366/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0491 - acc: 0.9863 - val_loss: 0.8306 - val_acc: 0.8822\n",
      "Epoch 367/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0384 - acc: 0.9907 - val_loss: 0.8295 - val_acc: 0.8834\n",
      "Epoch 368/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0354 - acc: 0.9922 - val_loss: 0.8329 - val_acc: 0.8797\n",
      "Epoch 369/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0558 - acc: 0.9851 - val_loss: 0.8824 - val_acc: 0.8759\n",
      "Epoch 370/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0560 - acc: 0.9830 - val_loss: 0.8585 - val_acc: 0.8804\n",
      "Epoch 371/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0442 - acc: 0.9880 - val_loss: 0.8289 - val_acc: 0.8829\n",
      "Epoch 372/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0447 - acc: 0.9880 - val_loss: 0.8263 - val_acc: 0.8817\n",
      "Epoch 373/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0342 - acc: 0.9928 - val_loss: 0.8417 - val_acc: 0.8826\n",
      "Epoch 374/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0324 - acc: 0.9933 - val_loss: 0.8226 - val_acc: 0.8852\n",
      "Epoch 375/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0540 - acc: 0.9851 - val_loss: 0.9711 - val_acc: 0.8597\n",
      "Epoch 376/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0583 - acc: 0.9829 - val_loss: 0.8497 - val_acc: 0.8798\n",
      "Epoch 377/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0342 - acc: 0.9922 - val_loss: 0.8294 - val_acc: 0.8836\n",
      "Epoch 378/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0450 - acc: 0.9875 - val_loss: 0.8791 - val_acc: 0.8745\n",
      "Epoch 379/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0488 - acc: 0.9864 - val_loss: 0.8716 - val_acc: 0.8786\n",
      "Epoch 380/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0446 - acc: 0.9874 - val_loss: 0.8776 - val_acc: 0.8768\n",
      "Epoch 381/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0321 - acc: 0.9929 - val_loss: 0.8329 - val_acc: 0.8821\n",
      "Epoch 382/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0424 - acc: 0.9891 - val_loss: 0.8659 - val_acc: 0.8801\n",
      "Epoch 383/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0529 - acc: 0.9842 - val_loss: 0.9474 - val_acc: 0.8654\n",
      "Epoch 384/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0653 - acc: 0.9809 - val_loss: 0.8333 - val_acc: 0.8823\n",
      "Epoch 385/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0305 - acc: 0.9942 - val_loss: 0.8346 - val_acc: 0.8849\n",
      "Epoch 386/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0302 - acc: 0.9942 - val_loss: 0.8641 - val_acc: 0.8788\n",
      "Epoch 387/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0507 - acc: 0.9859 - val_loss: 0.8402 - val_acc: 0.8821\n",
      "Epoch 388/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0413 - acc: 0.9888 - val_loss: 0.8619 - val_acc: 0.8817\n",
      "Epoch 389/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0465 - acc: 0.9872 - val_loss: 0.8600 - val_acc: 0.8785\n",
      "Epoch 390/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0330 - acc: 0.9930 - val_loss: 0.8598 - val_acc: 0.8787\n",
      "Epoch 391/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0410 - acc: 0.9888 - val_loss: 0.8831 - val_acc: 0.8758\n",
      "Epoch 392/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0367 - acc: 0.9906 - val_loss: 0.8511 - val_acc: 0.8812\n",
      "Epoch 393/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0510 - acc: 0.9867 - val_loss: 0.8509 - val_acc: 0.8809\n",
      "Epoch 394/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0414 - acc: 0.9888 - val_loss: 0.8600 - val_acc: 0.8799\n",
      "Epoch 395/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0357 - acc: 0.9911 - val_loss: 0.8455 - val_acc: 0.8836\n",
      "Epoch 396/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0469 - acc: 0.9870 - val_loss: 0.8531 - val_acc: 0.8821\n",
      "Epoch 397/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0413 - acc: 0.9892 - val_loss: 0.8581 - val_acc: 0.8807\n",
      "Epoch 398/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0297 - acc: 0.9939 - val_loss: 0.8571 - val_acc: 0.8826\n",
      "Epoch 399/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0623 - acc: 0.9824 - val_loss: 0.9128 - val_acc: 0.8751\n",
      "Epoch 400/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0463 - acc: 0.9873 - val_loss: 0.8877 - val_acc: 0.8798\n",
      "Epoch 401/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0334 - acc: 0.9924 - val_loss: 0.8533 - val_acc: 0.8836\n",
      "Epoch 402/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0378 - acc: 0.9903 - val_loss: 0.8564 - val_acc: 0.8815\n",
      "Epoch 403/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0347 - acc: 0.9920 - val_loss: 0.8676 - val_acc: 0.8817\n",
      "Epoch 404/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0448 - acc: 0.9879 - val_loss: 0.8638 - val_acc: 0.8795\n",
      "Epoch 405/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0516 - acc: 0.9850 - val_loss: 0.8802 - val_acc: 0.8776\n",
      "Epoch 406/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0343 - acc: 0.9918 - val_loss: 0.8782 - val_acc: 0.8777\n",
      "Epoch 407/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0309 - acc: 0.9939 - val_loss: 0.8616 - val_acc: 0.8841\n",
      "Epoch 408/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0272 - acc: 0.9954 - val_loss: 0.9017 - val_acc: 0.8755\n",
      "Epoch 409/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0679 - acc: 0.9781 - val_loss: 0.8717 - val_acc: 0.8821\n",
      "Epoch 410/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0287 - acc: 0.9945 - val_loss: 0.8653 - val_acc: 0.8823\n",
      "Epoch 411/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0338 - acc: 0.9927 - val_loss: 0.8817 - val_acc: 0.8809\n",
      "Epoch 412/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0552 - acc: 0.9836 - val_loss: 0.9252 - val_acc: 0.8736\n",
      "Epoch 413/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0401 - acc: 0.9892 - val_loss: 0.8629 - val_acc: 0.8806\n",
      "Epoch 414/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0366 - acc: 0.9908 - val_loss: 0.8596 - val_acc: 0.8835\n",
      "Epoch 415/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0255 - acc: 0.9956 - val_loss: 0.8987 - val_acc: 0.8763\n",
      "Epoch 416/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0382 - acc: 0.9897 - val_loss: 0.9606 - val_acc: 0.8682\n",
      "Epoch 417/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0341 - acc: 0.9921 - val_loss: 0.8640 - val_acc: 0.8816\n",
      "Epoch 418/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0731 - acc: 0.9778 - val_loss: 0.8815 - val_acc: 0.8784\n",
      "Epoch 419/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0315 - acc: 0.9928 - val_loss: 0.8699 - val_acc: 0.8828\n",
      "Epoch 420/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0271 - acc: 0.9949 - val_loss: 0.8680 - val_acc: 0.8811\n",
      "Epoch 421/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0394 - acc: 0.9903 - val_loss: 0.9350 - val_acc: 0.8730\n",
      "Epoch 422/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0551 - acc: 0.9841 - val_loss: 0.8883 - val_acc: 0.8803\n",
      "Epoch 423/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0272 - acc: 0.9948 - val_loss: 0.8916 - val_acc: 0.8787\n",
      "Epoch 424/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0301 - acc: 0.9935 - val_loss: 0.8623 - val_acc: 0.8841\n",
      "Epoch 425/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0296 - acc: 0.9935 - val_loss: 0.9564 - val_acc: 0.8689\n",
      "Epoch 426/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0415 - acc: 0.9887 - val_loss: 0.8802 - val_acc: 0.8810\n",
      "Epoch 427/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0454 - acc: 0.9879 - val_loss: 0.9119 - val_acc: 0.8780\n",
      "Epoch 428/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0539 - acc: 0.9847 - val_loss: 0.8843 - val_acc: 0.8819\n",
      "Epoch 429/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0340 - acc: 0.9916 - val_loss: 0.8770 - val_acc: 0.8823\n",
      "Epoch 430/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0279 - acc: 0.9943 - val_loss: 0.8799 - val_acc: 0.8853\n",
      "Epoch 431/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0341 - acc: 0.9920 - val_loss: 0.9444 - val_acc: 0.8696\n",
      "Epoch 432/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0485 - acc: 0.9859 - val_loss: 0.8627 - val_acc: 0.8843\n",
      "Epoch 433/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0265 - acc: 0.9950 - val_loss: 0.8888 - val_acc: 0.8794\n",
      "Epoch 434/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0253 - acc: 0.9957 - val_loss: 0.8808 - val_acc: 0.8821\n",
      "Epoch 435/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0265 - acc: 0.9947 - val_loss: 0.8884 - val_acc: 0.8832\n",
      "Epoch 436/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0732 - acc: 0.9776 - val_loss: 0.9134 - val_acc: 0.8787\n",
      "Epoch 437/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0494 - acc: 0.9859 - val_loss: 0.8840 - val_acc: 0.8820\n",
      "Epoch 438/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0250 - acc: 0.9955 - val_loss: 0.8867 - val_acc: 0.8802\n",
      "Epoch 439/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0249 - acc: 0.9956 - val_loss: 0.9141 - val_acc: 0.8788\n",
      "Epoch 440/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0477 - acc: 0.9862 - val_loss: 0.9179 - val_acc: 0.8765\n",
      "Epoch 441/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0365 - acc: 0.9909 - val_loss: 0.9006 - val_acc: 0.8791\n",
      "Epoch 442/500\n",
      "34108/34108 [==============================] - 1s 19us/step - loss: 0.0382 - acc: 0.9897 - val_loss: 0.8824 - val_acc: 0.8836\n",
      "Epoch 443/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0337 - acc: 0.9917 - val_loss: 0.9349 - val_acc: 0.8770\n",
      "Epoch 444/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0347 - acc: 0.9912 - val_loss: 0.9143 - val_acc: 0.8779\n",
      "Epoch 445/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0478 - acc: 0.9872 - val_loss: 0.9490 - val_acc: 0.8725\n",
      "Epoch 446/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0437 - acc: 0.9889 - val_loss: 0.9079 - val_acc: 0.8791\n",
      "Epoch 447/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0236 - acc: 0.9958 - val_loss: 0.8770 - val_acc: 0.8849\n",
      "Epoch 448/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0655 - acc: 0.9818 - val_loss: 0.8843 - val_acc: 0.8833\n",
      "Epoch 449/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0263 - acc: 0.9947 - val_loss: 0.8939 - val_acc: 0.8821\n",
      "Epoch 450/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0233 - acc: 0.9960 - val_loss: 0.9036 - val_acc: 0.8803\n",
      "Epoch 451/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0230 - acc: 0.9962 - val_loss: 0.8925 - val_acc: 0.8800\n",
      "Epoch 452/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0471 - acc: 0.9871 - val_loss: 0.9641 - val_acc: 0.8692\n",
      "Epoch 453/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0335 - acc: 0.9916 - val_loss: 0.9248 - val_acc: 0.8773\n",
      "Epoch 454/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0303 - acc: 0.9930 - val_loss: 0.8976 - val_acc: 0.8827\n",
      "Epoch 455/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0241 - acc: 0.9956 - val_loss: 0.9144 - val_acc: 0.8812\n",
      "Epoch 456/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0477 - acc: 0.9866 - val_loss: 0.9346 - val_acc: 0.8756\n",
      "Epoch 457/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0506 - acc: 0.9843 - val_loss: 0.9171 - val_acc: 0.8766\n",
      "Epoch 458/500\n",
      "34108/34108 [==============================] - 1s 18us/step - loss: 0.0260 - acc: 0.9946 - val_loss: 0.8918 - val_acc: 0.8833\n",
      "Epoch 459/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0233 - acc: 0.9962 - val_loss: 0.8899 - val_acc: 0.8832\n",
      "Epoch 460/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0235 - acc: 0.9959 - val_loss: 0.9118 - val_acc: 0.8810\n",
      "Epoch 461/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0524 - acc: 0.9846 - val_loss: 0.9727 - val_acc: 0.8700\n",
      "Epoch 462/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0590 - acc: 0.9826 - val_loss: 0.9199 - val_acc: 0.8780\n",
      "Epoch 463/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0284 - acc: 0.9938 - val_loss: 0.9035 - val_acc: 0.8806\n",
      "Epoch 464/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0227 - acc: 0.9962 - val_loss: 0.8930 - val_acc: 0.8842\n",
      "Epoch 465/500\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0238 - acc: 0.9957 - val_loss: 0.9003 - val_acc: 0.8835\n",
      "Epoch 466/500\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0277 - acc: 0.9941 - val_loss: 0.9434 - val_acc: 0.8778\n",
      "Epoch 467/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0672 - acc: 0.9798 - val_loss: 0.9637 - val_acc: 0.8696\n",
      "Epoch 468/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0304 - acc: 0.9932 - val_loss: 0.8938 - val_acc: 0.8854\n",
      "Epoch 469/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0223 - acc: 0.9966 - val_loss: 0.9123 - val_acc: 0.8803\n",
      "Epoch 470/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0309 - acc: 0.9925 - val_loss: 0.9202 - val_acc: 0.8791\n",
      "Epoch 471/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0324 - acc: 0.9920 - val_loss: 0.9218 - val_acc: 0.8802\n",
      "Epoch 472/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0413 - acc: 0.9892 - val_loss: 0.9579 - val_acc: 0.8719\n",
      "Epoch 473/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0541 - acc: 0.9833 - val_loss: 0.8952 - val_acc: 0.8826\n",
      "Epoch 474/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0228 - acc: 0.9963 - val_loss: 0.9157 - val_acc: 0.8816\n",
      "Epoch 475/500\n",
      "34108/34108 [==============================] - 1s 16us/step - loss: 0.0232 - acc: 0.9959 - val_loss: 0.9271 - val_acc: 0.8812\n",
      "Epoch 476/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0232 - acc: 0.9962 - val_loss: 0.9092 - val_acc: 0.8839\n",
      "Epoch 477/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0470 - acc: 0.9870 - val_loss: 0.9057 - val_acc: 0.8813\n",
      "Epoch 478/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0371 - acc: 0.9898 - val_loss: 0.9444 - val_acc: 0.8837\n",
      "Epoch 479/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0507 - acc: 0.9848 - val_loss: 0.9698 - val_acc: 0.8730\n",
      "Epoch 480/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0450 - acc: 0.9877 - val_loss: 0.9103 - val_acc: 0.8820\n",
      "Epoch 481/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0238 - acc: 0.9952 - val_loss: 0.9187 - val_acc: 0.8798\n",
      "Epoch 482/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0213 - acc: 0.9965 - val_loss: 0.9052 - val_acc: 0.8831\n",
      "Epoch 483/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0284 - acc: 0.9931 - val_loss: 0.9151 - val_acc: 0.8813\n",
      "Epoch 484/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0205 - acc: 0.9969 - val_loss: 0.9166 - val_acc: 0.8827\n",
      "Epoch 485/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0394 - acc: 0.9906 - val_loss: 0.9586 - val_acc: 0.8746\n",
      "Epoch 486/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0748 - acc: 0.9781 - val_loss: 0.9146 - val_acc: 0.8839\n",
      "Epoch 487/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0252 - acc: 0.9953 - val_loss: 0.9103 - val_acc: 0.8850\n",
      "Epoch 488/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0222 - acc: 0.9962 - val_loss: 0.9284 - val_acc: 0.8809\n",
      "Epoch 489/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0303 - acc: 0.9932 - val_loss: 0.9304 - val_acc: 0.8810\n",
      "Epoch 490/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0456 - acc: 0.9871 - val_loss: 0.9367 - val_acc: 0.8777\n",
      "Epoch 491/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0223 - acc: 0.9960 - val_loss: 0.9078 - val_acc: 0.8836\n",
      "Epoch 492/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0209 - acc: 0.9971 - val_loss: 0.9572 - val_acc: 0.8751\n",
      "Epoch 493/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0518 - acc: 0.9848 - val_loss: 0.9732 - val_acc: 0.8756\n",
      "Epoch 494/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0296 - acc: 0.9929 - val_loss: 0.9217 - val_acc: 0.8815\n",
      "Epoch 495/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0191 - acc: 0.9972 - val_loss: 0.9438 - val_acc: 0.8781\n",
      "Epoch 496/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0452 - acc: 0.9874 - val_loss: 0.9434 - val_acc: 0.8784\n",
      "Epoch 497/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0505 - acc: 0.9847 - val_loss: 0.9573 - val_acc: 0.8773\n",
      "Epoch 498/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0233 - acc: 0.9958 - val_loss: 0.9133 - val_acc: 0.8853\n",
      "Epoch 499/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0183 - acc: 0.9977 - val_loss: 0.9158 - val_acc: 0.8836\n",
      "Epoch 500/500\n",
      "34108/34108 [==============================] - 1s 17us/step - loss: 0.0189 - acc: 0.9975 - val_loss: 0.9616 - val_acc: 0.8788\n",
      "Train on 34108 samples, validate on 12117 samples\n",
      "Epoch 1/500\n",
      "34108/34108 [==============================] - 1s 37us/step - loss: 1.2518 - acc: 0.5108 - val_loss: 0.9480 - val_acc: 0.6945\n",
      "Epoch 2/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.8626 - acc: 0.7198 - val_loss: 0.7613 - val_acc: 0.7597\n",
      "Epoch 3/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.7239 - acc: 0.7774 - val_loss: 0.6902 - val_acc: 0.7886\n",
      "Epoch 4/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.6558 - acc: 0.7970 - val_loss: 0.6701 - val_acc: 0.7917\n",
      "Epoch 5/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.6092 - acc: 0.8129 - val_loss: 0.6358 - val_acc: 0.8082\n",
      "Epoch 6/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.5757 - acc: 0.8245 - val_loss: 0.6345 - val_acc: 0.8039\n",
      "Epoch 7/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.5459 - acc: 0.8314 - val_loss: 0.5964 - val_acc: 0.8212\n",
      "Epoch 8/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.5235 - acc: 0.8383 - val_loss: 0.5826 - val_acc: 0.8263\n",
      "Epoch 9/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.5016 - acc: 0.8472 - val_loss: 0.5691 - val_acc: 0.8263\n",
      "Epoch 10/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.4829 - acc: 0.8520 - val_loss: 0.5919 - val_acc: 0.8253\n",
      "Epoch 11/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.4723 - acc: 0.8550 - val_loss: 0.5567 - val_acc: 0.8349\n",
      "Epoch 12/500\n",
      "34108/34108 [==============================] - 1s 23us/step - loss: 0.4547 - acc: 0.8601 - val_loss: 0.5346 - val_acc: 0.8420\n",
      "Epoch 13/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.4432 - acc: 0.8647 - val_loss: 0.5419 - val_acc: 0.8394\n",
      "Epoch 14/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.4272 - acc: 0.8687 - val_loss: 0.5237 - val_acc: 0.8477\n",
      "Epoch 15/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.4189 - acc: 0.8716 - val_loss: 0.5359 - val_acc: 0.8446\n",
      "Epoch 16/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.4043 - acc: 0.8765 - val_loss: 0.5022 - val_acc: 0.8541\n",
      "Epoch 17/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.3955 - acc: 0.8795 - val_loss: 0.5082 - val_acc: 0.8571\n",
      "Epoch 18/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.3837 - acc: 0.8834 - val_loss: 0.5128 - val_acc: 0.8545\n",
      "Epoch 19/500\n",
      "34108/34108 [==============================] - 1s 23us/step - loss: 0.3786 - acc: 0.8845 - val_loss: 0.5194 - val_acc: 0.8479\n",
      "Epoch 20/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.3629 - acc: 0.8910 - val_loss: 0.4844 - val_acc: 0.8604\n",
      "Epoch 21/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.3588 - acc: 0.8909 - val_loss: 0.4911 - val_acc: 0.8604\n",
      "Epoch 22/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.3529 - acc: 0.8925 - val_loss: 0.4774 - val_acc: 0.8669\n",
      "Epoch 23/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.3410 - acc: 0.8956 - val_loss: 0.5042 - val_acc: 0.8599\n",
      "Epoch 24/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.3364 - acc: 0.8977 - val_loss: 0.4766 - val_acc: 0.8689\n",
      "Epoch 25/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.3324 - acc: 0.8984 - val_loss: 0.4811 - val_acc: 0.8680\n",
      "Epoch 26/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.3200 - acc: 0.9026 - val_loss: 0.4837 - val_acc: 0.8710\n",
      "Epoch 27/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.3181 - acc: 0.9026 - val_loss: 0.4689 - val_acc: 0.8707\n",
      "Epoch 28/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.3098 - acc: 0.9048 - val_loss: 0.5139 - val_acc: 0.8635\n",
      "Epoch 29/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.3073 - acc: 0.9059 - val_loss: 0.4816 - val_acc: 0.8699\n",
      "Epoch 30/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.2991 - acc: 0.9102 - val_loss: 0.4737 - val_acc: 0.8699\n",
      "Epoch 31/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.2917 - acc: 0.9125 - val_loss: 0.4679 - val_acc: 0.8758\n",
      "Epoch 32/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.2856 - acc: 0.9139 - val_loss: 0.4886 - val_acc: 0.8666\n",
      "Epoch 33/500\n",
      "34108/34108 [==============================] - 1s 23us/step - loss: 0.2815 - acc: 0.9149 - val_loss: 0.4824 - val_acc: 0.8720\n",
      "Epoch 34/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.2796 - acc: 0.9151 - val_loss: 0.4664 - val_acc: 0.8776\n",
      "Epoch 35/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.2756 - acc: 0.9162 - val_loss: 0.4669 - val_acc: 0.8789\n",
      "Epoch 36/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.2699 - acc: 0.9193 - val_loss: 0.4810 - val_acc: 0.8760\n",
      "Epoch 37/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.2613 - acc: 0.9230 - val_loss: 0.4794 - val_acc: 0.8765\n",
      "Epoch 38/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.2600 - acc: 0.9207 - val_loss: 0.4855 - val_acc: 0.8726\n",
      "Epoch 39/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.2607 - acc: 0.9212 - val_loss: 0.4675 - val_acc: 0.8788\n",
      "Epoch 40/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.2517 - acc: 0.9234 - val_loss: 0.4773 - val_acc: 0.8816\n",
      "Epoch 41/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.2486 - acc: 0.9241 - val_loss: 0.4750 - val_acc: 0.8765\n",
      "Epoch 42/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.2426 - acc: 0.9255 - val_loss: 0.4711 - val_acc: 0.8801\n",
      "Epoch 43/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.2405 - acc: 0.9277 - val_loss: 0.4597 - val_acc: 0.8866\n",
      "Epoch 44/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.2379 - acc: 0.9272 - val_loss: 0.4826 - val_acc: 0.8812\n",
      "Epoch 45/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.2357 - acc: 0.9290 - val_loss: 0.4722 - val_acc: 0.8820\n",
      "Epoch 46/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.2298 - acc: 0.9293 - val_loss: 0.4835 - val_acc: 0.8782\n",
      "Epoch 47/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.2258 - acc: 0.9324 - val_loss: 0.4845 - val_acc: 0.8822\n",
      "Epoch 48/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.2250 - acc: 0.9320 - val_loss: 0.4851 - val_acc: 0.8776\n",
      "Epoch 49/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.2184 - acc: 0.9340 - val_loss: 0.4996 - val_acc: 0.8810\n",
      "Epoch 50/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.2162 - acc: 0.9347 - val_loss: 0.4925 - val_acc: 0.8795\n",
      "Epoch 51/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.2135 - acc: 0.9367 - val_loss: 0.4908 - val_acc: 0.8831\n",
      "Epoch 52/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.2098 - acc: 0.9362 - val_loss: 0.4957 - val_acc: 0.8818\n",
      "Epoch 53/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.2083 - acc: 0.9356 - val_loss: 0.4816 - val_acc: 0.8817\n",
      "Epoch 54/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.2043 - acc: 0.9380 - val_loss: 0.4872 - val_acc: 0.8817\n",
      "Epoch 55/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.2052 - acc: 0.9369 - val_loss: 0.4888 - val_acc: 0.8824\n",
      "Epoch 56/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.2027 - acc: 0.9371 - val_loss: 0.4851 - val_acc: 0.8836\n",
      "Epoch 57/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1942 - acc: 0.9417 - val_loss: 0.4922 - val_acc: 0.8842\n",
      "Epoch 58/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1927 - acc: 0.9408 - val_loss: 0.4942 - val_acc: 0.8838\n",
      "Epoch 59/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1891 - acc: 0.9428 - val_loss: 0.5168 - val_acc: 0.8777\n",
      "Epoch 60/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1911 - acc: 0.9421 - val_loss: 0.4963 - val_acc: 0.8833\n",
      "Epoch 61/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1859 - acc: 0.9444 - val_loss: 0.5060 - val_acc: 0.8838\n",
      "Epoch 62/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1851 - acc: 0.9434 - val_loss: 0.4936 - val_acc: 0.8874\n",
      "Epoch 63/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1795 - acc: 0.9456 - val_loss: 0.4970 - val_acc: 0.8862\n",
      "Epoch 64/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1800 - acc: 0.9457 - val_loss: 0.4953 - val_acc: 0.8854\n",
      "Epoch 65/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1792 - acc: 0.9454 - val_loss: 0.5133 - val_acc: 0.8838\n",
      "Epoch 66/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1753 - acc: 0.9478 - val_loss: 0.5034 - val_acc: 0.8850\n",
      "Epoch 67/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1699 - acc: 0.9493 - val_loss: 0.5141 - val_acc: 0.8845\n",
      "Epoch 68/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.1744 - acc: 0.9464 - val_loss: 0.5164 - val_acc: 0.8826\n",
      "Epoch 69/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1662 - acc: 0.9502 - val_loss: 0.5001 - val_acc: 0.8870\n",
      "Epoch 70/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1670 - acc: 0.9496 - val_loss: 0.5324 - val_acc: 0.8794\n",
      "Epoch 71/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.1651 - acc: 0.9506 - val_loss: 0.5075 - val_acc: 0.8827\n",
      "Epoch 72/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1622 - acc: 0.9501 - val_loss: 0.5213 - val_acc: 0.8807\n",
      "Epoch 73/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1583 - acc: 0.9529 - val_loss: 0.5103 - val_acc: 0.8862\n",
      "Epoch 74/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1618 - acc: 0.9500 - val_loss: 0.5191 - val_acc: 0.8859\n",
      "Epoch 75/500\n",
      "34108/34108 [==============================] - 1s 23us/step - loss: 0.1572 - acc: 0.9518 - val_loss: 0.5224 - val_acc: 0.8851\n",
      "Epoch 76/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1533 - acc: 0.9536 - val_loss: 0.5552 - val_acc: 0.8764\n",
      "Epoch 77/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1512 - acc: 0.9545 - val_loss: 0.5366 - val_acc: 0.8839\n",
      "Epoch 78/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1526 - acc: 0.9532 - val_loss: 0.5362 - val_acc: 0.8821\n",
      "Epoch 79/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1448 - acc: 0.9563 - val_loss: 0.5479 - val_acc: 0.8788\n",
      "Epoch 80/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1458 - acc: 0.9557 - val_loss: 0.5604 - val_acc: 0.8797\n",
      "Epoch 81/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.1465 - acc: 0.9565 - val_loss: 0.5296 - val_acc: 0.8838\n",
      "Epoch 82/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1400 - acc: 0.9592 - val_loss: 0.5911 - val_acc: 0.8739\n",
      "Epoch 83/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.1421 - acc: 0.9574 - val_loss: 0.5383 - val_acc: 0.8832\n",
      "Epoch 84/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1398 - acc: 0.9583 - val_loss: 0.5273 - val_acc: 0.8862\n",
      "Epoch 85/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1381 - acc: 0.9578 - val_loss: 0.5423 - val_acc: 0.8817\n",
      "Epoch 86/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1369 - acc: 0.9593 - val_loss: 0.5563 - val_acc: 0.8798\n",
      "Epoch 87/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1325 - acc: 0.9605 - val_loss: 0.5963 - val_acc: 0.8696\n",
      "Epoch 88/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1338 - acc: 0.9584 - val_loss: 0.5641 - val_acc: 0.8822\n",
      "Epoch 89/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.1312 - acc: 0.9593 - val_loss: 0.5641 - val_acc: 0.8845\n",
      "Epoch 90/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1303 - acc: 0.9615 - val_loss: 0.5489 - val_acc: 0.8867\n",
      "Epoch 91/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1273 - acc: 0.9610 - val_loss: 0.5551 - val_acc: 0.8838\n",
      "Epoch 92/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1275 - acc: 0.9612 - val_loss: 0.5686 - val_acc: 0.8821\n",
      "Epoch 93/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.1242 - acc: 0.9627 - val_loss: 0.5533 - val_acc: 0.8851\n",
      "Epoch 94/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1246 - acc: 0.9621 - val_loss: 0.5579 - val_acc: 0.8839\n",
      "Epoch 95/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.1244 - acc: 0.9622 - val_loss: 0.5718 - val_acc: 0.8803\n",
      "Epoch 96/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1343 - acc: 0.9587 - val_loss: 0.5629 - val_acc: 0.8837\n",
      "Epoch 97/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1203 - acc: 0.9644 - val_loss: 0.5721 - val_acc: 0.8840\n",
      "Epoch 98/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.1212 - acc: 0.9626 - val_loss: 0.6019 - val_acc: 0.8757\n",
      "Epoch 99/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1135 - acc: 0.9658 - val_loss: 0.6030 - val_acc: 0.8733\n",
      "Epoch 100/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.1147 - acc: 0.9657 - val_loss: 0.5633 - val_acc: 0.8836\n",
      "Epoch 101/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.1154 - acc: 0.9660 - val_loss: 0.5734 - val_acc: 0.8816\n",
      "Epoch 102/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.1127 - acc: 0.9654 - val_loss: 0.5849 - val_acc: 0.8818\n",
      "Epoch 103/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.1169 - acc: 0.9653 - val_loss: 0.6027 - val_acc: 0.8799\n",
      "Epoch 104/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1118 - acc: 0.9659 - val_loss: 0.5888 - val_acc: 0.8812\n",
      "Epoch 105/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1185 - acc: 0.9626 - val_loss: 0.5859 - val_acc: 0.8875\n",
      "Epoch 106/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1043 - acc: 0.9696 - val_loss: 0.5821 - val_acc: 0.8863\n",
      "Epoch 107/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1165 - acc: 0.9644 - val_loss: 0.6002 - val_acc: 0.8818\n",
      "Epoch 108/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1010 - acc: 0.9706 - val_loss: 0.5855 - val_acc: 0.8852\n",
      "Epoch 109/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1049 - acc: 0.9694 - val_loss: 0.5864 - val_acc: 0.8861\n",
      "Epoch 110/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1094 - acc: 0.9672 - val_loss: 0.5827 - val_acc: 0.8838\n",
      "Epoch 111/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0998 - acc: 0.9716 - val_loss: 0.5813 - val_acc: 0.8886\n",
      "Epoch 112/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0983 - acc: 0.9715 - val_loss: 0.5963 - val_acc: 0.8846\n",
      "Epoch 113/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.1025 - acc: 0.9693 - val_loss: 0.6026 - val_acc: 0.8854\n",
      "Epoch 114/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.1000 - acc: 0.9707 - val_loss: 0.5919 - val_acc: 0.8845\n",
      "Epoch 115/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.1040 - acc: 0.9688 - val_loss: 0.5975 - val_acc: 0.8842\n",
      "Epoch 116/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0948 - acc: 0.9726 - val_loss: 0.6292 - val_acc: 0.8754\n",
      "Epoch 117/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0978 - acc: 0.9708 - val_loss: 0.6181 - val_acc: 0.8785\n",
      "Epoch 118/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0959 - acc: 0.9717 - val_loss: 0.6218 - val_acc: 0.8792\n",
      "Epoch 119/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.1013 - acc: 0.9691 - val_loss: 0.6166 - val_acc: 0.8816\n",
      "Epoch 120/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0936 - acc: 0.9725 - val_loss: 0.6155 - val_acc: 0.8840\n",
      "Epoch 121/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0958 - acc: 0.9714 - val_loss: 0.6072 - val_acc: 0.8846\n",
      "Epoch 122/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0889 - acc: 0.9742 - val_loss: 0.6068 - val_acc: 0.8859\n",
      "Epoch 123/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0899 - acc: 0.9741 - val_loss: 0.6197 - val_acc: 0.8824\n",
      "Epoch 124/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0966 - acc: 0.9702 - val_loss: 0.6193 - val_acc: 0.8843\n",
      "Epoch 125/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0934 - acc: 0.9721 - val_loss: 0.6292 - val_acc: 0.8862\n",
      "Epoch 126/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0885 - acc: 0.9747 - val_loss: 0.6222 - val_acc: 0.8857\n",
      "Epoch 127/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0937 - acc: 0.9715 - val_loss: 0.6148 - val_acc: 0.8846\n",
      "Epoch 128/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0837 - acc: 0.9761 - val_loss: 0.6712 - val_acc: 0.8768\n",
      "Epoch 129/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0864 - acc: 0.9743 - val_loss: 0.6190 - val_acc: 0.8849\n",
      "Epoch 130/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0865 - acc: 0.9736 - val_loss: 0.6682 - val_acc: 0.8771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0862 - acc: 0.9756 - val_loss: 0.6614 - val_acc: 0.8772\n",
      "Epoch 132/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0814 - acc: 0.9765 - val_loss: 0.6728 - val_acc: 0.8788\n",
      "Epoch 133/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0790 - acc: 0.9779 - val_loss: 0.6353 - val_acc: 0.8828\n",
      "Epoch 134/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0839 - acc: 0.9751 - val_loss: 0.6347 - val_acc: 0.8860\n",
      "Epoch 135/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0783 - acc: 0.9770 - val_loss: 0.6420 - val_acc: 0.8831\n",
      "Epoch 136/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0801 - acc: 0.9774 - val_loss: 0.6357 - val_acc: 0.8864\n",
      "Epoch 137/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0804 - acc: 0.9765 - val_loss: 0.6378 - val_acc: 0.8859\n",
      "Epoch 138/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0872 - acc: 0.9737 - val_loss: 0.6477 - val_acc: 0.8814\n",
      "Epoch 139/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0800 - acc: 0.9767 - val_loss: 0.6398 - val_acc: 0.8882\n",
      "Epoch 140/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0745 - acc: 0.9790 - val_loss: 0.6604 - val_acc: 0.8868\n",
      "Epoch 141/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0777 - acc: 0.9780 - val_loss: 0.6527 - val_acc: 0.8841\n",
      "Epoch 142/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0788 - acc: 0.9772 - val_loss: 0.6487 - val_acc: 0.8842\n",
      "Epoch 143/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0758 - acc: 0.9781 - val_loss: 0.6472 - val_acc: 0.8884\n",
      "Epoch 144/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0725 - acc: 0.9788 - val_loss: 0.6682 - val_acc: 0.8819\n",
      "Epoch 145/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0777 - acc: 0.9772 - val_loss: 0.6906 - val_acc: 0.8762\n",
      "Epoch 146/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0848 - acc: 0.9748 - val_loss: 0.6755 - val_acc: 0.8783\n",
      "Epoch 147/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0705 - acc: 0.9810 - val_loss: 0.6743 - val_acc: 0.8816\n",
      "Epoch 148/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0731 - acc: 0.9792 - val_loss: 0.6761 - val_acc: 0.8835\n",
      "Epoch 149/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0714 - acc: 0.9790 - val_loss: 0.6769 - val_acc: 0.8826\n",
      "Epoch 150/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0682 - acc: 0.9814 - val_loss: 0.6687 - val_acc: 0.8850\n",
      "Epoch 151/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0741 - acc: 0.9782 - val_loss: 0.6636 - val_acc: 0.8863\n",
      "Epoch 152/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0717 - acc: 0.9797 - val_loss: 0.6622 - val_acc: 0.8868\n",
      "Epoch 153/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0684 - acc: 0.9803 - val_loss: 0.6704 - val_acc: 0.8859\n",
      "Epoch 154/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0640 - acc: 0.9826 - val_loss: 0.6920 - val_acc: 0.8805\n",
      "Epoch 155/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0775 - acc: 0.9765 - val_loss: 0.6948 - val_acc: 0.8803\n",
      "Epoch 156/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0764 - acc: 0.9774 - val_loss: 0.6751 - val_acc: 0.8841\n",
      "Epoch 157/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0599 - acc: 0.9842 - val_loss: 0.6815 - val_acc: 0.8837\n",
      "Epoch 158/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0600 - acc: 0.9834 - val_loss: 0.7254 - val_acc: 0.8760\n",
      "Epoch 159/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0651 - acc: 0.9816 - val_loss: 0.7388 - val_acc: 0.8727\n",
      "Epoch 160/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0678 - acc: 0.9804 - val_loss: 0.6816 - val_acc: 0.8821\n",
      "Epoch 161/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0621 - acc: 0.9830 - val_loss: 0.6975 - val_acc: 0.8851\n",
      "Epoch 162/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0659 - acc: 0.9809 - val_loss: 0.7100 - val_acc: 0.8779\n",
      "Epoch 163/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0610 - acc: 0.9836 - val_loss: 0.7003 - val_acc: 0.8859\n",
      "Epoch 164/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0650 - acc: 0.9814 - val_loss: 0.7123 - val_acc: 0.8824\n",
      "Epoch 165/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0598 - acc: 0.9833 - val_loss: 0.6981 - val_acc: 0.8856\n",
      "Epoch 166/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0592 - acc: 0.9838 - val_loss: 0.7291 - val_acc: 0.8820\n",
      "Epoch 167/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0646 - acc: 0.9820 - val_loss: 0.7610 - val_acc: 0.8694\n",
      "Epoch 168/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0658 - acc: 0.9807 - val_loss: 0.7239 - val_acc: 0.8812\n",
      "Epoch 169/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0534 - acc: 0.9857 - val_loss: 0.6952 - val_acc: 0.8903\n",
      "Epoch 170/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0569 - acc: 0.9850 - val_loss: 0.7146 - val_acc: 0.8826\n",
      "Epoch 171/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0711 - acc: 0.9790 - val_loss: 0.7265 - val_acc: 0.8785\n",
      "Epoch 172/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0640 - acc: 0.9813 - val_loss: 0.7624 - val_acc: 0.8736\n",
      "Epoch 173/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0681 - acc: 0.9794 - val_loss: 0.7880 - val_acc: 0.8673\n",
      "Epoch 174/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0559 - acc: 0.9850 - val_loss: 0.7478 - val_acc: 0.8772\n",
      "Epoch 175/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0565 - acc: 0.9849 - val_loss: 0.7081 - val_acc: 0.8869\n",
      "Epoch 176/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0557 - acc: 0.9843 - val_loss: 0.7383 - val_acc: 0.8804\n",
      "Epoch 177/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0615 - acc: 0.9823 - val_loss: 0.7409 - val_acc: 0.8817\n",
      "Epoch 178/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0531 - acc: 0.9855 - val_loss: 0.7191 - val_acc: 0.8859\n",
      "Epoch 179/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0557 - acc: 0.9851 - val_loss: 0.7362 - val_acc: 0.8843\n",
      "Epoch 180/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0584 - acc: 0.9836 - val_loss: 0.7251 - val_acc: 0.8855\n",
      "Epoch 181/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0522 - acc: 0.9866 - val_loss: 0.7138 - val_acc: 0.8887\n",
      "Epoch 182/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0462 - acc: 0.9883 - val_loss: 0.7321 - val_acc: 0.8831\n",
      "Epoch 183/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0567 - acc: 0.9841 - val_loss: 0.7618 - val_acc: 0.8801\n",
      "Epoch 184/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0628 - acc: 0.9817 - val_loss: 0.8090 - val_acc: 0.8660\n",
      "Epoch 185/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0595 - acc: 0.9829 - val_loss: 0.7496 - val_acc: 0.8818\n",
      "Epoch 186/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0524 - acc: 0.9853 - val_loss: 0.7440 - val_acc: 0.8831\n",
      "Epoch 187/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0535 - acc: 0.9857 - val_loss: 0.7667 - val_acc: 0.8801\n",
      "Epoch 188/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0604 - acc: 0.9824 - val_loss: 0.7701 - val_acc: 0.8792\n",
      "Epoch 189/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0590 - acc: 0.9823 - val_loss: 0.7304 - val_acc: 0.8881\n",
      "Epoch 190/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0419 - acc: 0.9905 - val_loss: 0.7376 - val_acc: 0.8844\n",
      "Epoch 191/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0419 - acc: 0.9906 - val_loss: 0.7423 - val_acc: 0.8824\n",
      "Epoch 192/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0548 - acc: 0.9845 - val_loss: 0.7586 - val_acc: 0.8851\n",
      "Epoch 193/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0425 - acc: 0.9899 - val_loss: 0.7638 - val_acc: 0.8807\n",
      "Epoch 194/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0544 - acc: 0.9848 - val_loss: 0.7945 - val_acc: 0.8733\n",
      "Epoch 195/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0661 - acc: 0.9799 - val_loss: 0.7624 - val_acc: 0.8795\n",
      "Epoch 196/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0466 - acc: 0.9869 - val_loss: 0.7430 - val_acc: 0.8868\n",
      "Epoch 197/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0629 - acc: 0.9814 - val_loss: 0.7645 - val_acc: 0.8806\n",
      "Epoch 198/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0471 - acc: 0.9878 - val_loss: 0.7794 - val_acc: 0.8803\n",
      "Epoch 199/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0426 - acc: 0.9899 - val_loss: 0.7484 - val_acc: 0.8855\n",
      "Epoch 200/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0373 - acc: 0.9921 - val_loss: 0.8315 - val_acc: 0.8694\n",
      "Epoch 201/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0514 - acc: 0.9856 - val_loss: 0.7720 - val_acc: 0.8814\n",
      "Epoch 202/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0531 - acc: 0.9849 - val_loss: 0.8063 - val_acc: 0.8734\n",
      "Epoch 203/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0542 - acc: 0.9846 - val_loss: 0.7647 - val_acc: 0.8845\n",
      "Epoch 204/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0362 - acc: 0.9921 - val_loss: 0.7832 - val_acc: 0.8801\n",
      "Epoch 205/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0392 - acc: 0.9908 - val_loss: 0.7572 - val_acc: 0.8853\n",
      "Epoch 206/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0539 - acc: 0.9842 - val_loss: 0.7890 - val_acc: 0.8790\n",
      "Epoch 207/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0544 - acc: 0.9841 - val_loss: 0.7925 - val_acc: 0.8765\n",
      "Epoch 208/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0416 - acc: 0.9895 - val_loss: 0.7649 - val_acc: 0.8840\n",
      "Epoch 209/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0399 - acc: 0.9904 - val_loss: 0.7978 - val_acc: 0.8778\n",
      "Epoch 210/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0449 - acc: 0.9882 - val_loss: 0.7818 - val_acc: 0.8816\n",
      "Epoch 211/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0472 - acc: 0.9872 - val_loss: 0.7780 - val_acc: 0.8834\n",
      "Epoch 212/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0585 - acc: 0.9825 - val_loss: 0.7916 - val_acc: 0.8812\n",
      "Epoch 213/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0452 - acc: 0.9880 - val_loss: 0.7642 - val_acc: 0.8840\n",
      "Epoch 214/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0405 - acc: 0.9898 - val_loss: 0.7758 - val_acc: 0.8826\n",
      "Epoch 215/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0363 - acc: 0.9918 - val_loss: 0.7701 - val_acc: 0.8845\n",
      "Epoch 216/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0378 - acc: 0.9904 - val_loss: 0.7723 - val_acc: 0.8857\n",
      "Epoch 217/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0519 - acc: 0.9848 - val_loss: 0.7927 - val_acc: 0.8818\n",
      "Epoch 218/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0391 - acc: 0.9897 - val_loss: 0.7804 - val_acc: 0.8841\n",
      "Epoch 219/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0351 - acc: 0.9922 - val_loss: 0.8043 - val_acc: 0.8762\n",
      "Epoch 220/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0561 - acc: 0.9831 - val_loss: 0.8105 - val_acc: 0.8781\n",
      "Epoch 221/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0574 - acc: 0.9821 - val_loss: 0.8046 - val_acc: 0.8781\n",
      "Epoch 222/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0333 - acc: 0.9928 - val_loss: 0.7720 - val_acc: 0.8860\n",
      "Epoch 223/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0365 - acc: 0.9912 - val_loss: 0.7913 - val_acc: 0.8840\n",
      "Epoch 224/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0443 - acc: 0.9881 - val_loss: 0.7919 - val_acc: 0.8799\n",
      "Epoch 225/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0534 - acc: 0.9848 - val_loss: 0.8192 - val_acc: 0.8790\n",
      "Epoch 226/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0322 - acc: 0.9927 - val_loss: 0.7845 - val_acc: 0.8864\n",
      "Epoch 227/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0292 - acc: 0.9940 - val_loss: 0.7943 - val_acc: 0.8820\n",
      "Epoch 228/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0451 - acc: 0.9867 - val_loss: 0.8423 - val_acc: 0.8792\n",
      "Epoch 229/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0531 - acc: 0.9826 - val_loss: 0.7792 - val_acc: 0.8888\n",
      "Epoch 230/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0320 - acc: 0.9930 - val_loss: 0.7935 - val_acc: 0.8833\n",
      "Epoch 231/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0264 - acc: 0.9950 - val_loss: 0.7871 - val_acc: 0.8873\n",
      "Epoch 232/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0342 - acc: 0.9915 - val_loss: 0.7879 - val_acc: 0.8862\n",
      "Epoch 233/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0517 - acc: 0.9848 - val_loss: 0.8358 - val_acc: 0.8769\n",
      "Epoch 234/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0396 - acc: 0.9896 - val_loss: 0.7878 - val_acc: 0.8859\n",
      "Epoch 235/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0301 - acc: 0.9939 - val_loss: 0.8197 - val_acc: 0.8819\n",
      "Epoch 236/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0534 - acc: 0.9851 - val_loss: 0.8415 - val_acc: 0.8739\n",
      "Epoch 237/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0558 - acc: 0.9824 - val_loss: 0.8172 - val_acc: 0.8817\n",
      "Epoch 238/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0306 - acc: 0.9933 - val_loss: 0.8116 - val_acc: 0.8832\n",
      "Epoch 239/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0273 - acc: 0.9943 - val_loss: 0.7933 - val_acc: 0.8872\n",
      "Epoch 240/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0278 - acc: 0.9943 - val_loss: 0.8481 - val_acc: 0.8763\n",
      "Epoch 241/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0376 - acc: 0.9902 - val_loss: 0.8499 - val_acc: 0.8797\n",
      "Epoch 242/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0461 - acc: 0.9867 - val_loss: 0.8254 - val_acc: 0.8822\n",
      "Epoch 243/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0492 - acc: 0.9859 - val_loss: 0.8189 - val_acc: 0.8855\n",
      "Epoch 244/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0366 - acc: 0.9904 - val_loss: 0.8352 - val_acc: 0.8807\n",
      "Epoch 245/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0256 - acc: 0.9950 - val_loss: 0.8121 - val_acc: 0.8848\n",
      "Epoch 246/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0267 - acc: 0.9946 - val_loss: 0.8424 - val_acc: 0.8800\n",
      "Epoch 247/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0608 - acc: 0.9819 - val_loss: 0.8417 - val_acc: 0.8811\n",
      "Epoch 248/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0289 - acc: 0.9932 - val_loss: 0.8235 - val_acc: 0.8846\n",
      "Epoch 249/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0228 - acc: 0.9962 - val_loss: 0.8368 - val_acc: 0.8807\n",
      "Epoch 250/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0244 - acc: 0.9955 - val_loss: 0.8132 - val_acc: 0.8861\n",
      "Epoch 251/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0595 - acc: 0.9823 - val_loss: 0.8554 - val_acc: 0.8796\n",
      "Epoch 252/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0530 - acc: 0.9844 - val_loss: 0.8257 - val_acc: 0.8840\n",
      "Epoch 253/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0248 - acc: 0.9953 - val_loss: 0.8167 - val_acc: 0.8870\n",
      "Epoch 254/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0217 - acc: 0.9965 - val_loss: 0.8172 - val_acc: 0.8873\n",
      "Epoch 255/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0237 - acc: 0.9957 - val_loss: 0.8538 - val_acc: 0.8795\n",
      "Epoch 256/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0547 - acc: 0.9831 - val_loss: 0.8235 - val_acc: 0.8831\n",
      "Epoch 257/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0408 - acc: 0.9887 - val_loss: 0.8713 - val_acc: 0.8770\n",
      "Epoch 258/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0267 - acc: 0.9943 - val_loss: 0.8305 - val_acc: 0.8848\n",
      "Epoch 259/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0230 - acc: 0.9958 - val_loss: 0.8235 - val_acc: 0.8865\n",
      "Epoch 260/500\n",
      "34108/34108 [==============================] - ETA: 0s - loss: 0.0235 - acc: 0.995 - 1s 24us/step - loss: 0.0234 - acc: 0.9959 - val_loss: 0.8300 - val_acc: 0.8848\n",
      "Epoch 261/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0433 - acc: 0.9885 - val_loss: 0.8909 - val_acc: 0.8762\n",
      "Epoch 262/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0631 - acc: 0.9815 - val_loss: 0.8649 - val_acc: 0.8758\n",
      "Epoch 263/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0375 - acc: 0.9903 - val_loss: 0.8417 - val_acc: 0.8828\n",
      "Epoch 264/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0209 - acc: 0.9965 - val_loss: 0.8327 - val_acc: 0.8851\n",
      "Epoch 265/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0258 - acc: 0.9941 - val_loss: 0.9021 - val_acc: 0.8747\n",
      "Epoch 266/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0423 - acc: 0.9883 - val_loss: 0.8382 - val_acc: 0.8850\n",
      "Epoch 267/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0195 - acc: 0.9970 - val_loss: 0.8312 - val_acc: 0.8855\n",
      "Epoch 268/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0564 - acc: 0.9838 - val_loss: 0.9578 - val_acc: 0.8718\n",
      "Epoch 269/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0451 - acc: 0.9872 - val_loss: 0.8467 - val_acc: 0.8835\n",
      "Epoch 270/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0197 - acc: 0.9966 - val_loss: 0.8426 - val_acc: 0.8855\n",
      "Epoch 271/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0310 - acc: 0.9921 - val_loss: 0.8865 - val_acc: 0.8757\n",
      "Epoch 272/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0431 - acc: 0.9881 - val_loss: 0.8767 - val_acc: 0.8782\n",
      "Epoch 273/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0253 - acc: 0.9946 - val_loss: 0.8431 - val_acc: 0.8861\n",
      "Epoch 274/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0188 - acc: 0.9969 - val_loss: 0.8434 - val_acc: 0.8845\n",
      "Epoch 275/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0365 - acc: 0.9896 - val_loss: 0.9335 - val_acc: 0.8718\n",
      "Epoch 276/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0722 - acc: 0.9770 - val_loss: 0.8601 - val_acc: 0.8799\n",
      "Epoch 277/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0231 - acc: 0.9953 - val_loss: 0.8562 - val_acc: 0.8843\n",
      "Epoch 278/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0177 - acc: 0.9976 - val_loss: 0.8495 - val_acc: 0.8845\n",
      "Epoch 279/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0177 - acc: 0.9975 - val_loss: 0.9076 - val_acc: 0.8727\n",
      "Epoch 280/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0619 - acc: 0.9798 - val_loss: 0.9249 - val_acc: 0.8714\n",
      "Epoch 281/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0388 - acc: 0.9897 - val_loss: 0.8489 - val_acc: 0.8840\n",
      "Epoch 282/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0182 - acc: 0.9971 - val_loss: 0.8799 - val_acc: 0.8828\n",
      "Epoch 283/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0167 - acc: 0.9978 - val_loss: 0.8487 - val_acc: 0.8845\n",
      "Epoch 284/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0241 - acc: 0.9948 - val_loss: 0.8744 - val_acc: 0.8831\n",
      "Epoch 285/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0544 - acc: 0.9834 - val_loss: 0.8592 - val_acc: 0.8841\n",
      "Epoch 286/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0217 - acc: 0.9954 - val_loss: 0.8557 - val_acc: 0.8837\n",
      "Epoch 287/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0181 - acc: 0.9972 - val_loss: 0.8665 - val_acc: 0.8837\n",
      "Epoch 288/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0252 - acc: 0.9945 - val_loss: 0.8920 - val_acc: 0.8795\n",
      "Epoch 289/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0520 - acc: 0.9843 - val_loss: 0.9932 - val_acc: 0.8622\n",
      "Epoch 290/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0516 - acc: 0.9849 - val_loss: 0.8613 - val_acc: 0.8848\n",
      "Epoch 291/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0161 - acc: 0.9978 - val_loss: 0.8674 - val_acc: 0.8838\n",
      "Epoch 292/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0162 - acc: 0.9977 - val_loss: 0.8504 - val_acc: 0.8860\n",
      "Epoch 293/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0347 - acc: 0.9899 - val_loss: 0.8952 - val_acc: 0.8795\n",
      "Epoch 294/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0487 - acc: 0.9850 - val_loss: 1.0040 - val_acc: 0.8595\n",
      "Epoch 295/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0332 - acc: 0.9908 - val_loss: 0.8919 - val_acc: 0.8801\n",
      "Epoch 296/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0174 - acc: 0.9973 - val_loss: 0.8641 - val_acc: 0.8847\n",
      "Epoch 297/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0160 - acc: 0.9979 - val_loss: 0.8771 - val_acc: 0.8839\n",
      "Epoch 298/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0141 - acc: 0.9984 - val_loss: 0.8643 - val_acc: 0.8865\n",
      "Epoch 299/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0196 - acc: 0.9963 - val_loss: 0.8878 - val_acc: 0.8846\n",
      "Epoch 300/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0771 - acc: 0.9766 - val_loss: 0.9230 - val_acc: 0.8753\n",
      "Epoch 301/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0464 - acc: 0.9860 - val_loss: 0.8922 - val_acc: 0.8829\n",
      "Epoch 302/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0187 - acc: 0.9967 - val_loss: 0.8738 - val_acc: 0.8858\n",
      "Epoch 303/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0142 - acc: 0.9985 - val_loss: 0.8773 - val_acc: 0.8850\n",
      "Epoch 304/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0203 - acc: 0.9962 - val_loss: 0.8781 - val_acc: 0.8844\n",
      "Epoch 305/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0537 - acc: 0.9833 - val_loss: 0.8894 - val_acc: 0.8804\n",
      "Epoch 306/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0215 - acc: 0.9957 - val_loss: 0.8753 - val_acc: 0.8862\n",
      "Epoch 307/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0140 - acc: 0.9984 - val_loss: 0.8750 - val_acc: 0.8840\n",
      "Epoch 308/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0182 - acc: 0.9968 - val_loss: 0.9145 - val_acc: 0.8827\n",
      "Epoch 309/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0692 - acc: 0.9785 - val_loss: 0.9290 - val_acc: 0.8762\n",
      "Epoch 310/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0300 - acc: 0.9920 - val_loss: 0.8616 - val_acc: 0.8867\n",
      "Epoch 311/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0136 - acc: 0.9985 - val_loss: 0.8707 - val_acc: 0.8862\n",
      "Epoch 312/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0132 - acc: 0.9985 - val_loss: 0.8728 - val_acc: 0.8869\n",
      "Epoch 313/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0149 - acc: 0.9978 - val_loss: 0.8933 - val_acc: 0.8849\n",
      "Epoch 314/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0701 - acc: 0.9788 - val_loss: 0.9375 - val_acc: 0.8741\n",
      "Epoch 315/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0275 - acc: 0.9930 - val_loss: 0.8832 - val_acc: 0.8846\n",
      "Epoch 316/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0135 - acc: 0.9984 - val_loss: 0.8908 - val_acc: 0.8868\n",
      "Epoch 317/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0132 - acc: 0.9984 - val_loss: 0.8938 - val_acc: 0.8857\n",
      "Epoch 318/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0133 - acc: 0.9987 - val_loss: 0.9070 - val_acc: 0.8816\n",
      "Epoch 319/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0612 - acc: 0.9811 - val_loss: 0.9092 - val_acc: 0.8777\n",
      "Epoch 320/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0510 - acc: 0.9848 - val_loss: 0.8892 - val_acc: 0.8847\n",
      "Epoch 321/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0157 - acc: 0.9976 - val_loss: 0.8914 - val_acc: 0.8854\n",
      "Epoch 322/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0138 - acc: 0.9981 - val_loss: 0.8821 - val_acc: 0.8870\n",
      "Epoch 323/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0126 - acc: 0.9987 - val_loss: 0.8866 - val_acc: 0.8856\n",
      "Epoch 324/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0135 - acc: 0.9983 - val_loss: 0.9260 - val_acc: 0.8789\n",
      "Epoch 325/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0782 - acc: 0.9753 - val_loss: 0.9794 - val_acc: 0.8745\n",
      "Epoch 326/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0404 - acc: 0.9882 - val_loss: 0.9183 - val_acc: 0.8784\n",
      "Epoch 327/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0125 - acc: 0.9987 - val_loss: 0.9023 - val_acc: 0.8845\n",
      "Epoch 328/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0114 - acc: 0.9989 - val_loss: 0.9038 - val_acc: 0.8831\n",
      "Epoch 329/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0124 - acc: 0.9987 - val_loss: 0.9072 - val_acc: 0.8829\n",
      "Epoch 330/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0460 - acc: 0.9877 - val_loss: 0.9954 - val_acc: 0.8673\n",
      "Epoch 331/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0458 - acc: 0.9864 - val_loss: 0.9244 - val_acc: 0.8800\n",
      "Epoch 332/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0158 - acc: 0.9976 - val_loss: 0.9142 - val_acc: 0.8829\n",
      "Epoch 333/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0113 - acc: 0.9993 - val_loss: 0.9095 - val_acc: 0.8848\n",
      "Epoch 334/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0141 - acc: 0.9979 - val_loss: 0.9302 - val_acc: 0.8827\n",
      "Epoch 335/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0721 - acc: 0.9776 - val_loss: 1.0077 - val_acc: 0.8637\n",
      "Epoch 336/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0283 - acc: 0.9923 - val_loss: 0.9166 - val_acc: 0.8819\n",
      "Epoch 337/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0123 - acc: 0.9987 - val_loss: 0.8979 - val_acc: 0.8860\n",
      "Epoch 338/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0113 - acc: 0.9988 - val_loss: 0.8996 - val_acc: 0.8855\n",
      "Epoch 339/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0107 - acc: 0.9993 - val_loss: 0.9013 - val_acc: 0.8864\n",
      "Epoch 340/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0112 - acc: 0.9989 - val_loss: 0.9122 - val_acc: 0.8836\n",
      "Epoch 341/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0116 - acc: 0.9991 - val_loss: 0.9186 - val_acc: 0.8850\n",
      "Epoch 342/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1108 - acc: 0.9685 - val_loss: 0.9394 - val_acc: 0.8789\n",
      "Epoch 343/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0389 - acc: 0.9891 - val_loss: 0.9104 - val_acc: 0.8822\n",
      "Epoch 344/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0203 - acc: 0.9956 - val_loss: 0.9250 - val_acc: 0.8821\n",
      "Epoch 345/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0109 - acc: 0.9991 - val_loss: 0.9112 - val_acc: 0.8841\n",
      "Epoch 346/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0115 - acc: 0.9988 - val_loss: 0.9431 - val_acc: 0.8764\n",
      "Epoch 347/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0131 - acc: 0.9984 - val_loss: 0.9066 - val_acc: 0.8855\n",
      "Epoch 348/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0292 - acc: 0.9925 - val_loss: 0.9711 - val_acc: 0.8752\n",
      "Epoch 349/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0816 - acc: 0.9772 - val_loss: 0.9457 - val_acc: 0.8796\n",
      "Epoch 350/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0189 - acc: 0.9961 - val_loss: 0.9168 - val_acc: 0.8813\n",
      "Epoch 351/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0102 - acc: 0.9993 - val_loss: 0.9150 - val_acc: 0.8844\n",
      "Epoch 352/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0098 - acc: 0.9994 - val_loss: 0.9119 - val_acc: 0.8852\n",
      "Epoch 353/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0095 - acc: 0.9994 - val_loss: 0.9202 - val_acc: 0.8847\n",
      "Epoch 354/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0105 - acc: 0.9992 - val_loss: 0.9097 - val_acc: 0.8850\n",
      "Epoch 355/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0556 - acc: 0.9829 - val_loss: 1.0843 - val_acc: 0.8665\n",
      "Epoch 356/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0547 - acc: 0.9836 - val_loss: 0.9261 - val_acc: 0.8842\n",
      "Epoch 357/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0155 - acc: 0.9975 - val_loss: 0.9273 - val_acc: 0.8811\n",
      "Epoch 358/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0114 - acc: 0.9986 - val_loss: 0.9198 - val_acc: 0.8836\n",
      "Epoch 359/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0100 - acc: 0.9993 - val_loss: 0.9114 - val_acc: 0.8863\n",
      "Epoch 360/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0101 - acc: 0.9992 - val_loss: 0.9364 - val_acc: 0.8810\n",
      "Epoch 361/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0123 - acc: 0.9987 - val_loss: 0.9380 - val_acc: 0.8833\n",
      "Epoch 362/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0781 - acc: 0.9765 - val_loss: 0.9572 - val_acc: 0.8805\n",
      "Epoch 363/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0315 - acc: 0.9913 - val_loss: 0.9254 - val_acc: 0.8836\n",
      "Epoch 364/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0125 - acc: 0.9984 - val_loss: 0.9265 - val_acc: 0.8837\n",
      "Epoch 365/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0094 - acc: 0.9993 - val_loss: 0.9171 - val_acc: 0.8863\n",
      "Epoch 366/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0094 - acc: 0.9992 - val_loss: 0.9308 - val_acc: 0.8848\n",
      "Epoch 367/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0110 - acc: 0.9991 - val_loss: 0.9166 - val_acc: 0.8873\n",
      "Epoch 368/500\n",
      "34108/34108 [==============================] - 1s 23us/step - loss: 0.0104 - acc: 0.9989 - val_loss: 0.9333 - val_acc: 0.8836\n",
      "Epoch 369/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0946 - acc: 0.9750 - val_loss: 0.9937 - val_acc: 0.8759\n",
      "Epoch 370/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0373 - acc: 0.9895 - val_loss: 0.9221 - val_acc: 0.8844\n",
      "Epoch 371/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0107 - acc: 0.9989 - val_loss: 0.9239 - val_acc: 0.8845\n",
      "Epoch 372/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0088 - acc: 0.9996 - val_loss: 0.9179 - val_acc: 0.8860\n",
      "Epoch 373/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0262 - acc: 0.9929 - val_loss: 1.0047 - val_acc: 0.8732\n",
      "Epoch 374/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0420 - acc: 0.9871 - val_loss: 0.9676 - val_acc: 0.8764\n",
      "Epoch 375/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0190 - acc: 0.9960 - val_loss: 0.9236 - val_acc: 0.8874\n",
      "Epoch 376/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0094 - acc: 0.9993 - val_loss: 0.9317 - val_acc: 0.8856\n",
      "Epoch 377/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0088 - acc: 0.9993 - val_loss: 0.9290 - val_acc: 0.8858\n",
      "Epoch 378/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0085 - acc: 0.9996 - val_loss: 0.9381 - val_acc: 0.8845\n",
      "Epoch 379/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0090 - acc: 0.9994 - val_loss: 0.9454 - val_acc: 0.8831\n",
      "Epoch 380/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0665 - acc: 0.9833 - val_loss: 1.0042 - val_acc: 0.8708\n",
      "Epoch 381/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0685 - acc: 0.9782 - val_loss: 0.9235 - val_acc: 0.8853\n",
      "Epoch 382/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0112 - acc: 0.9988 - val_loss: 0.9390 - val_acc: 0.8831\n",
      "Epoch 383/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0089 - acc: 0.9994 - val_loss: 0.9292 - val_acc: 0.8847\n",
      "Epoch 384/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0097 - acc: 0.9992 - val_loss: 0.9379 - val_acc: 0.8864\n",
      "Epoch 385/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0082 - acc: 0.9994 - val_loss: 0.9322 - val_acc: 0.8855\n",
      "Epoch 386/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0081 - acc: 0.9996 - val_loss: 0.9255 - val_acc: 0.8863\n",
      "Epoch 387/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0080 - acc: 0.9996 - val_loss: 0.9325 - val_acc: 0.8864\n",
      "Epoch 388/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0590 - acc: 0.9855 - val_loss: 1.0324 - val_acc: 0.8684\n",
      "Epoch 389/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0865 - acc: 0.9750 - val_loss: 0.9625 - val_acc: 0.8748\n",
      "Epoch 390/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0149 - acc: 0.9973 - val_loss: 0.9354 - val_acc: 0.8854\n",
      "Epoch 391/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0084 - acc: 0.9996 - val_loss: 0.9367 - val_acc: 0.8855\n",
      "Epoch 392/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0079 - acc: 0.9996 - val_loss: 0.9258 - val_acc: 0.8860\n",
      "Epoch 393/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0078 - acc: 0.9997 - val_loss: 0.9352 - val_acc: 0.8861\n",
      "Epoch 394/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0082 - acc: 0.9993 - val_loss: 0.9389 - val_acc: 0.8842\n",
      "Epoch 395/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0083 - acc: 0.9995 - val_loss: 0.9412 - val_acc: 0.8855\n",
      "Epoch 396/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0181 - acc: 0.9962 - val_loss: 1.0402 - val_acc: 0.8686\n",
      "Epoch 397/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.1043 - acc: 0.9697 - val_loss: 1.0084 - val_acc: 0.8742\n",
      "Epoch 398/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0186 - acc: 0.9962 - val_loss: 0.9273 - val_acc: 0.8840\n",
      "Epoch 399/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0091 - acc: 0.9993 - val_loss: 0.9433 - val_acc: 0.8842\n",
      "Epoch 400/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0079 - acc: 0.9996 - val_loss: 0.9315 - val_acc: 0.8868\n",
      "Epoch 401/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0077 - acc: 0.9996 - val_loss: 0.9428 - val_acc: 0.8844\n",
      "Epoch 402/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0077 - acc: 0.9996 - val_loss: 0.9328 - val_acc: 0.8865\n",
      "Epoch 403/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0073 - acc: 0.9997 - val_loss: 0.9368 - val_acc: 0.8852\n",
      "Epoch 404/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0101 - acc: 0.9989 - val_loss: 0.9855 - val_acc: 0.8774\n",
      "Epoch 405/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1167 - acc: 0.9673 - val_loss: 0.9802 - val_acc: 0.8746\n",
      "Epoch 406/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0208 - acc: 0.9949 - val_loss: 0.9442 - val_acc: 0.8834\n",
      "Epoch 407/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0142 - acc: 0.9977 - val_loss: 0.9339 - val_acc: 0.8841\n",
      "Epoch 408/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0078 - acc: 0.9996 - val_loss: 0.9328 - val_acc: 0.8853\n",
      "Epoch 409/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0073 - acc: 0.9996 - val_loss: 0.9322 - val_acc: 0.8867\n",
      "Epoch 410/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0108 - acc: 0.9984 - val_loss: 0.9985 - val_acc: 0.8803\n",
      "Epoch 411/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0855 - acc: 0.9754 - val_loss: 0.9571 - val_acc: 0.8803\n",
      "Epoch 412/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0130 - acc: 0.9982 - val_loss: 0.9440 - val_acc: 0.8859\n",
      "Epoch 413/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0094 - acc: 0.9990 - val_loss: 0.9512 - val_acc: 0.8835\n",
      "Epoch 414/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0081 - acc: 0.9994 - val_loss: 0.9403 - val_acc: 0.8851\n",
      "Epoch 415/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0073 - acc: 0.9996 - val_loss: 0.9443 - val_acc: 0.8856\n",
      "Epoch 416/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0073 - acc: 0.9996 - val_loss: 0.9485 - val_acc: 0.8840\n",
      "Epoch 417/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0073 - acc: 0.9996 - val_loss: 0.9500 - val_acc: 0.8846\n",
      "Epoch 418/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0968 - acc: 0.9746 - val_loss: 0.9725 - val_acc: 0.8767\n",
      "Epoch 419/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0255 - acc: 0.9930 - val_loss: 0.9430 - val_acc: 0.8856\n",
      "Epoch 420/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0078 - acc: 0.9995 - val_loss: 0.9439 - val_acc: 0.8856\n",
      "Epoch 421/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0071 - acc: 0.9997 - val_loss: 0.9464 - val_acc: 0.8850\n",
      "Epoch 422/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0069 - acc: 0.9997 - val_loss: 0.9441 - val_acc: 0.8877\n",
      "Epoch 423/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0067 - acc: 0.9997 - val_loss: 0.9506 - val_acc: 0.8854\n",
      "Epoch 424/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0073 - acc: 0.9996 - val_loss: 0.9541 - val_acc: 0.8859\n",
      "Epoch 425/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0074 - acc: 0.9996 - val_loss: 0.9990 - val_acc: 0.8760\n",
      "Epoch 426/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1101 - acc: 0.9696 - val_loss: 0.9862 - val_acc: 0.8758\n",
      "Epoch 427/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0211 - acc: 0.9950 - val_loss: 0.9530 - val_acc: 0.8851\n",
      "Epoch 428/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0075 - acc: 0.9996 - val_loss: 0.9475 - val_acc: 0.8846\n",
      "Epoch 429/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0069 - acc: 0.9997 - val_loss: 0.9603 - val_acc: 0.8831\n",
      "Epoch 430/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0070 - acc: 0.9997 - val_loss: 0.9542 - val_acc: 0.8857\n",
      "Epoch 431/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0071 - acc: 0.9997 - val_loss: 0.9537 - val_acc: 0.8862\n",
      "Epoch 432/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0069 - acc: 0.9997 - val_loss: 0.9529 - val_acc: 0.8855\n",
      "Epoch 433/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0069 - acc: 0.9997 - val_loss: 0.9463 - val_acc: 0.8861\n",
      "Epoch 434/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0743 - acc: 0.9804 - val_loss: 1.0300 - val_acc: 0.8726\n",
      "Epoch 435/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0447 - acc: 0.9871 - val_loss: 0.9678 - val_acc: 0.8825\n",
      "Epoch 436/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0101 - acc: 0.9987 - val_loss: 0.9623 - val_acc: 0.8861\n",
      "Epoch 437/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0072 - acc: 0.9996 - val_loss: 0.9631 - val_acc: 0.8840\n",
      "Epoch 438/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0068 - acc: 0.9997 - val_loss: 0.9596 - val_acc: 0.8855\n",
      "Epoch 439/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0068 - acc: 0.9998 - val_loss: 0.9705 - val_acc: 0.8829\n",
      "Epoch 440/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0065 - acc: 0.9998 - val_loss: 0.9600 - val_acc: 0.8864\n",
      "Epoch 441/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0065 - acc: 0.9998 - val_loss: 0.9636 - val_acc: 0.8859\n",
      "Epoch 442/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.1036 - acc: 0.9722 - val_loss: 1.0163 - val_acc: 0.8737\n",
      "Epoch 443/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0392 - acc: 0.9885 - val_loss: 0.9997 - val_acc: 0.8769\n",
      "Epoch 444/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0094 - acc: 0.9992 - val_loss: 0.9781 - val_acc: 0.8838\n",
      "Epoch 445/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0068 - acc: 0.9998 - val_loss: 0.9780 - val_acc: 0.8832\n",
      "Epoch 446/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0079 - acc: 0.9993 - val_loss: 0.9654 - val_acc: 0.8853\n",
      "Epoch 447/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0064 - acc: 0.9997 - val_loss: 0.9670 - val_acc: 0.8859\n",
      "Epoch 448/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0064 - acc: 0.9997 - val_loss: 0.9671 - val_acc: 0.8844\n",
      "Epoch 449/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0064 - acc: 0.9997 - val_loss: 0.9651 - val_acc: 0.8850\n",
      "Epoch 450/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0073 - acc: 0.9995 - val_loss: 1.0028 - val_acc: 0.8831\n",
      "Epoch 451/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.1178 - acc: 0.9700 - val_loss: 0.9779 - val_acc: 0.8831\n",
      "Epoch 452/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0162 - acc: 0.9968 - val_loss: 0.9848 - val_acc: 0.8821\n",
      "Epoch 453/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0088 - acc: 0.9990 - val_loss: 0.9812 - val_acc: 0.8835\n",
      "Epoch 454/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0064 - acc: 0.9998 - val_loss: 0.9706 - val_acc: 0.8850\n",
      "Epoch 455/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0064 - acc: 0.9997 - val_loss: 0.9615 - val_acc: 0.8862\n",
      "Epoch 456/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0061 - acc: 0.9998 - val_loss: 0.9653 - val_acc: 0.8876\n",
      "Epoch 457/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0060 - acc: 0.9998 - val_loss: 0.9732 - val_acc: 0.8864\n",
      "Epoch 458/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0563 - acc: 0.9869 - val_loss: 1.1796 - val_acc: 0.8567\n",
      "Epoch 459/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0637 - acc: 0.9818 - val_loss: 0.9728 - val_acc: 0.8840\n",
      "Epoch 460/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0121 - acc: 0.9979 - val_loss: 0.9808 - val_acc: 0.8848\n",
      "Epoch 461/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0068 - acc: 0.9996 - val_loss: 0.9684 - val_acc: 0.8858\n",
      "Epoch 462/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0063 - acc: 0.9998 - val_loss: 0.9733 - val_acc: 0.8861\n",
      "Epoch 463/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0061 - acc: 0.9997 - val_loss: 0.9772 - val_acc: 0.8843\n",
      "Epoch 464/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0061 - acc: 0.9998 - val_loss: 0.9677 - val_acc: 0.8874\n",
      "Epoch 465/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0061 - acc: 0.9998 - val_loss: 0.9711 - val_acc: 0.8842\n",
      "Epoch 466/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0060 - acc: 0.9998 - val_loss: 0.9801 - val_acc: 0.8837\n",
      "Epoch 467/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0873 - acc: 0.9779 - val_loss: 1.0339 - val_acc: 0.8758\n",
      "Epoch 468/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0723 - acc: 0.9791 - val_loss: 1.0212 - val_acc: 0.8814\n",
      "Epoch 469/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0120 - acc: 0.9982 - val_loss: 0.9756 - val_acc: 0.8853\n",
      "Epoch 470/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0070 - acc: 0.9997 - val_loss: 0.9690 - val_acc: 0.8862\n",
      "Epoch 471/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0062 - acc: 0.9997 - val_loss: 0.9694 - val_acc: 0.8861\n",
      "Epoch 472/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0060 - acc: 0.9998 - val_loss: 0.9651 - val_acc: 0.8877\n",
      "Epoch 473/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0059 - acc: 0.9998 - val_loss: 0.9724 - val_acc: 0.8864\n",
      "Epoch 474/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0059 - acc: 0.9997 - val_loss: 0.9715 - val_acc: 0.8867\n",
      "Epoch 475/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0061 - acc: 0.9998 - val_loss: 0.9730 - val_acc: 0.8845\n",
      "Epoch 476/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0087 - acc: 0.9989 - val_loss: 1.0666 - val_acc: 0.8741\n",
      "Epoch 477/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.1280 - acc: 0.9660 - val_loss: 1.0165 - val_acc: 0.8741\n",
      "Epoch 478/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0181 - acc: 0.9957 - val_loss: 0.9748 - val_acc: 0.8855\n",
      "Epoch 479/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0077 - acc: 0.9994 - val_loss: 0.9895 - val_acc: 0.8854\n",
      "Epoch 480/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0066 - acc: 0.9997 - val_loss: 0.9828 - val_acc: 0.8850\n",
      "Epoch 481/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0063 - acc: 0.9998 - val_loss: 0.9727 - val_acc: 0.8867\n",
      "Epoch 482/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0061 - acc: 0.9998 - val_loss: 0.9711 - val_acc: 0.8873\n",
      "Epoch 483/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0059 - acc: 0.9998 - val_loss: 0.9824 - val_acc: 0.8861\n",
      "Epoch 484/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0061 - acc: 0.9997 - val_loss: 0.9750 - val_acc: 0.8854\n",
      "Epoch 485/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0063 - acc: 0.9998 - val_loss: 0.9845 - val_acc: 0.8846\n",
      "Epoch 486/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0965 - acc: 0.9733 - val_loss: 1.0644 - val_acc: 0.8692\n",
      "Epoch 487/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0489 - acc: 0.9852 - val_loss: 0.9830 - val_acc: 0.8818\n",
      "Epoch 488/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0116 - acc: 0.9979 - val_loss: 0.9724 - val_acc: 0.8837\n",
      "Epoch 489/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0070 - acc: 0.9997 - val_loss: 0.9718 - val_acc: 0.8874\n",
      "Epoch 490/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0073 - acc: 0.9996 - val_loss: 0.9756 - val_acc: 0.8857\n",
      "Epoch 491/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0072 - acc: 0.9996 - val_loss: 0.9684 - val_acc: 0.8871\n",
      "Epoch 492/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0061 - acc: 0.9998 - val_loss: 0.9767 - val_acc: 0.8869\n",
      "Epoch 493/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0059 - acc: 0.9998 - val_loss: 0.9690 - val_acc: 0.8873\n",
      "Epoch 494/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0058 - acc: 0.9998 - val_loss: 0.9709 - val_acc: 0.8867\n",
      "Epoch 495/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0343 - acc: 0.9919 - val_loss: 1.1802 - val_acc: 0.8540\n",
      "Epoch 496/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0823 - acc: 0.9761 - val_loss: 0.9799 - val_acc: 0.8850\n",
      "Epoch 497/500\n",
      "34108/34108 [==============================] - 1s 25us/step - loss: 0.0096 - acc: 0.9990 - val_loss: 0.9741 - val_acc: 0.8864\n",
      "Epoch 498/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0063 - acc: 0.9997 - val_loss: 0.9803 - val_acc: 0.8856\n",
      "Epoch 499/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0059 - acc: 0.9997 - val_loss: 0.9822 - val_acc: 0.8884\n",
      "Epoch 500/500\n",
      "34108/34108 [==============================] - 1s 24us/step - loss: 0.0058 - acc: 0.9998 - val_loss: 0.9764 - val_acc: 0.8878\n",
      "Train on 34108 samples, validate on 12117 samples\n",
      "Epoch 1/500\n",
      "34108/34108 [==============================] - 2s 45us/step - loss: 1.2011 - acc: 0.5369 - val_loss: 0.9062 - val_acc: 0.6911\n",
      "Epoch 2/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.8254 - acc: 0.7354 - val_loss: 0.7493 - val_acc: 0.7665\n",
      "Epoch 3/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.6964 - acc: 0.7863 - val_loss: 0.6993 - val_acc: 0.7829\n",
      "Epoch 4/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.6354 - acc: 0.8046 - val_loss: 0.6480 - val_acc: 0.7992\n",
      "Epoch 5/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.5920 - acc: 0.8178 - val_loss: 0.6410 - val_acc: 0.7976\n",
      "Epoch 6/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.5620 - acc: 0.8259 - val_loss: 0.5998 - val_acc: 0.8216\n",
      "Epoch 7/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.5296 - acc: 0.8373 - val_loss: 0.5808 - val_acc: 0.8302\n",
      "Epoch 8/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.5072 - acc: 0.8426 - val_loss: 0.5739 - val_acc: 0.8269\n",
      "Epoch 9/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.4851 - acc: 0.8499 - val_loss: 0.5667 - val_acc: 0.8346\n",
      "Epoch 10/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.4673 - acc: 0.8554 - val_loss: 0.5448 - val_acc: 0.8359\n",
      "Epoch 11/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.4497 - acc: 0.8625 - val_loss: 0.5345 - val_acc: 0.8389\n",
      "Epoch 12/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.4325 - acc: 0.8672 - val_loss: 0.5329 - val_acc: 0.8442\n",
      "Epoch 13/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.4258 - acc: 0.8686 - val_loss: 0.5459 - val_acc: 0.8358\n",
      "Epoch 14/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.4079 - acc: 0.8744 - val_loss: 0.5112 - val_acc: 0.8475\n",
      "Epoch 15/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.3947 - acc: 0.8791 - val_loss: 0.5266 - val_acc: 0.8472\n",
      "Epoch 16/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.3854 - acc: 0.8823 - val_loss: 0.4960 - val_acc: 0.8596\n",
      "Epoch 17/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.3756 - acc: 0.8847 - val_loss: 0.4763 - val_acc: 0.8651\n",
      "Epoch 18/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.3675 - acc: 0.8864 - val_loss: 0.5272 - val_acc: 0.8540\n",
      "Epoch 19/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.3586 - acc: 0.8914 - val_loss: 0.4890 - val_acc: 0.8586\n",
      "Epoch 20/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.3490 - acc: 0.8941 - val_loss: 0.4728 - val_acc: 0.8708\n",
      "Epoch 21/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.3440 - acc: 0.8949 - val_loss: 0.4827 - val_acc: 0.8647\n",
      "Epoch 22/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.3285 - acc: 0.9004 - val_loss: 0.4818 - val_acc: 0.8680\n",
      "Epoch 23/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.3231 - acc: 0.9030 - val_loss: 0.4854 - val_acc: 0.8643\n",
      "Epoch 24/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.3209 - acc: 0.9022 - val_loss: 0.4757 - val_acc: 0.8680\n",
      "Epoch 25/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.3130 - acc: 0.9047 - val_loss: 0.4884 - val_acc: 0.8654\n",
      "Epoch 26/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.3056 - acc: 0.9054 - val_loss: 0.4757 - val_acc: 0.8699\n",
      "Epoch 27/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.2982 - acc: 0.9090 - val_loss: 0.5017 - val_acc: 0.8643\n",
      "Epoch 28/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.2930 - acc: 0.9115 - val_loss: 0.4861 - val_acc: 0.8719\n",
      "Epoch 29/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.2845 - acc: 0.9135 - val_loss: 0.4657 - val_acc: 0.8763\n",
      "Epoch 30/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.2822 - acc: 0.9149 - val_loss: 0.4656 - val_acc: 0.8759\n",
      "Epoch 31/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.2714 - acc: 0.9187 - val_loss: 0.4998 - val_acc: 0.8727\n",
      "Epoch 32/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.2745 - acc: 0.9150 - val_loss: 0.4851 - val_acc: 0.8704\n",
      "Epoch 33/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.2618 - acc: 0.9208 - val_loss: 0.4812 - val_acc: 0.8743\n",
      "Epoch 34/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.2647 - acc: 0.9198 - val_loss: 0.4670 - val_acc: 0.8784\n",
      "Epoch 35/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.2554 - acc: 0.9237 - val_loss: 0.4798 - val_acc: 0.8789\n",
      "Epoch 36/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.2529 - acc: 0.9244 - val_loss: 0.4906 - val_acc: 0.8732\n",
      "Epoch 37/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.2466 - acc: 0.9255 - val_loss: 0.4897 - val_acc: 0.8769\n",
      "Epoch 38/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.2465 - acc: 0.9244 - val_loss: 0.4997 - val_acc: 0.8687\n",
      "Epoch 39/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.2365 - acc: 0.9286 - val_loss: 0.4875 - val_acc: 0.8774\n",
      "Epoch 40/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.2351 - acc: 0.9273 - val_loss: 0.5041 - val_acc: 0.8747\n",
      "Epoch 41/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.2285 - acc: 0.9308 - val_loss: 0.4728 - val_acc: 0.8801\n",
      "Epoch 42/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.2289 - acc: 0.9289 - val_loss: 0.4765 - val_acc: 0.8819\n",
      "Epoch 43/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.2253 - acc: 0.9322 - val_loss: 0.5284 - val_acc: 0.8666\n",
      "Epoch 44/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.2233 - acc: 0.9322 - val_loss: 0.4881 - val_acc: 0.8824\n",
      "Epoch 45/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.2185 - acc: 0.9334 - val_loss: 0.4999 - val_acc: 0.8764\n",
      "Epoch 46/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.2082 - acc: 0.9373 - val_loss: 0.4856 - val_acc: 0.8819\n",
      "Epoch 47/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.2096 - acc: 0.9361 - val_loss: 0.4822 - val_acc: 0.8851\n",
      "Epoch 48/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.2062 - acc: 0.9381 - val_loss: 0.4993 - val_acc: 0.8772\n",
      "Epoch 49/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1996 - acc: 0.9395 - val_loss: 0.4950 - val_acc: 0.8820\n",
      "Epoch 50/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.2002 - acc: 0.9389 - val_loss: 0.5569 - val_acc: 0.8662\n",
      "Epoch 51/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1973 - acc: 0.9405 - val_loss: 0.4837 - val_acc: 0.8837\n",
      "Epoch 52/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1890 - acc: 0.9432 - val_loss: 0.4965 - val_acc: 0.8813\n",
      "Epoch 53/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1894 - acc: 0.9423 - val_loss: 0.4939 - val_acc: 0.8861\n",
      "Epoch 54/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1849 - acc: 0.9438 - val_loss: 0.5127 - val_acc: 0.8784\n",
      "Epoch 55/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1814 - acc: 0.9448 - val_loss: 0.5223 - val_acc: 0.8793\n",
      "Epoch 56/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1827 - acc: 0.9438 - val_loss: 0.5252 - val_acc: 0.8758\n",
      "Epoch 57/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1758 - acc: 0.9468 - val_loss: 0.5023 - val_acc: 0.8807\n",
      "Epoch 58/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1721 - acc: 0.9479 - val_loss: 0.5241 - val_acc: 0.8793\n",
      "Epoch 59/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1694 - acc: 0.9488 - val_loss: 0.5128 - val_acc: 0.8845\n",
      "Epoch 60/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1680 - acc: 0.9489 - val_loss: 0.5156 - val_acc: 0.8808\n",
      "Epoch 61/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.1646 - acc: 0.9495 - val_loss: 0.5119 - val_acc: 0.8826\n",
      "Epoch 62/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1615 - acc: 0.9505 - val_loss: 0.5349 - val_acc: 0.8799\n",
      "Epoch 63/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1607 - acc: 0.9521 - val_loss: 0.5236 - val_acc: 0.8818\n",
      "Epoch 64/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1571 - acc: 0.9527 - val_loss: 0.5383 - val_acc: 0.8815\n",
      "Epoch 65/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1561 - acc: 0.9525 - val_loss: 0.5365 - val_acc: 0.8804\n",
      "Epoch 66/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.1571 - acc: 0.9528 - val_loss: 0.5242 - val_acc: 0.8833\n",
      "Epoch 67/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1484 - acc: 0.9558 - val_loss: 0.5201 - val_acc: 0.8831\n",
      "Epoch 68/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.1539 - acc: 0.9529 - val_loss: 0.5423 - val_acc: 0.8796\n",
      "Epoch 69/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1437 - acc: 0.9573 - val_loss: 0.5283 - val_acc: 0.8842\n",
      "Epoch 70/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.1461 - acc: 0.9564 - val_loss: 0.5318 - val_acc: 0.8832\n",
      "Epoch 71/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.1452 - acc: 0.9559 - val_loss: 0.5380 - val_acc: 0.8798\n",
      "Epoch 72/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.1387 - acc: 0.9590 - val_loss: 0.5527 - val_acc: 0.8819\n",
      "Epoch 73/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1342 - acc: 0.9612 - val_loss: 0.5576 - val_acc: 0.8795\n",
      "Epoch 74/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1392 - acc: 0.9584 - val_loss: 0.5730 - val_acc: 0.8787\n",
      "Epoch 75/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1379 - acc: 0.9588 - val_loss: 0.5382 - val_acc: 0.8822\n",
      "Epoch 76/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.1294 - acc: 0.9615 - val_loss: 0.5571 - val_acc: 0.8793\n",
      "Epoch 77/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1337 - acc: 0.9609 - val_loss: 0.5733 - val_acc: 0.8783\n",
      "Epoch 78/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1303 - acc: 0.9606 - val_loss: 0.5570 - val_acc: 0.8812\n",
      "Epoch 79/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1248 - acc: 0.9627 - val_loss: 0.5806 - val_acc: 0.8796\n",
      "Epoch 80/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1270 - acc: 0.9621 - val_loss: 0.5536 - val_acc: 0.8816\n",
      "Epoch 81/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.1298 - acc: 0.9603 - val_loss: 0.5695 - val_acc: 0.8774\n",
      "Epoch 82/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1245 - acc: 0.9629 - val_loss: 0.5429 - val_acc: 0.8846\n",
      "Epoch 83/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1181 - acc: 0.9641 - val_loss: 0.5720 - val_acc: 0.8794\n",
      "Epoch 84/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1167 - acc: 0.9661 - val_loss: 0.5828 - val_acc: 0.8796\n",
      "Epoch 85/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1236 - acc: 0.9622 - val_loss: 0.6148 - val_acc: 0.8737\n",
      "Epoch 86/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.1102 - acc: 0.9680 - val_loss: 0.5787 - val_acc: 0.8836\n",
      "Epoch 87/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.1154 - acc: 0.9659 - val_loss: 0.5837 - val_acc: 0.8807\n",
      "Epoch 88/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1169 - acc: 0.9645 - val_loss: 0.5695 - val_acc: 0.8866\n",
      "Epoch 89/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1125 - acc: 0.9663 - val_loss: 0.5693 - val_acc: 0.8844\n",
      "Epoch 90/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1080 - acc: 0.9682 - val_loss: 0.5776 - val_acc: 0.8868\n",
      "Epoch 91/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1082 - acc: 0.9682 - val_loss: 0.5836 - val_acc: 0.8832\n",
      "Epoch 92/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1054 - acc: 0.9687 - val_loss: 0.6054 - val_acc: 0.8781\n",
      "Epoch 93/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1044 - acc: 0.9690 - val_loss: 0.5836 - val_acc: 0.8830\n",
      "Epoch 94/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1140 - acc: 0.9652 - val_loss: 0.5889 - val_acc: 0.8826\n",
      "Epoch 95/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0981 - acc: 0.9720 - val_loss: 0.6513 - val_acc: 0.8742\n",
      "Epoch 96/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1006 - acc: 0.9697 - val_loss: 0.5917 - val_acc: 0.8850\n",
      "Epoch 97/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1004 - acc: 0.9707 - val_loss: 0.6428 - val_acc: 0.8726\n",
      "Epoch 98/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0982 - acc: 0.9707 - val_loss: 0.6433 - val_acc: 0.8742\n",
      "Epoch 99/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0949 - acc: 0.9727 - val_loss: 0.6048 - val_acc: 0.8869\n",
      "Epoch 100/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.1048 - acc: 0.9694 - val_loss: 0.6294 - val_acc: 0.8757\n",
      "Epoch 101/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0949 - acc: 0.9732 - val_loss: 0.6652 - val_acc: 0.8718\n",
      "Epoch 102/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0914 - acc: 0.9738 - val_loss: 0.6246 - val_acc: 0.8813\n",
      "Epoch 103/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0939 - acc: 0.9729 - val_loss: 0.6136 - val_acc: 0.8828\n",
      "Epoch 104/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0924 - acc: 0.9733 - val_loss: 0.6437 - val_acc: 0.8772\n",
      "Epoch 105/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0917 - acc: 0.9730 - val_loss: 0.6609 - val_acc: 0.8719\n",
      "Epoch 106/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0884 - acc: 0.9743 - val_loss: 0.6575 - val_acc: 0.8781\n",
      "Epoch 107/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0868 - acc: 0.9748 - val_loss: 0.6233 - val_acc: 0.8821\n",
      "Epoch 108/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0878 - acc: 0.9737 - val_loss: 0.6418 - val_acc: 0.8805\n",
      "Epoch 109/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0972 - acc: 0.9707 - val_loss: 0.6313 - val_acc: 0.8829\n",
      "Epoch 110/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0800 - acc: 0.9779 - val_loss: 0.6198 - val_acc: 0.8847\n",
      "Epoch 111/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0836 - acc: 0.9758 - val_loss: 0.6539 - val_acc: 0.8815\n",
      "Epoch 112/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0935 - acc: 0.9715 - val_loss: 0.6360 - val_acc: 0.8852\n",
      "Epoch 113/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0795 - acc: 0.9772 - val_loss: 0.6291 - val_acc: 0.8822\n",
      "Epoch 114/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0792 - acc: 0.9775 - val_loss: 0.6567 - val_acc: 0.8779\n",
      "Epoch 115/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0842 - acc: 0.9754 - val_loss: 0.6608 - val_acc: 0.8776\n",
      "Epoch 116/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0899 - acc: 0.9735 - val_loss: 0.6282 - val_acc: 0.8836\n",
      "Epoch 117/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0801 - acc: 0.9769 - val_loss: 0.6454 - val_acc: 0.8836\n",
      "Epoch 118/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0747 - acc: 0.9787 - val_loss: 0.6382 - val_acc: 0.8818\n",
      "Epoch 119/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0740 - acc: 0.9804 - val_loss: 0.6530 - val_acc: 0.8817\n",
      "Epoch 120/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0720 - acc: 0.9801 - val_loss: 0.6681 - val_acc: 0.8786\n",
      "Epoch 121/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0724 - acc: 0.9799 - val_loss: 0.6911 - val_acc: 0.8803\n",
      "Epoch 122/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0885 - acc: 0.9733 - val_loss: 0.6632 - val_acc: 0.8793\n",
      "Epoch 123/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0732 - acc: 0.9792 - val_loss: 0.6746 - val_acc: 0.8798\n",
      "Epoch 124/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0739 - acc: 0.9787 - val_loss: 0.6920 - val_acc: 0.8760\n",
      "Epoch 125/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0753 - acc: 0.9790 - val_loss: 0.6696 - val_acc: 0.8820\n",
      "Epoch 126/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0720 - acc: 0.9793 - val_loss: 0.6799 - val_acc: 0.8817\n",
      "Epoch 127/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0669 - acc: 0.9819 - val_loss: 0.6715 - val_acc: 0.8817\n",
      "Epoch 128/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0734 - acc: 0.9789 - val_loss: 0.6906 - val_acc: 0.8836\n",
      "Epoch 129/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0650 - acc: 0.9821 - val_loss: 0.6611 - val_acc: 0.8839\n",
      "Epoch 130/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0658 - acc: 0.9818 - val_loss: 0.7044 - val_acc: 0.8776\n",
      "Epoch 131/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0636 - acc: 0.9826 - val_loss: 0.6907 - val_acc: 0.8823\n",
      "Epoch 132/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0597 - acc: 0.9847 - val_loss: 0.6918 - val_acc: 0.8801\n",
      "Epoch 133/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0682 - acc: 0.9813 - val_loss: 0.6945 - val_acc: 0.8820\n",
      "Epoch 134/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0776 - acc: 0.9760 - val_loss: 0.7046 - val_acc: 0.8788\n",
      "Epoch 135/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0563 - acc: 0.9852 - val_loss: 0.6680 - val_acc: 0.8863\n",
      "Epoch 136/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0758 - acc: 0.9772 - val_loss: 0.6945 - val_acc: 0.8819\n",
      "Epoch 137/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0598 - acc: 0.9843 - val_loss: 0.7092 - val_acc: 0.8790\n",
      "Epoch 138/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0617 - acc: 0.9826 - val_loss: 0.7274 - val_acc: 0.8719\n",
      "Epoch 139/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0631 - acc: 0.9818 - val_loss: 0.7021 - val_acc: 0.8846\n",
      "Epoch 140/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0683 - acc: 0.9809 - val_loss: 0.6851 - val_acc: 0.8857\n",
      "Epoch 141/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0618 - acc: 0.9829 - val_loss: 0.7107 - val_acc: 0.8816\n",
      "Epoch 142/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0535 - acc: 0.9864 - val_loss: 0.7140 - val_acc: 0.8825\n",
      "Epoch 143/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0554 - acc: 0.9855 - val_loss: 0.7190 - val_acc: 0.8807\n",
      "Epoch 144/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0731 - acc: 0.9790 - val_loss: 0.7015 - val_acc: 0.8812\n",
      "Epoch 145/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0707 - acc: 0.9791 - val_loss: 0.7337 - val_acc: 0.8784\n",
      "Epoch 146/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0474 - acc: 0.9884 - val_loss: 0.7005 - val_acc: 0.8846\n",
      "Epoch 147/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0485 - acc: 0.9877 - val_loss: 0.7069 - val_acc: 0.8836\n",
      "Epoch 148/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0609 - acc: 0.9819 - val_loss: 0.7187 - val_acc: 0.8821\n",
      "Epoch 149/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0570 - acc: 0.9845 - val_loss: 0.7181 - val_acc: 0.8835\n",
      "Epoch 150/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0578 - acc: 0.9836 - val_loss: 0.7788 - val_acc: 0.8683\n",
      "Epoch 151/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0631 - acc: 0.9813 - val_loss: 0.7224 - val_acc: 0.8810\n",
      "Epoch 152/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0540 - acc: 0.9850 - val_loss: 0.7191 - val_acc: 0.8817\n",
      "Epoch 153/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0579 - acc: 0.9833 - val_loss: 0.7292 - val_acc: 0.8813\n",
      "Epoch 154/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0548 - acc: 0.9841 - val_loss: 0.7326 - val_acc: 0.8807\n",
      "Epoch 155/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0499 - acc: 0.9872 - val_loss: 0.7692 - val_acc: 0.8793\n",
      "Epoch 156/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0622 - acc: 0.9823 - val_loss: 0.7380 - val_acc: 0.8807\n",
      "Epoch 157/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0614 - acc: 0.9824 - val_loss: 0.7363 - val_acc: 0.8830\n",
      "Epoch 158/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0420 - acc: 0.9899 - val_loss: 0.7486 - val_acc: 0.8805\n",
      "Epoch 159/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0437 - acc: 0.9895 - val_loss: 0.7369 - val_acc: 0.8833\n",
      "Epoch 160/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0449 - acc: 0.9890 - val_loss: 0.7532 - val_acc: 0.8788\n",
      "Epoch 161/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0631 - acc: 0.9812 - val_loss: 0.7464 - val_acc: 0.8806\n",
      "Epoch 162/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0638 - acc: 0.9809 - val_loss: 0.7417 - val_acc: 0.8795\n",
      "Epoch 163/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0382 - acc: 0.9918 - val_loss: 0.7307 - val_acc: 0.8856\n",
      "Epoch 164/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0475 - acc: 0.9873 - val_loss: 0.7705 - val_acc: 0.8765\n",
      "Epoch 165/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0502 - acc: 0.9867 - val_loss: 0.7590 - val_acc: 0.8775\n",
      "Epoch 166/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0385 - acc: 0.9911 - val_loss: 0.7495 - val_acc: 0.8837\n",
      "Epoch 167/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0555 - acc: 0.9837 - val_loss: 0.7776 - val_acc: 0.8741\n",
      "Epoch 168/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0538 - acc: 0.9848 - val_loss: 0.7833 - val_acc: 0.8756\n",
      "Epoch 169/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0405 - acc: 0.9901 - val_loss: 0.7449 - val_acc: 0.8845\n",
      "Epoch 170/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0381 - acc: 0.9912 - val_loss: 0.7722 - val_acc: 0.8784\n",
      "Epoch 171/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0457 - acc: 0.9876 - val_loss: 0.7420 - val_acc: 0.8874\n",
      "Epoch 172/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0469 - acc: 0.9873 - val_loss: 0.7575 - val_acc: 0.8827\n",
      "Epoch 173/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0433 - acc: 0.9896 - val_loss: 0.7552 - val_acc: 0.8840\n",
      "Epoch 174/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0661 - acc: 0.9799 - val_loss: 0.7529 - val_acc: 0.8832\n",
      "Epoch 175/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0384 - acc: 0.9911 - val_loss: 0.7693 - val_acc: 0.8835\n",
      "Epoch 176/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0369 - acc: 0.9915 - val_loss: 0.8142 - val_acc: 0.8727\n",
      "Epoch 177/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0623 - acc: 0.9814 - val_loss: 0.7594 - val_acc: 0.8836\n",
      "Epoch 178/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0355 - acc: 0.9923 - val_loss: 0.7570 - val_acc: 0.8848\n",
      "Epoch 179/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0355 - acc: 0.9923 - val_loss: 0.7661 - val_acc: 0.8850\n",
      "Epoch 180/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0477 - acc: 0.9869 - val_loss: 0.7687 - val_acc: 0.8837\n",
      "Epoch 181/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0460 - acc: 0.9878 - val_loss: 0.8022 - val_acc: 0.8744\n",
      "Epoch 182/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0502 - acc: 0.9855 - val_loss: 0.7699 - val_acc: 0.8846\n",
      "Epoch 183/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0280 - acc: 0.9950 - val_loss: 0.7881 - val_acc: 0.8852\n",
      "Epoch 184/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0410 - acc: 0.9894 - val_loss: 0.8061 - val_acc: 0.8778\n",
      "Epoch 185/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0591 - acc: 0.9823 - val_loss: 0.8094 - val_acc: 0.8798\n",
      "Epoch 186/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0445 - acc: 0.9876 - val_loss: 0.7823 - val_acc: 0.8809\n",
      "Epoch 187/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0295 - acc: 0.9941 - val_loss: 0.8108 - val_acc: 0.8803\n",
      "Epoch 188/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0332 - acc: 0.9925 - val_loss: 0.7913 - val_acc: 0.8823\n",
      "Epoch 189/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0655 - acc: 0.9807 - val_loss: 0.8307 - val_acc: 0.8719\n",
      "Epoch 190/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0634 - acc: 0.9813 - val_loss: 0.7801 - val_acc: 0.8825\n",
      "Epoch 191/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0275 - acc: 0.9945 - val_loss: 0.7874 - val_acc: 0.8845\n",
      "Epoch 192/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0241 - acc: 0.9960 - val_loss: 0.8180 - val_acc: 0.8788\n",
      "Epoch 193/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0340 - acc: 0.9918 - val_loss: 0.7998 - val_acc: 0.8803\n",
      "Epoch 194/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0890 - acc: 0.9721 - val_loss: 0.8811 - val_acc: 0.8663\n",
      "Epoch 195/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0409 - acc: 0.9893 - val_loss: 0.7875 - val_acc: 0.8836\n",
      "Epoch 196/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0234 - acc: 0.9965 - val_loss: 0.8002 - val_acc: 0.8838\n",
      "Epoch 197/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0418 - acc: 0.9890 - val_loss: 0.8663 - val_acc: 0.8693\n",
      "Epoch 198/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0390 - acc: 0.9897 - val_loss: 0.7948 - val_acc: 0.8837\n",
      "Epoch 199/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0280 - acc: 0.9944 - val_loss: 0.8252 - val_acc: 0.8797\n",
      "Epoch 200/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0271 - acc: 0.9942 - val_loss: 0.7912 - val_acc: 0.8850\n",
      "Epoch 201/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0496 - acc: 0.9856 - val_loss: 0.8215 - val_acc: 0.8775\n",
      "Epoch 202/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0369 - acc: 0.9908 - val_loss: 0.8108 - val_acc: 0.8811\n",
      "Epoch 203/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0285 - acc: 0.9943 - val_loss: 0.8047 - val_acc: 0.8847\n",
      "Epoch 204/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0489 - acc: 0.9854 - val_loss: 0.8268 - val_acc: 0.8787\n",
      "Epoch 205/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0420 - acc: 0.9884 - val_loss: 0.7970 - val_acc: 0.8854\n",
      "Epoch 206/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0222 - acc: 0.9963 - val_loss: 0.8046 - val_acc: 0.8840\n",
      "Epoch 207/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0320 - acc: 0.9920 - val_loss: 0.8465 - val_acc: 0.8760\n",
      "Epoch 208/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0565 - acc: 0.9833 - val_loss: 0.8553 - val_acc: 0.8749\n",
      "Epoch 209/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0558 - acc: 0.9834 - val_loss: 0.8209 - val_acc: 0.8809\n",
      "Epoch 210/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0296 - acc: 0.9934 - val_loss: 0.8034 - val_acc: 0.8852\n",
      "Epoch 211/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0201 - acc: 0.9969 - val_loss: 0.8054 - val_acc: 0.8855\n",
      "Epoch 212/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0201 - acc: 0.9966 - val_loss: 0.8142 - val_acc: 0.8836\n",
      "Epoch 213/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0267 - acc: 0.9944 - val_loss: 0.8135 - val_acc: 0.8836\n",
      "Epoch 214/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0651 - acc: 0.9812 - val_loss: 0.8710 - val_acc: 0.8718\n",
      "Epoch 215/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0480 - acc: 0.9863 - val_loss: 0.8038 - val_acc: 0.8841\n",
      "Epoch 216/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0230 - acc: 0.9959 - val_loss: 0.8300 - val_acc: 0.8830\n",
      "Epoch 217/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0201 - acc: 0.9970 - val_loss: 0.8328 - val_acc: 0.8836\n",
      "Epoch 218/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0421 - acc: 0.9882 - val_loss: 0.8315 - val_acc: 0.8815\n",
      "Epoch 219/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0264 - acc: 0.9942 - val_loss: 0.8202 - val_acc: 0.8869\n",
      "Epoch 220/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0317 - acc: 0.9919 - val_loss: 0.9013 - val_acc: 0.8677\n",
      "Epoch 221/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0780 - acc: 0.9763 - val_loss: 0.8177 - val_acc: 0.8859\n",
      "Epoch 222/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0212 - acc: 0.9961 - val_loss: 0.8367 - val_acc: 0.8840\n",
      "Epoch 223/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0174 - acc: 0.9975 - val_loss: 0.8148 - val_acc: 0.8874\n",
      "Epoch 224/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0165 - acc: 0.9981 - val_loss: 0.8582 - val_acc: 0.8819\n",
      "Epoch 225/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0388 - acc: 0.9897 - val_loss: 0.9201 - val_acc: 0.8646\n",
      "Epoch 226/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0912 - acc: 0.9718 - val_loss: 0.8472 - val_acc: 0.8781\n",
      "Epoch 227/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0241 - acc: 0.9950 - val_loss: 0.8365 - val_acc: 0.8835\n",
      "Epoch 228/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0161 - acc: 0.9981 - val_loss: 0.8371 - val_acc: 0.8854\n",
      "Epoch 229/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0195 - acc: 0.9970 - val_loss: 0.8594 - val_acc: 0.8826\n",
      "Epoch 230/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0266 - acc: 0.9943 - val_loss: 0.8593 - val_acc: 0.8787\n",
      "Epoch 231/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0708 - acc: 0.9783 - val_loss: 0.8529 - val_acc: 0.8803\n",
      "Epoch 232/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0219 - acc: 0.9960 - val_loss: 0.8319 - val_acc: 0.8860\n",
      "Epoch 233/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0150 - acc: 0.9985 - val_loss: 0.8325 - val_acc: 0.8845\n",
      "Epoch 234/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0142 - acc: 0.9988 - val_loss: 0.8284 - val_acc: 0.8870\n",
      "Epoch 235/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0281 - acc: 0.9934 - val_loss: 0.8736 - val_acc: 0.8788\n",
      "Epoch 236/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0944 - acc: 0.9703 - val_loss: 0.8317 - val_acc: 0.8812\n",
      "Epoch 237/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0215 - acc: 0.9964 - val_loss: 0.8505 - val_acc: 0.8834\n",
      "Epoch 238/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0167 - acc: 0.9977 - val_loss: 0.8335 - val_acc: 0.8859\n",
      "Epoch 239/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0134 - acc: 0.9989 - val_loss: 0.8399 - val_acc: 0.8858\n",
      "Epoch 240/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0346 - acc: 0.9908 - val_loss: 0.8723 - val_acc: 0.8715\n",
      "Epoch 241/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0485 - acc: 0.9854 - val_loss: 0.8547 - val_acc: 0.8803\n",
      "Epoch 242/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0285 - acc: 0.9929 - val_loss: 0.8453 - val_acc: 0.8823\n",
      "Epoch 243/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0254 - acc: 0.9943 - val_loss: 0.8574 - val_acc: 0.8838\n",
      "Epoch 244/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0137 - acc: 0.9986 - val_loss: 0.8477 - val_acc: 0.8846\n",
      "Epoch 245/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0154 - acc: 0.9980 - val_loss: 0.8457 - val_acc: 0.8847\n",
      "Epoch 246/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.1081 - acc: 0.9663 - val_loss: 0.8872 - val_acc: 0.8741\n",
      "Epoch 247/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0273 - acc: 0.9937 - val_loss: 0.8426 - val_acc: 0.8862\n",
      "Epoch 248/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0140 - acc: 0.9987 - val_loss: 0.8594 - val_acc: 0.8845\n",
      "Epoch 249/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0148 - acc: 0.9980 - val_loss: 0.8717 - val_acc: 0.8823\n",
      "Epoch 250/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0165 - acc: 0.9979 - val_loss: 0.8700 - val_acc: 0.8833\n",
      "Epoch 251/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0401 - acc: 0.9885 - val_loss: 0.9195 - val_acc: 0.8703\n",
      "Epoch 252/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0549 - acc: 0.9837 - val_loss: 0.8781 - val_acc: 0.8801\n",
      "Epoch 253/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0242 - acc: 0.9950 - val_loss: 0.8925 - val_acc: 0.8763\n",
      "Epoch 254/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0138 - acc: 0.9986 - val_loss: 0.8575 - val_acc: 0.8858\n",
      "Epoch 255/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0121 - acc: 0.9991 - val_loss: 0.8602 - val_acc: 0.8859\n",
      "Epoch 256/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0133 - acc: 0.9985 - val_loss: 0.9020 - val_acc: 0.8798\n",
      "Epoch 257/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1127 - acc: 0.9671 - val_loss: 0.9259 - val_acc: 0.8694\n",
      "Epoch 258/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0306 - acc: 0.9926 - val_loss: 0.8492 - val_acc: 0.8850\n",
      "Epoch 259/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0132 - acc: 0.9989 - val_loss: 0.8700 - val_acc: 0.8833\n",
      "Epoch 260/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0120 - acc: 0.9991 - val_loss: 0.8560 - val_acc: 0.8860\n",
      "Epoch 261/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0134 - acc: 0.9987 - val_loss: 0.8699 - val_acc: 0.8836\n",
      "Epoch 262/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0127 - acc: 0.9989 - val_loss: 0.8651 - val_acc: 0.8859\n",
      "Epoch 263/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0124 - acc: 0.9991 - val_loss: 0.8627 - val_acc: 0.8872\n",
      "Epoch 264/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0654 - acc: 0.9825 - val_loss: 0.9907 - val_acc: 0.8580\n",
      "Epoch 265/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0693 - acc: 0.9794 - val_loss: 0.9106 - val_acc: 0.8745\n",
      "Epoch 266/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0172 - acc: 0.9973 - val_loss: 0.8744 - val_acc: 0.8838\n",
      "Epoch 267/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0122 - acc: 0.9990 - val_loss: 0.9040 - val_acc: 0.8809\n",
      "Epoch 268/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0160 - acc: 0.9975 - val_loss: 0.8883 - val_acc: 0.8822\n",
      "Epoch 269/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0706 - acc: 0.9781 - val_loss: 0.8815 - val_acc: 0.8795\n",
      "Epoch 270/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0262 - acc: 0.9938 - val_loss: 0.8797 - val_acc: 0.8817\n",
      "Epoch 271/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0132 - acc: 0.9986 - val_loss: 0.8758 - val_acc: 0.8851\n",
      "Epoch 272/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0114 - acc: 0.9989 - val_loss: 0.8807 - val_acc: 0.8845\n",
      "Epoch 273/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0122 - acc: 0.9987 - val_loss: 0.8998 - val_acc: 0.8831\n",
      "Epoch 274/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0384 - acc: 0.9892 - val_loss: 0.9265 - val_acc: 0.8720\n",
      "Epoch 275/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0924 - acc: 0.9713 - val_loss: 0.9045 - val_acc: 0.8784\n",
      "Epoch 276/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0204 - acc: 0.9954 - val_loss: 0.8712 - val_acc: 0.8855\n",
      "Epoch 277/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0118 - acc: 0.9988 - val_loss: 0.8725 - val_acc: 0.8847\n",
      "Epoch 278/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0109 - acc: 0.9991 - val_loss: 0.8772 - val_acc: 0.8869\n",
      "Epoch 279/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0109 - acc: 0.9991 - val_loss: 0.8876 - val_acc: 0.8839\n",
      "Epoch 280/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0167 - acc: 0.9973 - val_loss: 0.9421 - val_acc: 0.8756\n",
      "Epoch 281/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0847 - acc: 0.9736 - val_loss: 0.9228 - val_acc: 0.8754\n",
      "Epoch 282/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0347 - acc: 0.9905 - val_loss: 0.9033 - val_acc: 0.8803\n",
      "Epoch 283/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0146 - acc: 0.9978 - val_loss: 0.9030 - val_acc: 0.8817\n",
      "Epoch 284/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0108 - acc: 0.9991 - val_loss: 0.8888 - val_acc: 0.8860\n",
      "Epoch 285/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0095 - acc: 0.9994 - val_loss: 0.8904 - val_acc: 0.8869\n",
      "Epoch 286/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0097 - acc: 0.9992 - val_loss: 0.9049 - val_acc: 0.8831\n",
      "Epoch 287/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0105 - acc: 0.9992 - val_loss: 0.9120 - val_acc: 0.8820\n",
      "Epoch 288/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0648 - acc: 0.9831 - val_loss: 0.9883 - val_acc: 0.8662\n",
      "Epoch 289/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0702 - acc: 0.9799 - val_loss: 0.9489 - val_acc: 0.8722\n",
      "Epoch 290/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0249 - acc: 0.9935 - val_loss: 0.8904 - val_acc: 0.8835\n",
      "Epoch 291/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0123 - acc: 0.9989 - val_loss: 0.8903 - val_acc: 0.8852\n",
      "Epoch 292/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0097 - acc: 0.9994 - val_loss: 0.8997 - val_acc: 0.8852\n",
      "Epoch 293/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0094 - acc: 0.9995 - val_loss: 0.9002 - val_acc: 0.8863\n",
      "Epoch 294/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0123 - acc: 0.9984 - val_loss: 0.9161 - val_acc: 0.8815\n",
      "Epoch 295/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0670 - acc: 0.9817 - val_loss: 0.9494 - val_acc: 0.8730\n",
      "Epoch 296/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0442 - acc: 0.9862 - val_loss: 0.9139 - val_acc: 0.8805\n",
      "Epoch 297/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0149 - acc: 0.9982 - val_loss: 0.8959 - val_acc: 0.8847\n",
      "Epoch 298/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0108 - acc: 0.9991 - val_loss: 0.9032 - val_acc: 0.8855\n",
      "Epoch 299/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0090 - acc: 0.9995 - val_loss: 0.9045 - val_acc: 0.8858\n",
      "Epoch 300/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0174 - acc: 0.9965 - val_loss: 1.0139 - val_acc: 0.8690\n",
      "Epoch 301/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0934 - acc: 0.9733 - val_loss: 0.8912 - val_acc: 0.8821\n",
      "Epoch 302/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0154 - acc: 0.9974 - val_loss: 0.8904 - val_acc: 0.8871\n",
      "Epoch 303/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0093 - acc: 0.9996 - val_loss: 0.9014 - val_acc: 0.8864\n",
      "Epoch 304/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0088 - acc: 0.9995 - val_loss: 0.9152 - val_acc: 0.8845\n",
      "Epoch 305/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0085 - acc: 0.9996 - val_loss: 0.9074 - val_acc: 0.8857\n",
      "Epoch 306/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0083 - acc: 0.9996 - val_loss: 0.9028 - val_acc: 0.8874\n",
      "Epoch 307/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0092 - acc: 0.9994 - val_loss: 0.9254 - val_acc: 0.8844\n",
      "Epoch 308/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1368 - acc: 0.9620 - val_loss: 0.9142 - val_acc: 0.8797\n",
      "Epoch 309/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0245 - acc: 0.9940 - val_loss: 0.9283 - val_acc: 0.8820\n",
      "Epoch 310/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0134 - acc: 0.9983 - val_loss: 0.9079 - val_acc: 0.8853\n",
      "Epoch 311/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0092 - acc: 0.9994 - val_loss: 0.9166 - val_acc: 0.8836\n",
      "Epoch 312/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0086 - acc: 0.9996 - val_loss: 0.9172 - val_acc: 0.8842\n",
      "Epoch 313/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0086 - acc: 0.9996 - val_loss: 0.9146 - val_acc: 0.8860\n",
      "Epoch 314/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0084 - acc: 0.9996 - val_loss: 0.9121 - val_acc: 0.8856\n",
      "Epoch 315/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0094 - acc: 0.9994 - val_loss: 0.9181 - val_acc: 0.8853\n",
      "Epoch 316/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1219 - acc: 0.9685 - val_loss: 0.9506 - val_acc: 0.8734\n",
      "Epoch 317/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0312 - acc: 0.9922 - val_loss: 0.9107 - val_acc: 0.8844\n",
      "Epoch 318/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0156 - acc: 0.9973 - val_loss: 0.8942 - val_acc: 0.8877\n",
      "Epoch 319/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0093 - acc: 0.9995 - val_loss: 0.9100 - val_acc: 0.8867\n",
      "Epoch 320/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0086 - acc: 0.9995 - val_loss: 0.9086 - val_acc: 0.8873\n",
      "Epoch 321/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0085 - acc: 0.9995 - val_loss: 0.9066 - val_acc: 0.8870\n",
      "Epoch 322/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0081 - acc: 0.9996 - val_loss: 0.9083 - val_acc: 0.8882\n",
      "Epoch 323/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0977 - acc: 0.9738 - val_loss: 0.9581 - val_acc: 0.8742\n",
      "Epoch 324/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0370 - acc: 0.9900 - val_loss: 0.9299 - val_acc: 0.8792\n",
      "Epoch 325/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0123 - acc: 0.9987 - val_loss: 0.9152 - val_acc: 0.8847\n",
      "Epoch 326/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0090 - acc: 0.9995 - val_loss: 0.9106 - val_acc: 0.8870\n",
      "Epoch 327/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0095 - acc: 0.9993 - val_loss: 0.9235 - val_acc: 0.8835\n",
      "Epoch 328/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0088 - acc: 0.9995 - val_loss: 0.9098 - val_acc: 0.8869\n",
      "Epoch 329/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0147 - acc: 0.9977 - val_loss: 1.0737 - val_acc: 0.8637\n",
      "Epoch 330/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0856 - acc: 0.9755 - val_loss: 0.9138 - val_acc: 0.8826\n",
      "Epoch 331/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0306 - acc: 0.9913 - val_loss: 0.9415 - val_acc: 0.8792\n",
      "Epoch 332/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0103 - acc: 0.9991 - val_loss: 0.9102 - val_acc: 0.8861\n",
      "Epoch 333/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0080 - acc: 0.9997 - val_loss: 0.9186 - val_acc: 0.8848\n",
      "Epoch 334/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0076 - acc: 0.9996 - val_loss: 0.9367 - val_acc: 0.8838\n",
      "Epoch 335/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0079 - acc: 0.9997 - val_loss: 0.9399 - val_acc: 0.8813\n",
      "Epoch 336/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0074 - acc: 0.9997 - val_loss: 0.9205 - val_acc: 0.8871\n",
      "Epoch 337/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0080 - acc: 0.9996 - val_loss: 0.9334 - val_acc: 0.8828\n",
      "Epoch 338/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0532 - acc: 0.9864 - val_loss: 1.0351 - val_acc: 0.8649\n",
      "Epoch 339/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1042 - acc: 0.9707 - val_loss: 0.9493 - val_acc: 0.8806\n",
      "Epoch 340/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0228 - acc: 0.9946 - val_loss: 0.9152 - val_acc: 0.8845\n",
      "Epoch 341/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0091 - acc: 0.9995 - val_loss: 0.9199 - val_acc: 0.8861\n",
      "Epoch 342/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0082 - acc: 0.9995 - val_loss: 0.9387 - val_acc: 0.8840\n",
      "Epoch 343/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0080 - acc: 0.9996 - val_loss: 0.9260 - val_acc: 0.8863\n",
      "Epoch 344/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0077 - acc: 0.9997 - val_loss: 0.9228 - val_acc: 0.8871\n",
      "Epoch 345/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0077 - acc: 0.9997 - val_loss: 0.9227 - val_acc: 0.8868\n",
      "Epoch 346/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0074 - acc: 0.9996 - val_loss: 0.9389 - val_acc: 0.8859\n",
      "Epoch 347/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0871 - acc: 0.9775 - val_loss: 1.0797 - val_acc: 0.8646\n",
      "Epoch 348/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0659 - acc: 0.9802 - val_loss: 0.9597 - val_acc: 0.8769\n",
      "Epoch 349/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0145 - acc: 0.9977 - val_loss: 0.9234 - val_acc: 0.8845\n",
      "Epoch 350/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0089 - acc: 0.9996 - val_loss: 0.9268 - val_acc: 0.8859\n",
      "Epoch 351/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0076 - acc: 0.9997 - val_loss: 0.9244 - val_acc: 0.8867\n",
      "Epoch 352/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0072 - acc: 0.9997 - val_loss: 0.9332 - val_acc: 0.8860\n",
      "Epoch 353/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0070 - acc: 0.9997 - val_loss: 0.9327 - val_acc: 0.8858\n",
      "Epoch 354/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0070 - acc: 0.9997 - val_loss: 0.9276 - val_acc: 0.8852\n",
      "Epoch 355/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0070 - acc: 0.9998 - val_loss: 0.9345 - val_acc: 0.8861\n",
      "Epoch 356/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0069 - acc: 0.9997 - val_loss: 0.9319 - val_acc: 0.8857\n",
      "Epoch 357/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0079 - acc: 0.9994 - val_loss: 0.9541 - val_acc: 0.8814\n",
      "Epoch 358/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1641 - acc: 0.9588 - val_loss: 1.0155 - val_acc: 0.8703\n",
      "Epoch 359/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0275 - acc: 0.9928 - val_loss: 0.9390 - val_acc: 0.8800\n",
      "Epoch 360/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0106 - acc: 0.9991 - val_loss: 0.9402 - val_acc: 0.8824\n",
      "Epoch 361/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0082 - acc: 0.9996 - val_loss: 0.9476 - val_acc: 0.8831\n",
      "Epoch 362/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0077 - acc: 0.9996 - val_loss: 0.9384 - val_acc: 0.8847\n",
      "Epoch 363/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0071 - acc: 0.9997 - val_loss: 0.9356 - val_acc: 0.8840\n",
      "Epoch 364/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0075 - acc: 0.9996 - val_loss: 0.9330 - val_acc: 0.8841\n",
      "Epoch 365/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0934 - acc: 0.9731 - val_loss: 0.9706 - val_acc: 0.8769\n",
      "Epoch 366/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0315 - acc: 0.9906 - val_loss: 0.9595 - val_acc: 0.8797\n",
      "Epoch 367/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0158 - acc: 0.9970 - val_loss: 0.9462 - val_acc: 0.8839\n",
      "Epoch 368/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0081 - acc: 0.9996 - val_loss: 0.9414 - val_acc: 0.8850\n",
      "Epoch 369/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0070 - acc: 0.9997 - val_loss: 0.9441 - val_acc: 0.8835\n",
      "Epoch 370/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0069 - acc: 0.9996 - val_loss: 0.9382 - val_acc: 0.8859\n",
      "Epoch 371/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0100 - acc: 0.9986 - val_loss: 1.0188 - val_acc: 0.8707\n",
      "Epoch 372/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0965 - acc: 0.9727 - val_loss: 0.9805 - val_acc: 0.8753\n",
      "Epoch 373/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0251 - acc: 0.9937 - val_loss: 0.9250 - val_acc: 0.8836\n",
      "Epoch 374/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0111 - acc: 0.9988 - val_loss: 0.9275 - val_acc: 0.8845\n",
      "Epoch 375/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0071 - acc: 0.9996 - val_loss: 0.9428 - val_acc: 0.8850\n",
      "Epoch 376/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0067 - acc: 0.9998 - val_loss: 0.9404 - val_acc: 0.8861\n",
      "Epoch 377/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0066 - acc: 0.9997 - val_loss: 0.9438 - val_acc: 0.8857\n",
      "Epoch 378/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0066 - acc: 0.9998 - val_loss: 0.9415 - val_acc: 0.8868\n",
      "Epoch 379/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0065 - acc: 0.9998 - val_loss: 0.9530 - val_acc: 0.8845\n",
      "Epoch 380/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0066 - acc: 0.9998 - val_loss: 0.9489 - val_acc: 0.8859\n",
      "Epoch 381/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1333 - acc: 0.9727 - val_loss: 1.0612 - val_acc: 0.8618\n",
      "Epoch 382/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0457 - acc: 0.9867 - val_loss: 0.9631 - val_acc: 0.8794\n",
      "Epoch 383/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0103 - acc: 0.9990 - val_loss: 0.9472 - val_acc: 0.8825\n",
      "Epoch 384/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0076 - acc: 0.9997 - val_loss: 0.9413 - val_acc: 0.8842\n",
      "Epoch 385/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0070 - acc: 0.9997 - val_loss: 0.9522 - val_acc: 0.8831\n",
      "Epoch 386/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0068 - acc: 0.9998 - val_loss: 0.9521 - val_acc: 0.8840\n",
      "Epoch 387/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0067 - acc: 0.9997 - val_loss: 0.9475 - val_acc: 0.8853\n",
      "Epoch 388/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0066 - acc: 0.9998 - val_loss: 0.9521 - val_acc: 0.8850\n",
      "Epoch 389/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0142 - acc: 0.9976 - val_loss: 1.1838 - val_acc: 0.8609\n",
      "Epoch 390/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1076 - acc: 0.9714 - val_loss: 0.9742 - val_acc: 0.8767\n",
      "Epoch 391/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0256 - acc: 0.9936 - val_loss: 0.9870 - val_acc: 0.8769\n",
      "Epoch 392/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0241 - acc: 0.9942 - val_loss: 0.9497 - val_acc: 0.8825\n",
      "Epoch 393/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0083 - acc: 0.9996 - val_loss: 0.9398 - val_acc: 0.8850\n",
      "Epoch 394/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0071 - acc: 0.9997 - val_loss: 0.9452 - val_acc: 0.8854\n",
      "Epoch 395/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0066 - acc: 0.9998 - val_loss: 0.9596 - val_acc: 0.8837\n",
      "Epoch 396/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0065 - acc: 0.9998 - val_loss: 0.9523 - val_acc: 0.8855\n",
      "Epoch 397/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0064 - acc: 0.9998 - val_loss: 0.9531 - val_acc: 0.8858\n",
      "Epoch 398/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0064 - acc: 0.9998 - val_loss: 0.9529 - val_acc: 0.8838\n",
      "Epoch 399/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0390 - acc: 0.9906 - val_loss: 1.1602 - val_acc: 0.8543\n",
      "Epoch 400/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1038 - acc: 0.9700 - val_loss: 0.9777 - val_acc: 0.8767\n",
      "Epoch 401/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0148 - acc: 0.9974 - val_loss: 0.9505 - val_acc: 0.8803\n",
      "Epoch 402/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0126 - acc: 0.9978 - val_loss: 0.9812 - val_acc: 0.8788\n",
      "Epoch 403/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0112 - acc: 0.9987 - val_loss: 0.9431 - val_acc: 0.8856\n",
      "Epoch 404/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0069 - acc: 0.9997 - val_loss: 0.9533 - val_acc: 0.8846\n",
      "Epoch 405/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0064 - acc: 0.9997 - val_loss: 0.9611 - val_acc: 0.8842\n",
      "Epoch 406/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0063 - acc: 0.9998 - val_loss: 0.9599 - val_acc: 0.8853\n",
      "Epoch 407/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0062 - acc: 0.9998 - val_loss: 0.9613 - val_acc: 0.8841\n",
      "Epoch 408/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0061 - acc: 0.9997 - val_loss: 0.9604 - val_acc: 0.8855\n",
      "Epoch 409/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1047 - acc: 0.9725 - val_loss: 0.9987 - val_acc: 0.8725\n",
      "Epoch 410/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0403 - acc: 0.9883 - val_loss: 0.9583 - val_acc: 0.8834\n",
      "Epoch 411/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0140 - acc: 0.9974 - val_loss: 0.9482 - val_acc: 0.8855\n",
      "Epoch 412/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0082 - acc: 0.9995 - val_loss: 0.9653 - val_acc: 0.8841\n",
      "Epoch 413/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0070 - acc: 0.9997 - val_loss: 0.9583 - val_acc: 0.8850\n",
      "Epoch 414/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0065 - acc: 0.9998 - val_loss: 0.9645 - val_acc: 0.8842\n",
      "Epoch 415/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0063 - acc: 0.9997 - val_loss: 0.9586 - val_acc: 0.8869\n",
      "Epoch 416/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0062 - acc: 0.9998 - val_loss: 0.9559 - val_acc: 0.8853\n",
      "Epoch 417/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0062 - acc: 0.9998 - val_loss: 0.9715 - val_acc: 0.8850\n",
      "Epoch 418/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0064 - acc: 0.9997 - val_loss: 0.9661 - val_acc: 0.8853\n",
      "Epoch 419/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0064 - acc: 0.9998 - val_loss: 0.9586 - val_acc: 0.8850\n",
      "Epoch 420/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.1412 - acc: 0.9646 - val_loss: 1.0055 - val_acc: 0.8765\n",
      "Epoch 421/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0294 - acc: 0.9916 - val_loss: 0.9876 - val_acc: 0.8817\n",
      "Epoch 422/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0115 - acc: 0.9985 - val_loss: 0.9556 - val_acc: 0.8855\n",
      "Epoch 423/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0074 - acc: 0.9996 - val_loss: 0.9618 - val_acc: 0.8865\n",
      "Epoch 424/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0067 - acc: 0.9997 - val_loss: 0.9684 - val_acc: 0.8855\n",
      "Epoch 425/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0064 - acc: 0.9997 - val_loss: 0.9661 - val_acc: 0.8859\n",
      "Epoch 426/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0064 - acc: 0.9998 - val_loss: 0.9713 - val_acc: 0.8851\n",
      "Epoch 427/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0061 - acc: 0.9998 - val_loss: 0.9729 - val_acc: 0.8845\n",
      "Epoch 428/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0060 - acc: 0.9998 - val_loss: 0.9674 - val_acc: 0.8853\n",
      "Epoch 429/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0182 - acc: 0.9963 - val_loss: 1.1915 - val_acc: 0.8524\n",
      "Epoch 430/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1215 - acc: 0.9676 - val_loss: 0.9912 - val_acc: 0.8773\n",
      "Epoch 431/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0197 - acc: 0.9956 - val_loss: 0.9687 - val_acc: 0.8842\n",
      "Epoch 432/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0084 - acc: 0.9994 - val_loss: 0.9674 - val_acc: 0.8836\n",
      "Epoch 433/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0257 - acc: 0.9935 - val_loss: 1.0266 - val_acc: 0.8730\n",
      "Epoch 434/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0130 - acc: 0.9979 - val_loss: 0.9650 - val_acc: 0.8840\n",
      "Epoch 435/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0085 - acc: 0.9993 - val_loss: 0.9606 - val_acc: 0.8829\n",
      "Epoch 436/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0063 - acc: 0.9998 - val_loss: 0.9712 - val_acc: 0.8840\n",
      "Epoch 437/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0059 - acc: 0.9998 - val_loss: 0.9696 - val_acc: 0.8834\n",
      "Epoch 438/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0058 - acc: 0.9998 - val_loss: 0.9719 - val_acc: 0.8850\n",
      "Epoch 439/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0057 - acc: 0.9998 - val_loss: 0.9688 - val_acc: 0.8849\n",
      "Epoch 440/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0056 - acc: 0.9998 - val_loss: 0.9655 - val_acc: 0.8859\n",
      "Epoch 441/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0058 - acc: 0.9998 - val_loss: 0.9703 - val_acc: 0.8858\n",
      "Epoch 442/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.1130 - acc: 0.9727 - val_loss: 1.0227 - val_acc: 0.8653\n",
      "Epoch 443/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0457 - acc: 0.9860 - val_loss: 0.9772 - val_acc: 0.8792\n",
      "Epoch 444/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0141 - acc: 0.9973 - val_loss: 0.9770 - val_acc: 0.8838\n",
      "Epoch 445/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0070 - acc: 0.9997 - val_loss: 0.9778 - val_acc: 0.8836\n",
      "Epoch 446/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0063 - acc: 0.9997 - val_loss: 0.9778 - val_acc: 0.8837\n",
      "Epoch 447/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0059 - acc: 0.9998 - val_loss: 0.9796 - val_acc: 0.8850\n",
      "Epoch 448/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0058 - acc: 0.9998 - val_loss: 0.9848 - val_acc: 0.8835\n",
      "Epoch 449/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0057 - acc: 0.9998 - val_loss: 0.9774 - val_acc: 0.8852\n",
      "Epoch 450/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0057 - acc: 0.9997 - val_loss: 0.9803 - val_acc: 0.8844\n",
      "Epoch 451/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0056 - acc: 0.9998 - val_loss: 0.9791 - val_acc: 0.8841\n",
      "Epoch 452/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0057 - acc: 0.9998 - val_loss: 1.0011 - val_acc: 0.8816\n",
      "Epoch 453/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.1486 - acc: 0.9644 - val_loss: 1.0182 - val_acc: 0.8689\n",
      "Epoch 454/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0286 - acc: 0.9925 - val_loss: 0.9996 - val_acc: 0.8800\n",
      "Epoch 455/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0110 - acc: 0.9987 - val_loss: 0.9723 - val_acc: 0.8817\n",
      "Epoch 456/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0070 - acc: 0.9997 - val_loss: 0.9703 - val_acc: 0.8847\n",
      "Epoch 457/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0062 - acc: 0.9998 - val_loss: 0.9784 - val_acc: 0.8842\n",
      "Epoch 458/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0059 - acc: 0.9998 - val_loss: 0.9807 - val_acc: 0.8851\n",
      "Epoch 459/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0059 - acc: 0.9998 - val_loss: 0.9810 - val_acc: 0.8838\n",
      "Epoch 460/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0057 - acc: 0.9998 - val_loss: 0.9895 - val_acc: 0.8840\n",
      "Epoch 461/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0058 - acc: 0.9998 - val_loss: 0.9853 - val_acc: 0.8854\n",
      "Epoch 462/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0056 - acc: 0.9998 - val_loss: 0.9853 - val_acc: 0.8855\n",
      "Epoch 463/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0056 - acc: 0.9998 - val_loss: 0.9829 - val_acc: 0.8839\n",
      "Epoch 464/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0333 - acc: 0.9939 - val_loss: 1.3377 - val_acc: 0.8452\n",
      "Epoch 465/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1305 - acc: 0.9658 - val_loss: 0.9814 - val_acc: 0.8795\n",
      "Epoch 466/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0159 - acc: 0.9966 - val_loss: 0.9684 - val_acc: 0.8852\n",
      "Epoch 467/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0072 - acc: 0.9997 - val_loss: 0.9759 - val_acc: 0.8826\n",
      "Epoch 468/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0063 - acc: 0.9998 - val_loss: 0.9760 - val_acc: 0.8840\n",
      "Epoch 469/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0061 - acc: 0.9998 - val_loss: 0.9747 - val_acc: 0.8849\n",
      "Epoch 470/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0060 - acc: 0.9998 - val_loss: 0.9818 - val_acc: 0.8850\n",
      "Epoch 471/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0059 - acc: 0.9998 - val_loss: 0.9757 - val_acc: 0.8859\n",
      "Epoch 472/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0058 - acc: 0.9998 - val_loss: 0.9818 - val_acc: 0.8857\n",
      "Epoch 473/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0057 - acc: 0.9998 - val_loss: 0.9804 - val_acc: 0.8864\n",
      "Epoch 474/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0061 - acc: 0.9997 - val_loss: 0.9960 - val_acc: 0.8841\n",
      "Epoch 475/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1199 - acc: 0.9704 - val_loss: 1.0306 - val_acc: 0.8745\n",
      "Epoch 476/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0329 - acc: 0.9911 - val_loss: 1.0092 - val_acc: 0.8798\n",
      "Epoch 477/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0092 - acc: 0.9991 - val_loss: 0.9815 - val_acc: 0.8850\n",
      "Epoch 478/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0063 - acc: 0.9998 - val_loss: 0.9824 - val_acc: 0.8861\n",
      "Epoch 479/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0058 - acc: 0.9998 - val_loss: 0.9911 - val_acc: 0.8849\n",
      "Epoch 480/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0056 - acc: 0.9998 - val_loss: 0.9868 - val_acc: 0.8854\n",
      "Epoch 481/500\n",
      "34108/34108 [==============================] - 1s 27us/step - loss: 0.0055 - acc: 0.9998 - val_loss: 0.9903 - val_acc: 0.8841\n",
      "Epoch 482/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0819 - acc: 0.9798 - val_loss: 1.0707 - val_acc: 0.8713\n",
      "Epoch 483/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0381 - acc: 0.9900 - val_loss: 0.9877 - val_acc: 0.8814\n",
      "Epoch 484/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0082 - acc: 0.9993 - val_loss: 0.9908 - val_acc: 0.8822\n",
      "Epoch 485/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0062 - acc: 0.9997 - val_loss: 0.9893 - val_acc: 0.8850\n",
      "Epoch 486/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0058 - acc: 0.9998 - val_loss: 0.9880 - val_acc: 0.8862\n",
      "Epoch 487/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0056 - acc: 0.9998 - val_loss: 0.9920 - val_acc: 0.8845\n",
      "Epoch 488/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0055 - acc: 0.9998 - val_loss: 0.9910 - val_acc: 0.8855\n",
      "Epoch 489/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0055 - acc: 0.9998 - val_loss: 0.9945 - val_acc: 0.8850\n",
      "Epoch 490/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0054 - acc: 0.9998 - val_loss: 1.0008 - val_acc: 0.8853\n",
      "Epoch 491/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0055 - acc: 0.9998 - val_loss: 0.9970 - val_acc: 0.8867\n",
      "Epoch 492/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0488 - acc: 0.9904 - val_loss: 1.3746 - val_acc: 0.8330\n",
      "Epoch 493/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.1000 - acc: 0.9741 - val_loss: 1.0197 - val_acc: 0.8793\n",
      "Epoch 494/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0202 - acc: 0.9951 - val_loss: 0.9910 - val_acc: 0.8829\n",
      "Epoch 495/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0100 - acc: 0.9987 - val_loss: 0.9905 - val_acc: 0.8835\n",
      "Epoch 496/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0062 - acc: 0.9998 - val_loss: 0.9897 - val_acc: 0.8855\n",
      "Epoch 497/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0056 - acc: 0.9998 - val_loss: 0.9959 - val_acc: 0.8853\n",
      "Epoch 498/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0055 - acc: 0.9998 - val_loss: 0.9870 - val_acc: 0.8861\n",
      "Epoch 499/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0054 - acc: 0.9998 - val_loss: 0.9978 - val_acc: 0.8850\n",
      "Epoch 500/500\n",
      "34108/34108 [==============================] - 1s 26us/step - loss: 0.0053 - acc: 0.9998 - val_loss: 0.9978 - val_acc: 0.8852\n",
      "Train on 34108 samples, validate on 12117 samples\n",
      "Epoch 1/500\n",
      "34108/34108 [==============================] - 2s 47us/step - loss: 1.1964 - acc: 0.5409 - val_loss: 0.8958 - val_acc: 0.7043\n",
      "Epoch 2/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.8144 - acc: 0.7406 - val_loss: 0.7534 - val_acc: 0.7588\n",
      "Epoch 3/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.6893 - acc: 0.7855 - val_loss: 0.6798 - val_acc: 0.7905\n",
      "Epoch 4/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.6285 - acc: 0.8067 - val_loss: 0.6413 - val_acc: 0.8032\n",
      "Epoch 5/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.5831 - acc: 0.8210 - val_loss: 0.6126 - val_acc: 0.8108\n",
      "Epoch 6/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.5503 - acc: 0.8305 - val_loss: 0.5881 - val_acc: 0.8182\n",
      "Epoch 7/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.5225 - acc: 0.8390 - val_loss: 0.5650 - val_acc: 0.8324\n",
      "Epoch 8/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.4944 - acc: 0.8485 - val_loss: 0.5560 - val_acc: 0.8366\n",
      "Epoch 9/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.4772 - acc: 0.8535 - val_loss: 0.5796 - val_acc: 0.8275\n",
      "Epoch 10/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.4568 - acc: 0.8607 - val_loss: 0.5294 - val_acc: 0.8446\n",
      "Epoch 11/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.4405 - acc: 0.8658 - val_loss: 0.5357 - val_acc: 0.8440\n",
      "Epoch 12/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.4190 - acc: 0.8733 - val_loss: 0.5047 - val_acc: 0.8533\n",
      "Epoch 13/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.4112 - acc: 0.8741 - val_loss: 0.5326 - val_acc: 0.8510\n",
      "Epoch 14/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.3956 - acc: 0.8788 - val_loss: 0.5373 - val_acc: 0.8442\n",
      "Epoch 15/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.3848 - acc: 0.8823 - val_loss: 0.5017 - val_acc: 0.8617\n",
      "Epoch 16/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.3768 - acc: 0.8853 - val_loss: 0.4927 - val_acc: 0.8619\n",
      "Epoch 17/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.3621 - acc: 0.8903 - val_loss: 0.4903 - val_acc: 0.8641\n",
      "Epoch 18/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.3528 - acc: 0.8928 - val_loss: 0.4753 - val_acc: 0.8666\n",
      "Epoch 19/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.3472 - acc: 0.8944 - val_loss: 0.4900 - val_acc: 0.8589\n",
      "Epoch 20/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.3356 - acc: 0.8973 - val_loss: 0.4687 - val_acc: 0.8667\n",
      "Epoch 21/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.3254 - acc: 0.9019 - val_loss: 0.4751 - val_acc: 0.8667\n",
      "Epoch 22/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.3169 - acc: 0.9037 - val_loss: 0.4862 - val_acc: 0.8646\n",
      "Epoch 23/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.3111 - acc: 0.9076 - val_loss: 0.4740 - val_acc: 0.8716\n",
      "Epoch 24/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.3059 - acc: 0.9075 - val_loss: 0.4818 - val_acc: 0.8733\n",
      "Epoch 25/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.2986 - acc: 0.9085 - val_loss: 0.4753 - val_acc: 0.8718\n",
      "Epoch 26/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.2937 - acc: 0.9115 - val_loss: 0.4701 - val_acc: 0.8757\n",
      "Epoch 27/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.2922 - acc: 0.9103 - val_loss: 0.4667 - val_acc: 0.8735\n",
      "Epoch 28/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.2808 - acc: 0.9136 - val_loss: 0.4595 - val_acc: 0.8790\n",
      "Epoch 29/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.2796 - acc: 0.9155 - val_loss: 0.4751 - val_acc: 0.8755\n",
      "Epoch 30/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.2709 - acc: 0.9171 - val_loss: 0.4613 - val_acc: 0.8804\n",
      "Epoch 31/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.2696 - acc: 0.9169 - val_loss: 0.4956 - val_acc: 0.8722\n",
      "Epoch 32/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.2607 - acc: 0.9213 - val_loss: 0.4778 - val_acc: 0.8795\n",
      "Epoch 33/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.2533 - acc: 0.9230 - val_loss: 0.4771 - val_acc: 0.8795\n",
      "Epoch 34/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.2503 - acc: 0.9240 - val_loss: 0.4786 - val_acc: 0.8766\n",
      "Epoch 35/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.2453 - acc: 0.9251 - val_loss: 0.4717 - val_acc: 0.8804\n",
      "Epoch 36/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.2430 - acc: 0.9264 - val_loss: 0.4671 - val_acc: 0.8814\n",
      "Epoch 37/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.2362 - acc: 0.9274 - val_loss: 0.4775 - val_acc: 0.8793\n",
      "Epoch 38/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.2313 - acc: 0.9287 - val_loss: 0.5042 - val_acc: 0.8704\n",
      "Epoch 39/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.2275 - acc: 0.9306 - val_loss: 0.5050 - val_acc: 0.8777\n",
      "Epoch 40/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.2246 - acc: 0.9312 - val_loss: 0.4898 - val_acc: 0.8750\n",
      "Epoch 41/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.2240 - acc: 0.9317 - val_loss: 0.4912 - val_acc: 0.8780\n",
      "Epoch 42/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.2148 - acc: 0.9339 - val_loss: 0.4877 - val_acc: 0.8819\n",
      "Epoch 43/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.2135 - acc: 0.9345 - val_loss: 0.4790 - val_acc: 0.8836\n",
      "Epoch 44/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.2052 - acc: 0.9379 - val_loss: 0.4866 - val_acc: 0.8809\n",
      "Epoch 45/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.2049 - acc: 0.9382 - val_loss: 0.4794 - val_acc: 0.8826\n",
      "Epoch 46/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.2073 - acc: 0.9361 - val_loss: 0.4866 - val_acc: 0.8844\n",
      "Epoch 47/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.2000 - acc: 0.9387 - val_loss: 0.4907 - val_acc: 0.8821\n",
      "Epoch 48/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1920 - acc: 0.9427 - val_loss: 0.5095 - val_acc: 0.8793\n",
      "Epoch 49/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1923 - acc: 0.9412 - val_loss: 0.5006 - val_acc: 0.8807\n",
      "Epoch 50/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1844 - acc: 0.9444 - val_loss: 0.5012 - val_acc: 0.8833\n",
      "Epoch 51/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1861 - acc: 0.9436 - val_loss: 0.4920 - val_acc: 0.8840\n",
      "Epoch 52/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.1772 - acc: 0.9473 - val_loss: 0.5040 - val_acc: 0.8814\n",
      "Epoch 53/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.1781 - acc: 0.9467 - val_loss: 0.5127 - val_acc: 0.8850\n",
      "Epoch 54/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1784 - acc: 0.9461 - val_loss: 0.5063 - val_acc: 0.8803\n",
      "Epoch 55/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1721 - acc: 0.9474 - val_loss: 0.5070 - val_acc: 0.8859\n",
      "Epoch 56/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1710 - acc: 0.9475 - val_loss: 0.5195 - val_acc: 0.8823\n",
      "Epoch 57/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1650 - acc: 0.9506 - val_loss: 0.5182 - val_acc: 0.8800\n",
      "Epoch 58/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1616 - acc: 0.9497 - val_loss: 0.5221 - val_acc: 0.8837\n",
      "Epoch 59/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1630 - acc: 0.9506 - val_loss: 0.5198 - val_acc: 0.8848\n",
      "Epoch 60/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1529 - acc: 0.9539 - val_loss: 0.5417 - val_acc: 0.8790\n",
      "Epoch 61/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1579 - acc: 0.9519 - val_loss: 0.5478 - val_acc: 0.8798\n",
      "Epoch 62/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.1489 - acc: 0.9552 - val_loss: 0.5283 - val_acc: 0.8813\n",
      "Epoch 63/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.1493 - acc: 0.9549 - val_loss: 0.5491 - val_acc: 0.8763\n",
      "Epoch 64/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1451 - acc: 0.9564 - val_loss: 0.5407 - val_acc: 0.8828\n",
      "Epoch 65/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1438 - acc: 0.9565 - val_loss: 0.5412 - val_acc: 0.8818\n",
      "Epoch 66/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1468 - acc: 0.9546 - val_loss: 0.5432 - val_acc: 0.8820\n",
      "Epoch 67/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1417 - acc: 0.9569 - val_loss: 0.5461 - val_acc: 0.8840\n",
      "Epoch 68/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1385 - acc: 0.9586 - val_loss: 0.5468 - val_acc: 0.8818\n",
      "Epoch 69/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1377 - acc: 0.9573 - val_loss: 0.5446 - val_acc: 0.8810\n",
      "Epoch 70/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1361 - acc: 0.9588 - val_loss: 0.5491 - val_acc: 0.8823\n",
      "Epoch 71/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.1345 - acc: 0.9586 - val_loss: 0.5443 - val_acc: 0.8843\n",
      "Epoch 72/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1297 - acc: 0.9601 - val_loss: 0.5505 - val_acc: 0.8826\n",
      "Epoch 73/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1229 - acc: 0.9635 - val_loss: 0.5627 - val_acc: 0.8814\n",
      "Epoch 74/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1319 - acc: 0.9597 - val_loss: 0.5566 - val_acc: 0.8821\n",
      "Epoch 75/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1211 - acc: 0.9636 - val_loss: 0.5735 - val_acc: 0.8799\n",
      "Epoch 76/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1274 - acc: 0.9601 - val_loss: 0.5615 - val_acc: 0.8851\n",
      "Epoch 77/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1198 - acc: 0.9631 - val_loss: 0.5633 - val_acc: 0.8869\n",
      "Epoch 78/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.1132 - acc: 0.9668 - val_loss: 0.5747 - val_acc: 0.8823\n",
      "Epoch 79/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1148 - acc: 0.9652 - val_loss: 0.5992 - val_acc: 0.8753\n",
      "Epoch 80/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.1249 - acc: 0.9605 - val_loss: 0.6337 - val_acc: 0.8768\n",
      "Epoch 81/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1138 - acc: 0.9661 - val_loss: 0.5714 - val_acc: 0.8860\n",
      "Epoch 82/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1119 - acc: 0.9665 - val_loss: 0.6498 - val_acc: 0.8684\n",
      "Epoch 83/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1052 - acc: 0.9685 - val_loss: 0.6050 - val_acc: 0.8784\n",
      "Epoch 84/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1065 - acc: 0.9674 - val_loss: 0.5905 - val_acc: 0.8807\n",
      "Epoch 85/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1114 - acc: 0.9660 - val_loss: 0.5874 - val_acc: 0.8828\n",
      "Epoch 86/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0989 - acc: 0.9723 - val_loss: 0.5969 - val_acc: 0.8842\n",
      "Epoch 87/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1058 - acc: 0.9677 - val_loss: 0.6145 - val_acc: 0.8783\n",
      "Epoch 88/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0973 - acc: 0.9710 - val_loss: 0.5952 - val_acc: 0.8837\n",
      "Epoch 89/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.1033 - acc: 0.9696 - val_loss: 0.6139 - val_acc: 0.8791\n",
      "Epoch 90/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1011 - acc: 0.9688 - val_loss: 0.6094 - val_acc: 0.8796\n",
      "Epoch 91/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1004 - acc: 0.9707 - val_loss: 0.6139 - val_acc: 0.8808\n",
      "Epoch 92/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1027 - acc: 0.9675 - val_loss: 0.6118 - val_acc: 0.8817\n",
      "Epoch 93/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0892 - acc: 0.9738 - val_loss: 0.6862 - val_acc: 0.8673\n",
      "Epoch 94/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0977 - acc: 0.9715 - val_loss: 0.6096 - val_acc: 0.8826\n",
      "Epoch 95/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0978 - acc: 0.9702 - val_loss: 0.6118 - val_acc: 0.8803\n",
      "Epoch 96/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0874 - acc: 0.9743 - val_loss: 0.6065 - val_acc: 0.8857\n",
      "Epoch 97/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0919 - acc: 0.9739 - val_loss: 0.6310 - val_acc: 0.8817\n",
      "Epoch 98/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0922 - acc: 0.9725 - val_loss: 0.6321 - val_acc: 0.8794\n",
      "Epoch 99/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0869 - acc: 0.9746 - val_loss: 0.6217 - val_acc: 0.8850\n",
      "Epoch 100/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0932 - acc: 0.9711 - val_loss: 0.6305 - val_acc: 0.8864\n",
      "Epoch 101/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0901 - acc: 0.9728 - val_loss: 0.6517 - val_acc: 0.8778\n",
      "Epoch 102/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0787 - acc: 0.9766 - val_loss: 0.6262 - val_acc: 0.8893\n",
      "Epoch 103/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0794 - acc: 0.9777 - val_loss: 0.6351 - val_acc: 0.8836\n",
      "Epoch 104/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0798 - acc: 0.9780 - val_loss: 0.6287 - val_acc: 0.8839\n",
      "Epoch 105/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0860 - acc: 0.9743 - val_loss: 0.6729 - val_acc: 0.8762\n",
      "Epoch 106/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0835 - acc: 0.9744 - val_loss: 0.6350 - val_acc: 0.8836\n",
      "Epoch 107/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0757 - acc: 0.9779 - val_loss: 0.6299 - val_acc: 0.8835\n",
      "Epoch 108/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0796 - acc: 0.9765 - val_loss: 0.6947 - val_acc: 0.8751\n",
      "Epoch 109/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0739 - acc: 0.9788 - val_loss: 0.7125 - val_acc: 0.8695\n",
      "Epoch 110/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0829 - acc: 0.9756 - val_loss: 0.6792 - val_acc: 0.8765\n",
      "Epoch 111/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0807 - acc: 0.9755 - val_loss: 0.6711 - val_acc: 0.8770\n",
      "Epoch 112/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0742 - acc: 0.9782 - val_loss: 0.6709 - val_acc: 0.8772\n",
      "Epoch 113/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0678 - acc: 0.9808 - val_loss: 0.6565 - val_acc: 0.8840\n",
      "Epoch 114/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0740 - acc: 0.9784 - val_loss: 0.6619 - val_acc: 0.8808\n",
      "Epoch 115/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0748 - acc: 0.9783 - val_loss: 0.6974 - val_acc: 0.8753\n",
      "Epoch 116/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0676 - acc: 0.9817 - val_loss: 0.6812 - val_acc: 0.8808\n",
      "Epoch 117/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0679 - acc: 0.9812 - val_loss: 0.6903 - val_acc: 0.8805\n",
      "Epoch 118/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0699 - acc: 0.9798 - val_loss: 0.6716 - val_acc: 0.8812\n",
      "Epoch 119/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0737 - acc: 0.9780 - val_loss: 0.6708 - val_acc: 0.8824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0667 - acc: 0.9811 - val_loss: 0.6865 - val_acc: 0.8819\n",
      "Epoch 121/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0731 - acc: 0.9785 - val_loss: 0.7168 - val_acc: 0.8792\n",
      "Epoch 122/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0658 - acc: 0.9812 - val_loss: 0.6910 - val_acc: 0.8834\n",
      "Epoch 123/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0617 - acc: 0.9818 - val_loss: 0.6654 - val_acc: 0.8864\n",
      "Epoch 124/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0648 - acc: 0.9813 - val_loss: 0.6867 - val_acc: 0.8819\n",
      "Epoch 125/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0594 - acc: 0.9832 - val_loss: 0.7096 - val_acc: 0.8800\n",
      "Epoch 126/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0631 - acc: 0.9821 - val_loss: 0.6934 - val_acc: 0.8855\n",
      "Epoch 127/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0594 - acc: 0.9830 - val_loss: 0.6814 - val_acc: 0.8863\n",
      "Epoch 128/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0629 - acc: 0.9825 - val_loss: 0.6709 - val_acc: 0.8862\n",
      "Epoch 129/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0744 - acc: 0.9772 - val_loss: 0.7178 - val_acc: 0.8790\n",
      "Epoch 130/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0628 - acc: 0.9826 - val_loss: 0.6974 - val_acc: 0.8808\n",
      "Epoch 131/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0569 - acc: 0.9849 - val_loss: 0.7160 - val_acc: 0.8783\n",
      "Epoch 132/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0568 - acc: 0.9842 - val_loss: 0.6927 - val_acc: 0.8849\n",
      "Epoch 133/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0619 - acc: 0.9827 - val_loss: 0.7046 - val_acc: 0.8850\n",
      "Epoch 134/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0471 - acc: 0.9886 - val_loss: 0.6972 - val_acc: 0.8850\n",
      "Epoch 135/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0526 - acc: 0.9860 - val_loss: 0.7124 - val_acc: 0.8828\n",
      "Epoch 136/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0805 - acc: 0.9754 - val_loss: 0.7132 - val_acc: 0.8797\n",
      "Epoch 137/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0568 - acc: 0.9838 - val_loss: 0.7074 - val_acc: 0.8857\n",
      "Epoch 138/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0521 - acc: 0.9861 - val_loss: 0.7127 - val_acc: 0.8837\n",
      "Epoch 139/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0444 - acc: 0.9895 - val_loss: 0.7527 - val_acc: 0.8740\n",
      "Epoch 140/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0541 - acc: 0.9851 - val_loss: 0.7177 - val_acc: 0.8841\n",
      "Epoch 141/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0555 - acc: 0.9840 - val_loss: 0.7342 - val_acc: 0.8805\n",
      "Epoch 142/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0530 - acc: 0.9851 - val_loss: 0.7297 - val_acc: 0.8804\n",
      "Epoch 143/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0478 - acc: 0.9874 - val_loss: 0.7266 - val_acc: 0.8797\n",
      "Epoch 144/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0667 - acc: 0.9797 - val_loss: 0.7381 - val_acc: 0.8832\n",
      "Epoch 145/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0523 - acc: 0.9855 - val_loss: 0.7609 - val_acc: 0.8789\n",
      "Epoch 146/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0548 - acc: 0.9844 - val_loss: 0.7176 - val_acc: 0.8837\n",
      "Epoch 147/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0512 - acc: 0.9857 - val_loss: 0.7193 - val_acc: 0.8821\n",
      "Epoch 148/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0438 - acc: 0.9892 - val_loss: 0.7561 - val_acc: 0.8804\n",
      "Epoch 149/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0427 - acc: 0.9890 - val_loss: 0.7449 - val_acc: 0.8844\n",
      "Epoch 150/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0648 - acc: 0.9802 - val_loss: 0.7525 - val_acc: 0.8769\n",
      "Epoch 151/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0479 - acc: 0.9867 - val_loss: 0.7642 - val_acc: 0.8765\n",
      "Epoch 152/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0535 - acc: 0.9840 - val_loss: 0.7466 - val_acc: 0.8825\n",
      "Epoch 153/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0453 - acc: 0.9879 - val_loss: 0.7889 - val_acc: 0.8758\n",
      "Epoch 154/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0593 - acc: 0.9825 - val_loss: 0.7412 - val_acc: 0.8849\n",
      "Epoch 155/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0385 - acc: 0.9909 - val_loss: 0.7563 - val_acc: 0.8827\n",
      "Epoch 156/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0391 - acc: 0.9908 - val_loss: 0.7338 - val_acc: 0.8845\n",
      "Epoch 157/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0381 - acc: 0.9908 - val_loss: 0.7547 - val_acc: 0.8831\n",
      "Epoch 158/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0675 - acc: 0.9787 - val_loss: 0.8009 - val_acc: 0.8699\n",
      "Epoch 159/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0479 - acc: 0.9869 - val_loss: 0.7513 - val_acc: 0.8830\n",
      "Epoch 160/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0307 - acc: 0.9937 - val_loss: 0.7489 - val_acc: 0.8866\n",
      "Epoch 161/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0477 - acc: 0.9870 - val_loss: 0.7983 - val_acc: 0.8756\n",
      "Epoch 162/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0554 - acc: 0.9836 - val_loss: 0.7774 - val_acc: 0.8790\n",
      "Epoch 163/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0336 - acc: 0.9921 - val_loss: 0.7940 - val_acc: 0.8769\n",
      "Epoch 164/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0423 - acc: 0.9890 - val_loss: 0.7827 - val_acc: 0.8790\n",
      "Epoch 165/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0451 - acc: 0.9880 - val_loss: 0.7509 - val_acc: 0.8840\n",
      "Epoch 166/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0332 - acc: 0.9923 - val_loss: 0.8047 - val_acc: 0.8745\n",
      "Epoch 167/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0432 - acc: 0.9890 - val_loss: 0.7615 - val_acc: 0.8827\n",
      "Epoch 168/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0574 - acc: 0.9817 - val_loss: 0.8119 - val_acc: 0.8722\n",
      "Epoch 169/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0508 - acc: 0.9853 - val_loss: 0.7712 - val_acc: 0.8824\n",
      "Epoch 170/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0319 - acc: 0.9934 - val_loss: 0.7660 - val_acc: 0.8862\n",
      "Epoch 171/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0282 - acc: 0.9943 - val_loss: 0.7952 - val_acc: 0.8792\n",
      "Epoch 172/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0331 - acc: 0.9924 - val_loss: 0.8074 - val_acc: 0.8741\n",
      "Epoch 173/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0723 - acc: 0.9770 - val_loss: 0.7712 - val_acc: 0.8821\n",
      "Epoch 174/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0320 - acc: 0.9926 - val_loss: 0.7847 - val_acc: 0.8812\n",
      "Epoch 175/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0311 - acc: 0.9926 - val_loss: 0.7803 - val_acc: 0.8827\n",
      "Epoch 176/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0580 - acc: 0.9833 - val_loss: 0.7904 - val_acc: 0.8791\n",
      "Epoch 177/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0352 - acc: 0.9916 - val_loss: 0.7735 - val_acc: 0.8839\n",
      "Epoch 178/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0258 - acc: 0.9951 - val_loss: 0.7790 - val_acc: 0.8848\n",
      "Epoch 179/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0320 - acc: 0.9923 - val_loss: 0.8537 - val_acc: 0.8708\n",
      "Epoch 180/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0668 - acc: 0.9790 - val_loss: 0.7819 - val_acc: 0.8860\n",
      "Epoch 181/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0246 - acc: 0.9948 - val_loss: 0.7987 - val_acc: 0.8836\n",
      "Epoch 182/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0233 - acc: 0.9960 - val_loss: 0.7896 - val_acc: 0.8847\n",
      "Epoch 183/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0279 - acc: 0.9939 - val_loss: 0.8166 - val_acc: 0.8777\n",
      "Epoch 184/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0654 - acc: 0.9802 - val_loss: 0.8118 - val_acc: 0.8783\n",
      "Epoch 185/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0484 - acc: 0.9859 - val_loss: 0.8149 - val_acc: 0.8803\n",
      "Epoch 186/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0471 - acc: 0.9872 - val_loss: 0.8457 - val_acc: 0.8713\n",
      "Epoch 187/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0322 - acc: 0.9926 - val_loss: 0.7978 - val_acc: 0.8818\n",
      "Epoch 188/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0210 - acc: 0.9965 - val_loss: 0.7916 - val_acc: 0.8860\n",
      "Epoch 189/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0347 - acc: 0.9909 - val_loss: 0.8214 - val_acc: 0.8796\n",
      "Epoch 190/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0599 - acc: 0.9816 - val_loss: 0.8036 - val_acc: 0.8817\n",
      "Epoch 191/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0211 - acc: 0.9967 - val_loss: 0.7974 - val_acc: 0.8864\n",
      "Epoch 192/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0220 - acc: 0.9960 - val_loss: 0.8361 - val_acc: 0.8784\n",
      "Epoch 193/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0541 - acc: 0.9833 - val_loss: 0.8274 - val_acc: 0.8774\n",
      "Epoch 194/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0367 - acc: 0.9902 - val_loss: 0.8213 - val_acc: 0.8838\n",
      "Epoch 195/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0224 - acc: 0.9956 - val_loss: 0.8196 - val_acc: 0.8811\n",
      "Epoch 196/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0209 - acc: 0.9962 - val_loss: 0.8158 - val_acc: 0.8834\n",
      "Epoch 197/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0333 - acc: 0.9912 - val_loss: 0.8971 - val_acc: 0.8673\n",
      "Epoch 198/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0785 - acc: 0.9752 - val_loss: 0.8385 - val_acc: 0.8784\n",
      "Epoch 199/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0303 - acc: 0.9928 - val_loss: 0.8152 - val_acc: 0.8831\n",
      "Epoch 200/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0175 - acc: 0.9974 - val_loss: 0.8157 - val_acc: 0.8858\n",
      "Epoch 201/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0524 - acc: 0.9847 - val_loss: 0.9004 - val_acc: 0.8693\n",
      "Epoch 202/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0461 - acc: 0.9860 - val_loss: 0.8247 - val_acc: 0.8818\n",
      "Epoch 203/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0191 - acc: 0.9968 - val_loss: 0.8297 - val_acc: 0.8831\n",
      "Epoch 204/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0156 - acc: 0.9979 - val_loss: 0.8260 - val_acc: 0.8845\n",
      "Epoch 205/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0163 - acc: 0.9977 - val_loss: 0.8290 - val_acc: 0.8827\n",
      "Epoch 206/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0414 - acc: 0.9882 - val_loss: 0.8801 - val_acc: 0.8719\n",
      "Epoch 207/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0913 - acc: 0.9704 - val_loss: 0.8149 - val_acc: 0.8808\n",
      "Epoch 208/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0235 - acc: 0.9951 - val_loss: 0.8176 - val_acc: 0.8869\n",
      "Epoch 209/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0166 - acc: 0.9977 - val_loss: 0.8223 - val_acc: 0.8862\n",
      "Epoch 210/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0167 - acc: 0.9972 - val_loss: 0.8272 - val_acc: 0.8848\n",
      "Epoch 211/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0167 - acc: 0.9977 - val_loss: 0.8103 - val_acc: 0.8859\n",
      "Epoch 212/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0382 - acc: 0.9889 - val_loss: 0.8575 - val_acc: 0.8755\n",
      "Epoch 213/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0798 - acc: 0.9750 - val_loss: 0.8335 - val_acc: 0.8775\n",
      "Epoch 214/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0209 - acc: 0.9963 - val_loss: 0.8206 - val_acc: 0.8850\n",
      "Epoch 215/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0153 - acc: 0.9979 - val_loss: 0.8338 - val_acc: 0.8847\n",
      "Epoch 216/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0140 - acc: 0.9984 - val_loss: 0.8359 - val_acc: 0.8836\n",
      "Epoch 217/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0166 - acc: 0.9976 - val_loss: 0.8252 - val_acc: 0.8850\n",
      "Epoch 218/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0582 - acc: 0.9831 - val_loss: 0.9371 - val_acc: 0.8644\n",
      "Epoch 219/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0604 - acc: 0.9809 - val_loss: 0.8470 - val_acc: 0.8832\n",
      "Epoch 220/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0180 - acc: 0.9967 - val_loss: 0.8376 - val_acc: 0.8863\n",
      "Epoch 221/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0151 - acc: 0.9979 - val_loss: 0.8344 - val_acc: 0.8861\n",
      "Epoch 222/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0131 - acc: 0.9985 - val_loss: 0.8398 - val_acc: 0.8837\n",
      "Epoch 223/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0271 - acc: 0.9933 - val_loss: 0.8759 - val_acc: 0.8779\n",
      "Epoch 224/500\n",
      "34108/34108 [==============================] - 1s 35us/step - loss: 0.0769 - acc: 0.9768 - val_loss: 0.9026 - val_acc: 0.8711\n",
      "Epoch 225/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0298 - acc: 0.9925 - val_loss: 0.8612 - val_acc: 0.8796\n",
      "Epoch 226/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0136 - acc: 0.9983 - val_loss: 0.8375 - val_acc: 0.8845\n",
      "Epoch 227/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0136 - acc: 0.9983 - val_loss: 0.8587 - val_acc: 0.8810\n",
      "Epoch 228/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0718 - acc: 0.9775 - val_loss: 0.8505 - val_acc: 0.8790\n",
      "Epoch 229/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0265 - acc: 0.9935 - val_loss: 0.8289 - val_acc: 0.8873\n",
      "Epoch 230/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0135 - acc: 0.9984 - val_loss: 0.8404 - val_acc: 0.8845\n",
      "Epoch 231/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0128 - acc: 0.9984 - val_loss: 0.8721 - val_acc: 0.8794\n",
      "Epoch 232/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0279 - acc: 0.9923 - val_loss: 0.9185 - val_acc: 0.8776\n",
      "Epoch 233/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0677 - acc: 0.9789 - val_loss: 0.8762 - val_acc: 0.8778\n",
      "Epoch 234/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0456 - acc: 0.9864 - val_loss: 0.8535 - val_acc: 0.8798\n",
      "Epoch 235/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0159 - acc: 0.9974 - val_loss: 0.8417 - val_acc: 0.8840\n",
      "Epoch 236/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0111 - acc: 0.9989 - val_loss: 0.8406 - val_acc: 0.8855\n",
      "Epoch 237/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0111 - acc: 0.9989 - val_loss: 0.8567 - val_acc: 0.8850\n",
      "Epoch 238/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0376 - acc: 0.9894 - val_loss: 0.9142 - val_acc: 0.8722\n",
      "Epoch 239/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0630 - acc: 0.9804 - val_loss: 0.9209 - val_acc: 0.8718\n",
      "Epoch 240/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0220 - acc: 0.9952 - val_loss: 0.8566 - val_acc: 0.8821\n",
      "Epoch 241/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0126 - acc: 0.9985 - val_loss: 0.8627 - val_acc: 0.8851\n",
      "Epoch 242/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0113 - acc: 0.9987 - val_loss: 0.8732 - val_acc: 0.8819\n",
      "Epoch 243/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0119 - acc: 0.9985 - val_loss: 0.8533 - val_acc: 0.8852\n",
      "Epoch 244/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0754 - acc: 0.9770 - val_loss: 0.8852 - val_acc: 0.8741\n",
      "Epoch 245/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0348 - acc: 0.9905 - val_loss: 0.8657 - val_acc: 0.8784\n",
      "Epoch 246/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0154 - acc: 0.9977 - val_loss: 0.8580 - val_acc: 0.8834\n",
      "Epoch 247/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0107 - acc: 0.9990 - val_loss: 0.8539 - val_acc: 0.8843\n",
      "Epoch 248/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0102 - acc: 0.9993 - val_loss: 0.8723 - val_acc: 0.8825\n",
      "Epoch 249/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0601 - acc: 0.9815 - val_loss: 0.9101 - val_acc: 0.8749\n",
      "Epoch 250/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0415 - acc: 0.9880 - val_loss: 0.8675 - val_acc: 0.8818\n",
      "Epoch 251/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0128 - acc: 0.9985 - val_loss: 0.8752 - val_acc: 0.8837\n",
      "Epoch 252/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0098 - acc: 0.9992 - val_loss: 0.8687 - val_acc: 0.8846\n",
      "Epoch 253/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0100 - acc: 0.9992 - val_loss: 0.8786 - val_acc: 0.8821\n",
      "Epoch 254/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0101 - acc: 0.9991 - val_loss: 0.8849 - val_acc: 0.8829\n",
      "Epoch 255/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0730 - acc: 0.9781 - val_loss: 0.9476 - val_acc: 0.8699\n",
      "Epoch 256/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0522 - acc: 0.9843 - val_loss: 0.8690 - val_acc: 0.8806\n",
      "Epoch 257/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0136 - acc: 0.9981 - val_loss: 0.8726 - val_acc: 0.8834\n",
      "Epoch 258/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0092 - acc: 0.9994 - val_loss: 0.8669 - val_acc: 0.8851\n",
      "Epoch 259/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0090 - acc: 0.9992 - val_loss: 0.8689 - val_acc: 0.8872\n",
      "Epoch 260/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0088 - acc: 0.9995 - val_loss: 0.8765 - val_acc: 0.8856\n",
      "Epoch 261/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0187 - acc: 0.9961 - val_loss: 0.9378 - val_acc: 0.8720\n",
      "Epoch 262/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.1001 - acc: 0.9682 - val_loss: 0.9787 - val_acc: 0.8646\n",
      "Epoch 263/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0323 - acc: 0.9916 - val_loss: 0.8751 - val_acc: 0.8826\n",
      "Epoch 264/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0141 - acc: 0.9978 - val_loss: 0.8757 - val_acc: 0.8829\n",
      "Epoch 265/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0088 - acc: 0.9994 - val_loss: 0.8775 - val_acc: 0.8873\n",
      "Epoch 266/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0081 - acc: 0.9995 - val_loss: 0.8872 - val_acc: 0.8845\n",
      "Epoch 267/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0083 - acc: 0.9995 - val_loss: 0.8835 - val_acc: 0.8849\n",
      "Epoch 268/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0083 - acc: 0.9994 - val_loss: 0.8834 - val_acc: 0.8873\n",
      "Epoch 269/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0886 - acc: 0.9734 - val_loss: 1.0705 - val_acc: 0.8540\n",
      "Epoch 270/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0590 - acc: 0.9825 - val_loss: 0.8843 - val_acc: 0.8789\n",
      "Epoch 271/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0114 - acc: 0.9987 - val_loss: 0.8722 - val_acc: 0.8858\n",
      "Epoch 272/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0087 - acc: 0.9996 - val_loss: 0.8725 - val_acc: 0.8841\n",
      "Epoch 273/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0081 - acc: 0.9996 - val_loss: 0.8860 - val_acc: 0.8850\n",
      "Epoch 274/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0083 - acc: 0.9996 - val_loss: 0.8835 - val_acc: 0.8860\n",
      "Epoch 275/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0078 - acc: 0.9996 - val_loss: 0.8837 - val_acc: 0.8838\n",
      "Epoch 276/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0790 - acc: 0.9802 - val_loss: 0.9941 - val_acc: 0.8661\n",
      "Epoch 277/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0608 - acc: 0.9826 - val_loss: 0.9087 - val_acc: 0.8801\n",
      "Epoch 278/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0163 - acc: 0.9971 - val_loss: 0.8804 - val_acc: 0.8834\n",
      "Epoch 279/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0091 - acc: 0.9992 - val_loss: 0.8838 - val_acc: 0.8840\n",
      "Epoch 280/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0079 - acc: 0.9996 - val_loss: 0.8970 - val_acc: 0.8839\n",
      "Epoch 281/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0076 - acc: 0.9997 - val_loss: 0.9059 - val_acc: 0.8810\n",
      "Epoch 282/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0078 - acc: 0.9996 - val_loss: 0.9145 - val_acc: 0.8813\n",
      "Epoch 283/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0620 - acc: 0.9820 - val_loss: 0.8888 - val_acc: 0.8777\n",
      "Epoch 284/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0393 - acc: 0.9882 - val_loss: 0.9560 - val_acc: 0.8722\n",
      "Epoch 285/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0203 - acc: 0.9953 - val_loss: 0.8894 - val_acc: 0.8818\n",
      "Epoch 286/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0107 - acc: 0.9987 - val_loss: 0.8967 - val_acc: 0.8823\n",
      "Epoch 287/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0146 - acc: 0.9973 - val_loss: 0.9118 - val_acc: 0.8808\n",
      "Epoch 288/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0090 - acc: 0.9994 - val_loss: 0.8968 - val_acc: 0.8843\n",
      "Epoch 289/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0073 - acc: 0.9996 - val_loss: 0.8911 - val_acc: 0.8852\n",
      "Epoch 290/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0078 - acc: 0.9996 - val_loss: 0.9138 - val_acc: 0.8825\n",
      "Epoch 291/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0975 - acc: 0.9730 - val_loss: 0.9702 - val_acc: 0.8703\n",
      "Epoch 292/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0373 - acc: 0.9902 - val_loss: 0.9071 - val_acc: 0.8793\n",
      "Epoch 293/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0102 - acc: 0.9991 - val_loss: 0.8929 - val_acc: 0.8830\n",
      "Epoch 294/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0077 - acc: 0.9996 - val_loss: 0.8955 - val_acc: 0.8850\n",
      "Epoch 295/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0071 - acc: 0.9996 - val_loss: 0.9053 - val_acc: 0.8865\n",
      "Epoch 296/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0077 - acc: 0.9993 - val_loss: 0.9043 - val_acc: 0.8831\n",
      "Epoch 297/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0079 - acc: 0.9996 - val_loss: 0.8985 - val_acc: 0.8864\n",
      "Epoch 298/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0075 - acc: 0.9994 - val_loss: 0.9028 - val_acc: 0.8828\n",
      "Epoch 299/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.1060 - acc: 0.9677 - val_loss: 0.9234 - val_acc: 0.8734\n",
      "Epoch 300/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0274 - acc: 0.9928 - val_loss: 0.9224 - val_acc: 0.8806\n",
      "Epoch 301/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0314 - acc: 0.9914 - val_loss: 0.9552 - val_acc: 0.8772\n",
      "Epoch 302/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0115 - acc: 0.9985 - val_loss: 0.9272 - val_acc: 0.8826\n",
      "Epoch 303/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0076 - acc: 0.9996 - val_loss: 0.9077 - val_acc: 0.8847\n",
      "Epoch 304/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0065 - acc: 0.9997 - val_loss: 0.9127 - val_acc: 0.8835\n",
      "Epoch 305/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0068 - acc: 0.9996 - val_loss: 0.9253 - val_acc: 0.8827\n",
      "Epoch 306/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0065 - acc: 0.9997 - val_loss: 0.9102 - val_acc: 0.8845\n",
      "Epoch 307/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0098 - acc: 0.9985 - val_loss: 0.9631 - val_acc: 0.8749\n",
      "Epoch 308/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1301 - acc: 0.9623 - val_loss: 0.9731 - val_acc: 0.8755\n",
      "Epoch 309/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0292 - acc: 0.9925 - val_loss: 0.9026 - val_acc: 0.8833\n",
      "Epoch 310/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0097 - acc: 0.9993 - val_loss: 0.9151 - val_acc: 0.8838\n",
      "Epoch 311/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0072 - acc: 0.9997 - val_loss: 0.9094 - val_acc: 0.8845\n",
      "Epoch 312/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0067 - acc: 0.9997 - val_loss: 0.9055 - val_acc: 0.8859\n",
      "Epoch 313/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0073 - acc: 0.9994 - val_loss: 0.9157 - val_acc: 0.8836\n",
      "Epoch 314/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0065 - acc: 0.9998 - val_loss: 0.9239 - val_acc: 0.8835\n",
      "Epoch 315/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0599 - acc: 0.9849 - val_loss: 1.1460 - val_acc: 0.8562\n",
      "Epoch 316/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0818 - acc: 0.9762 - val_loss: 0.9010 - val_acc: 0.8826\n",
      "Epoch 317/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0198 - acc: 0.9956 - val_loss: 0.9084 - val_acc: 0.8812\n",
      "Epoch 318/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0091 - acc: 0.9991 - val_loss: 0.9140 - val_acc: 0.8842\n",
      "Epoch 319/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0069 - acc: 0.9998 - val_loss: 0.9069 - val_acc: 0.8859\n",
      "Epoch 320/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0065 - acc: 0.9998 - val_loss: 0.9157 - val_acc: 0.8854\n",
      "Epoch 321/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0066 - acc: 0.9997 - val_loss: 0.9293 - val_acc: 0.8826\n",
      "Epoch 322/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0063 - acc: 0.9998 - val_loss: 0.9258 - val_acc: 0.8845\n",
      "Epoch 323/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0061 - acc: 0.9997 - val_loss: 0.9131 - val_acc: 0.8859\n",
      "Epoch 324/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0090 - acc: 0.9988 - val_loss: 1.0122 - val_acc: 0.8674\n",
      "Epoch 325/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.1121 - acc: 0.9674 - val_loss: 0.9752 - val_acc: 0.8735\n",
      "Epoch 326/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0205 - acc: 0.9952 - val_loss: 0.9088 - val_acc: 0.8838\n",
      "Epoch 327/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0092 - acc: 0.9993 - val_loss: 0.9204 - val_acc: 0.8843\n",
      "Epoch 328/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0162 - acc: 0.9965 - val_loss: 0.9199 - val_acc: 0.8825\n",
      "Epoch 329/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0082 - acc: 0.9993 - val_loss: 0.9114 - val_acc: 0.8859\n",
      "Epoch 330/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0060 - acc: 0.9998 - val_loss: 0.9184 - val_acc: 0.8858\n",
      "Epoch 331/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0066 - acc: 0.9995 - val_loss: 0.9279 - val_acc: 0.8850\n",
      "Epoch 332/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0865 - acc: 0.9748 - val_loss: 0.9967 - val_acc: 0.8703\n",
      "Epoch 333/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0310 - acc: 0.9914 - val_loss: 0.9090 - val_acc: 0.8834\n",
      "Epoch 334/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0086 - acc: 0.9993 - val_loss: 0.9151 - val_acc: 0.8837\n",
      "Epoch 335/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0067 - acc: 0.9997 - val_loss: 0.9184 - val_acc: 0.8855\n",
      "Epoch 336/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0066 - acc: 0.9996 - val_loss: 0.9166 - val_acc: 0.8843\n",
      "Epoch 337/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0058 - acc: 0.9998 - val_loss: 0.9255 - val_acc: 0.8855\n",
      "Epoch 338/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0268 - acc: 0.9934 - val_loss: 1.1939 - val_acc: 0.8439\n",
      "Epoch 339/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0877 - acc: 0.9740 - val_loss: 0.9399 - val_acc: 0.8772\n",
      "Epoch 340/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0115 - acc: 0.9984 - val_loss: 0.9317 - val_acc: 0.8826\n",
      "Epoch 341/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0094 - acc: 0.9989 - val_loss: 0.9360 - val_acc: 0.8845\n",
      "Epoch 342/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0068 - acc: 0.9997 - val_loss: 0.9217 - val_acc: 0.8850\n",
      "Epoch 343/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0060 - acc: 0.9999 - val_loss: 0.9288 - val_acc: 0.8845\n",
      "Epoch 344/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0060 - acc: 0.9997 - val_loss: 0.9531 - val_acc: 0.8816\n",
      "Epoch 345/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0488 - acc: 0.9873 - val_loss: 1.0424 - val_acc: 0.8624\n",
      "Epoch 346/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0780 - acc: 0.9772 - val_loss: 0.9373 - val_acc: 0.8801\n",
      "Epoch 347/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0137 - acc: 0.9974 - val_loss: 0.9246 - val_acc: 0.8850\n",
      "Epoch 348/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0065 - acc: 0.9997 - val_loss: 0.9182 - val_acc: 0.8864\n",
      "Epoch 349/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0055 - acc: 0.9998 - val_loss: 0.9207 - val_acc: 0.8863\n",
      "Epoch 350/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0053 - acc: 0.9998 - val_loss: 0.9213 - val_acc: 0.8864\n",
      "Epoch 351/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0053 - acc: 0.9999 - val_loss: 0.9306 - val_acc: 0.8856\n",
      "Epoch 352/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0051 - acc: 0.9998 - val_loss: 0.9270 - val_acc: 0.8873\n",
      "Epoch 353/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0051 - acc: 0.9999 - val_loss: 0.9331 - val_acc: 0.8854\n",
      "Epoch 354/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.1497 - acc: 0.9620 - val_loss: 0.9427 - val_acc: 0.8804\n",
      "Epoch 355/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0284 - acc: 0.9921 - val_loss: 0.9434 - val_acc: 0.8817\n",
      "Epoch 356/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0098 - acc: 0.9987 - val_loss: 0.9279 - val_acc: 0.8840\n",
      "Epoch 357/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0061 - acc: 0.9998 - val_loss: 0.9220 - val_acc: 0.8864\n",
      "Epoch 358/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0056 - acc: 0.9998 - val_loss: 0.9311 - val_acc: 0.8864\n",
      "Epoch 359/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0057 - acc: 0.9997 - val_loss: 0.9358 - val_acc: 0.8858\n",
      "Epoch 360/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0056 - acc: 0.9997 - val_loss: 0.9397 - val_acc: 0.8847\n",
      "Epoch 361/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0054 - acc: 0.9998 - val_loss: 0.9431 - val_acc: 0.8845\n",
      "Epoch 362/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0051 - acc: 0.9998 - val_loss: 0.9412 - val_acc: 0.8857\n",
      "Epoch 363/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0059 - acc: 0.9996 - val_loss: 0.9818 - val_acc: 0.8784\n",
      "Epoch 364/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.1357 - acc: 0.9641 - val_loss: 0.9997 - val_acc: 0.8666\n",
      "Epoch 365/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0258 - acc: 0.9926 - val_loss: 0.9688 - val_acc: 0.8779\n",
      "Epoch 366/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0130 - acc: 0.9974 - val_loss: 0.9562 - val_acc: 0.8801\n",
      "Epoch 367/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0068 - acc: 0.9997 - val_loss: 0.9409 - val_acc: 0.8838\n",
      "Epoch 368/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0055 - acc: 0.9998 - val_loss: 0.9449 - val_acc: 0.8836\n",
      "Epoch 369/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0052 - acc: 0.9998 - val_loss: 0.9430 - val_acc: 0.8840\n",
      "Epoch 370/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0052 - acc: 0.9998 - val_loss: 0.9409 - val_acc: 0.8849\n",
      "Epoch 371/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0050 - acc: 0.9999 - val_loss: 0.9421 - val_acc: 0.8847\n",
      "Epoch 372/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0052 - acc: 0.9998 - val_loss: 0.9481 - val_acc: 0.8842\n",
      "Epoch 373/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0672 - acc: 0.9837 - val_loss: 1.1765 - val_acc: 0.8506\n",
      "Epoch 374/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0698 - acc: 0.9785 - val_loss: 0.9651 - val_acc: 0.8763\n",
      "Epoch 375/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0198 - acc: 0.9952 - val_loss: 0.9343 - val_acc: 0.8831\n",
      "Epoch 376/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0077 - acc: 0.9993 - val_loss: 0.9468 - val_acc: 0.8842\n",
      "Epoch 377/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0118 - acc: 0.9977 - val_loss: 0.9398 - val_acc: 0.8854\n",
      "Epoch 378/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0063 - acc: 0.9996 - val_loss: 0.9401 - val_acc: 0.8846\n",
      "Epoch 379/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0051 - acc: 0.9998 - val_loss: 0.9401 - val_acc: 0.8849\n",
      "Epoch 380/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0049 - acc: 0.9997 - val_loss: 0.9426 - val_acc: 0.8875\n",
      "Epoch 381/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0761 - acc: 0.9779 - val_loss: 1.0249 - val_acc: 0.8701\n",
      "Epoch 382/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0356 - acc: 0.9897 - val_loss: 0.9492 - val_acc: 0.8821\n",
      "Epoch 383/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0087 - acc: 0.9990 - val_loss: 0.9331 - val_acc: 0.8873\n",
      "Epoch 384/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0055 - acc: 0.9998 - val_loss: 0.9363 - val_acc: 0.8865\n",
      "Epoch 385/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0051 - acc: 0.9998 - val_loss: 0.9462 - val_acc: 0.8860\n",
      "Epoch 386/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0048 - acc: 0.9999 - val_loss: 0.9506 - val_acc: 0.8864\n",
      "Epoch 387/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0048 - acc: 0.9998 - val_loss: 0.9544 - val_acc: 0.8837\n",
      "Epoch 388/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0048 - acc: 0.9998 - val_loss: 0.9533 - val_acc: 0.8859\n",
      "Epoch 389/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0047 - acc: 0.9999 - val_loss: 0.9538 - val_acc: 0.8850\n",
      "Epoch 390/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0819 - acc: 0.9797 - val_loss: 1.0671 - val_acc: 0.8623\n",
      "Epoch 391/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0648 - acc: 0.9801 - val_loss: 1.0025 - val_acc: 0.8757\n",
      "Epoch 392/500\n",
      "34108/34108 [==============================] - 1s 30us/step - loss: 0.0248 - acc: 0.9933 - val_loss: 0.9631 - val_acc: 0.8812\n",
      "Epoch 393/500\n",
      "34108/34108 [==============================] - 1s 31us/step - loss: 0.0097 - acc: 0.9987 - val_loss: 0.9537 - val_acc: 0.8844\n",
      "Epoch 394/500\n",
      "34108/34108 [==============================] - 1s 34us/step - loss: 0.0055 - acc: 0.9998 - val_loss: 0.9562 - val_acc: 0.8851\n",
      "Epoch 395/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0049 - acc: 0.9998 - val_loss: 0.9578 - val_acc: 0.8868\n",
      "Epoch 396/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0047 - acc: 0.9998 - val_loss: 0.9524 - val_acc: 0.8865\n",
      "Epoch 397/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0046 - acc: 0.9999 - val_loss: 0.9544 - val_acc: 0.8859\n",
      "Epoch 398/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0046 - acc: 0.9998 - val_loss: 0.9582 - val_acc: 0.8874\n",
      "Epoch 399/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0049 - acc: 0.9998 - val_loss: 0.9598 - val_acc: 0.8871\n",
      "Epoch 400/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0046 - acc: 0.9998 - val_loss: 0.9636 - val_acc: 0.8859\n",
      "Epoch 401/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1205 - acc: 0.9687 - val_loss: 1.1149 - val_acc: 0.8576\n",
      "Epoch 402/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0337 - acc: 0.9897 - val_loss: 0.9597 - val_acc: 0.8815\n",
      "Epoch 403/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0086 - acc: 0.9992 - val_loss: 0.9505 - val_acc: 0.8844\n",
      "Epoch 404/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0061 - acc: 0.9997 - val_loss: 0.9603 - val_acc: 0.8840\n",
      "Epoch 405/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0056 - acc: 0.9998 - val_loss: 0.9670 - val_acc: 0.8832\n",
      "Epoch 406/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0052 - acc: 0.9998 - val_loss: 0.9575 - val_acc: 0.8873\n",
      "Epoch 407/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0049 - acc: 0.9998 - val_loss: 0.9634 - val_acc: 0.8855\n",
      "Epoch 408/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0050 - acc: 0.9998 - val_loss: 0.9700 - val_acc: 0.8828\n",
      "Epoch 409/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0047 - acc: 0.9998 - val_loss: 0.9695 - val_acc: 0.8835\n",
      "Epoch 410/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0943 - acc: 0.9740 - val_loss: 1.0626 - val_acc: 0.8653\n",
      "Epoch 411/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0254 - acc: 0.9931 - val_loss: 0.9692 - val_acc: 0.8829\n",
      "Epoch 412/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0067 - acc: 0.9996 - val_loss: 0.9577 - val_acc: 0.8846\n",
      "Epoch 413/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0049 - acc: 0.9999 - val_loss: 0.9612 - val_acc: 0.8849\n",
      "Epoch 414/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0046 - acc: 0.9999 - val_loss: 0.9663 - val_acc: 0.8862\n",
      "Epoch 415/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0045 - acc: 0.9999 - val_loss: 0.9606 - val_acc: 0.8840\n",
      "Epoch 416/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0044 - acc: 0.9999 - val_loss: 0.9613 - val_acc: 0.8858\n",
      "Epoch 417/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0043 - acc: 0.9999 - val_loss: 0.9674 - val_acc: 0.8853\n",
      "Epoch 418/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0042 - acc: 0.9999 - val_loss: 0.9684 - val_acc: 0.8839\n",
      "Epoch 419/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0363 - acc: 0.9917 - val_loss: 1.3599 - val_acc: 0.8359\n",
      "Epoch 420/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.1025 - acc: 0.9717 - val_loss: 0.9824 - val_acc: 0.8782\n",
      "Epoch 421/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0246 - acc: 0.9938 - val_loss: 0.9857 - val_acc: 0.8817\n",
      "Epoch 422/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0095 - acc: 0.9988 - val_loss: 0.9659 - val_acc: 0.8858\n",
      "Epoch 423/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0055 - acc: 0.9998 - val_loss: 0.9803 - val_acc: 0.8850\n",
      "Epoch 424/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0055 - acc: 0.9997 - val_loss: 0.9744 - val_acc: 0.8818\n",
      "Epoch 425/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0048 - acc: 0.9999 - val_loss: 0.9773 - val_acc: 0.8856\n",
      "Epoch 426/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0044 - acc: 0.9998 - val_loss: 0.9849 - val_acc: 0.8850\n",
      "Epoch 427/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0043 - acc: 0.9999 - val_loss: 0.9828 - val_acc: 0.8863\n",
      "Epoch 428/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0044 - acc: 0.9999 - val_loss: 0.9805 - val_acc: 0.8859\n",
      "Epoch 429/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0044 - acc: 0.9998 - val_loss: 0.9904 - val_acc: 0.8858\n",
      "Epoch 430/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1010 - acc: 0.9729 - val_loss: 1.0548 - val_acc: 0.8654\n",
      "Epoch 431/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0546 - acc: 0.9827 - val_loss: 0.9777 - val_acc: 0.8822\n",
      "Epoch 432/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0138 - acc: 0.9970 - val_loss: 0.9644 - val_acc: 0.8836\n",
      "Epoch 433/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0059 - acc: 0.9996 - val_loss: 0.9756 - val_acc: 0.8855\n",
      "Epoch 434/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0047 - acc: 0.9999 - val_loss: 0.9716 - val_acc: 0.8855\n",
      "Epoch 435/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0044 - acc: 0.9998 - val_loss: 0.9769 - val_acc: 0.8847\n",
      "Epoch 436/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0042 - acc: 0.9999 - val_loss: 0.9818 - val_acc: 0.8843\n",
      "Epoch 437/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0042 - acc: 0.9999 - val_loss: 0.9868 - val_acc: 0.8845\n",
      "Epoch 438/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0042 - acc: 0.9999 - val_loss: 0.9809 - val_acc: 0.8851\n",
      "Epoch 439/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0042 - acc: 0.9998 - val_loss: 0.9985 - val_acc: 0.8826\n",
      "Epoch 440/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0046 - acc: 0.9999 - val_loss: 0.9868 - val_acc: 0.8841\n",
      "Epoch 441/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1222 - acc: 0.9668 - val_loss: 1.0158 - val_acc: 0.8737\n",
      "Epoch 442/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0272 - acc: 0.9927 - val_loss: 0.9819 - val_acc: 0.8813\n",
      "Epoch 443/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0140 - acc: 0.9969 - val_loss: 0.9835 - val_acc: 0.8827\n",
      "Epoch 444/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0099 - acc: 0.9983 - val_loss: 0.9805 - val_acc: 0.8830\n",
      "Epoch 445/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0052 - acc: 0.9998 - val_loss: 0.9769 - val_acc: 0.8837\n",
      "Epoch 446/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0045 - acc: 0.9999 - val_loss: 0.9774 - val_acc: 0.8850\n",
      "Epoch 447/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0045 - acc: 0.9997 - val_loss: 0.9837 - val_acc: 0.8835\n",
      "Epoch 448/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0052 - acc: 0.9997 - val_loss: 0.9788 - val_acc: 0.8851\n",
      "Epoch 449/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0051 - acc: 0.9997 - val_loss: 0.9778 - val_acc: 0.8848\n",
      "Epoch 450/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0043 - acc: 0.9999 - val_loss: 0.9880 - val_acc: 0.8841\n",
      "Epoch 451/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0853 - acc: 0.9795 - val_loss: 1.1330 - val_acc: 0.8562\n",
      "Epoch 452/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0549 - acc: 0.9833 - val_loss: 0.9911 - val_acc: 0.8783\n",
      "Epoch 453/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0089 - acc: 0.9989 - val_loss: 0.9736 - val_acc: 0.8818\n",
      "Epoch 454/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0052 - acc: 0.9998 - val_loss: 0.9764 - val_acc: 0.8840\n",
      "Epoch 455/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0046 - acc: 0.9998 - val_loss: 0.9731 - val_acc: 0.8845\n",
      "Epoch 456/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0043 - acc: 0.9999 - val_loss: 0.9831 - val_acc: 0.8832\n",
      "Epoch 457/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0043 - acc: 0.9999 - val_loss: 0.9869 - val_acc: 0.8834\n",
      "Epoch 458/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0041 - acc: 0.9999 - val_loss: 0.9851 - val_acc: 0.8843\n",
      "Epoch 459/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0040 - acc: 0.9999 - val_loss: 0.9875 - val_acc: 0.8854\n",
      "Epoch 460/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0041 - acc: 0.9999 - val_loss: 0.9967 - val_acc: 0.8839\n",
      "Epoch 461/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0041 - acc: 0.9999 - val_loss: 0.9934 - val_acc: 0.8828\n",
      "Epoch 462/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0049 - acc: 0.9997 - val_loss: 1.0648 - val_acc: 0.8797\n",
      "Epoch 463/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1686 - acc: 0.9582 - val_loss: 0.9910 - val_acc: 0.8788\n",
      "Epoch 464/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0235 - acc: 0.9931 - val_loss: 1.0199 - val_acc: 0.8782\n",
      "Epoch 465/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0101 - acc: 0.9985 - val_loss: 0.9944 - val_acc: 0.8826\n",
      "Epoch 466/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0084 - acc: 0.9989 - val_loss: 0.9805 - val_acc: 0.8844\n",
      "Epoch 467/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0094 - acc: 0.9982 - val_loss: 1.0153 - val_acc: 0.8794\n",
      "Epoch 468/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0342 - acc: 0.9899 - val_loss: 1.0379 - val_acc: 0.8760\n",
      "Epoch 469/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0193 - acc: 0.9948 - val_loss: 0.9986 - val_acc: 0.8828\n",
      "Epoch 470/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0065 - acc: 0.9993 - val_loss: 0.9878 - val_acc: 0.8848\n",
      "Epoch 471/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0043 - acc: 0.9999 - val_loss: 0.9927 - val_acc: 0.8848\n",
      "Epoch 472/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0040 - acc: 0.9999 - val_loss: 0.9911 - val_acc: 0.8859\n",
      "Epoch 473/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0039 - acc: 0.9999 - val_loss: 0.9966 - val_acc: 0.8850\n",
      "Epoch 474/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0038 - acc: 0.9999 - val_loss: 0.9986 - val_acc: 0.8836\n",
      "Epoch 475/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0037 - acc: 0.9999 - val_loss: 1.0013 - val_acc: 0.8837\n",
      "Epoch 476/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0037 - acc: 0.9999 - val_loss: 0.9984 - val_acc: 0.8840\n",
      "Epoch 477/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0038 - acc: 0.9999 - val_loss: 0.9956 - val_acc: 0.8848\n",
      "Epoch 478/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0039 - acc: 0.9999 - val_loss: 0.9905 - val_acc: 0.8845\n",
      "Epoch 479/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0403 - acc: 0.9912 - val_loss: 1.1947 - val_acc: 0.8578\n",
      "Epoch 480/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.1334 - acc: 0.9656 - val_loss: 1.0130 - val_acc: 0.8733\n",
      "Epoch 481/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0166 - acc: 0.9959 - val_loss: 0.9892 - val_acc: 0.8824\n",
      "Epoch 482/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0068 - acc: 0.9995 - val_loss: 1.0106 - val_acc: 0.8799\n",
      "Epoch 483/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0062 - acc: 0.9996 - val_loss: 1.0054 - val_acc: 0.8832\n",
      "Epoch 484/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0045 - acc: 0.9998 - val_loss: 1.0015 - val_acc: 0.8835\n",
      "Epoch 485/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0042 - acc: 0.9999 - val_loss: 1.0034 - val_acc: 0.8830\n",
      "Epoch 486/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0040 - acc: 0.9999 - val_loss: 0.9976 - val_acc: 0.8840\n",
      "Epoch 487/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0040 - acc: 0.9998 - val_loss: 1.0007 - val_acc: 0.8845\n",
      "Epoch 488/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0039 - acc: 0.9999 - val_loss: 1.0063 - val_acc: 0.8836\n",
      "Epoch 489/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0040 - acc: 0.9999 - val_loss: 0.9984 - val_acc: 0.8858\n",
      "Epoch 490/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0042 - acc: 0.9998 - val_loss: 1.0150 - val_acc: 0.8838\n",
      "Epoch 491/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.1194 - acc: 0.9692 - val_loss: 1.0235 - val_acc: 0.8776\n",
      "Epoch 492/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0354 - acc: 0.9900 - val_loss: 1.0514 - val_acc: 0.8732\n",
      "Epoch 493/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0166 - acc: 0.9959 - val_loss: 0.9980 - val_acc: 0.8831\n",
      "Epoch 494/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0062 - acc: 0.9996 - val_loss: 0.9993 - val_acc: 0.8829\n",
      "Epoch 495/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0043 - acc: 0.9999 - val_loss: 1.0035 - val_acc: 0.8836\n",
      "Epoch 496/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0040 - acc: 0.9999 - val_loss: 1.0067 - val_acc: 0.8833\n",
      "Epoch 497/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0039 - acc: 0.9999 - val_loss: 1.0086 - val_acc: 0.8834\n",
      "Epoch 498/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0039 - acc: 0.9999 - val_loss: 1.0074 - val_acc: 0.8844\n",
      "Epoch 499/500\n",
      "34108/34108 [==============================] - 1s 32us/step - loss: 0.0037 - acc: 0.9999 - val_loss: 1.0105 - val_acc: 0.8831\n",
      "Epoch 500/500\n",
      "34108/34108 [==============================] - 1s 33us/step - loss: 0.0038 - acc: 0.9999 - val_loss: 1.0097 - val_acc: 0.8836\n",
      "Train on 34108 samples, validate on 12117 samples\n",
      "Epoch 1/500\n",
      "34108/34108 [==============================] - 2s 55us/step - loss: 1.1638 - acc: 0.5604 - val_loss: 0.8799 - val_acc: 0.7277\n",
      "Epoch 2/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.7900 - acc: 0.7497 - val_loss: 0.7408 - val_acc: 0.7587\n",
      "Epoch 3/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.6755 - acc: 0.7887 - val_loss: 0.6668 - val_acc: 0.7968\n",
      "Epoch 4/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.6172 - acc: 0.8102 - val_loss: 0.6549 - val_acc: 0.8019\n",
      "Epoch 5/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.5756 - acc: 0.8220 - val_loss: 0.6291 - val_acc: 0.8018\n",
      "Epoch 6/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.5432 - acc: 0.8305 - val_loss: 0.6079 - val_acc: 0.8128\n",
      "Epoch 7/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.5140 - acc: 0.8410 - val_loss: 0.5744 - val_acc: 0.8292\n",
      "Epoch 8/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.4927 - acc: 0.8476 - val_loss: 0.5523 - val_acc: 0.8318\n",
      "Epoch 9/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.4693 - acc: 0.8562 - val_loss: 0.5344 - val_acc: 0.8387\n",
      "Epoch 10/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.4496 - acc: 0.8608 - val_loss: 0.5540 - val_acc: 0.8387\n",
      "Epoch 11/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.4379 - acc: 0.8660 - val_loss: 0.5305 - val_acc: 0.8452\n",
      "Epoch 12/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.4169 - acc: 0.8718 - val_loss: 0.5096 - val_acc: 0.8533\n",
      "Epoch 13/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.4058 - acc: 0.8756 - val_loss: 0.5613 - val_acc: 0.8412\n",
      "Epoch 14/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.3896 - acc: 0.8813 - val_loss: 0.5370 - val_acc: 0.8432\n",
      "Epoch 15/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.3859 - acc: 0.8828 - val_loss: 0.4938 - val_acc: 0.8604\n",
      "Epoch 16/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.3687 - acc: 0.8878 - val_loss: 0.5026 - val_acc: 0.8577\n",
      "Epoch 17/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.3594 - acc: 0.8907 - val_loss: 0.4744 - val_acc: 0.8644\n",
      "Epoch 18/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.3443 - acc: 0.8961 - val_loss: 0.5066 - val_acc: 0.8618\n",
      "Epoch 19/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.3407 - acc: 0.8963 - val_loss: 0.4878 - val_acc: 0.8647\n",
      "Epoch 20/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.3298 - acc: 0.8994 - val_loss: 0.5346 - val_acc: 0.8564\n",
      "Epoch 21/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.3233 - acc: 0.9005 - val_loss: 0.4782 - val_acc: 0.8669\n",
      "Epoch 22/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.3125 - acc: 0.9042 - val_loss: 0.4864 - val_acc: 0.8707\n",
      "Epoch 23/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.3093 - acc: 0.9049 - val_loss: 0.4858 - val_acc: 0.8677\n",
      "Epoch 24/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.3007 - acc: 0.9078 - val_loss: 0.4893 - val_acc: 0.8674\n",
      "Epoch 25/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.2899 - acc: 0.9131 - val_loss: 0.4880 - val_acc: 0.8703\n",
      "Epoch 26/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.2919 - acc: 0.9094 - val_loss: 0.4750 - val_acc: 0.8739\n",
      "Epoch 27/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.2775 - acc: 0.9151 - val_loss: 0.4865 - val_acc: 0.8751\n",
      "Epoch 28/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.2746 - acc: 0.9154 - val_loss: 0.4801 - val_acc: 0.8743\n",
      "Epoch 29/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.2695 - acc: 0.9176 - val_loss: 0.4833 - val_acc: 0.8746\n",
      "Epoch 30/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.2650 - acc: 0.9181 - val_loss: 0.4687 - val_acc: 0.8784\n",
      "Epoch 31/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.2593 - acc: 0.9212 - val_loss: 0.4726 - val_acc: 0.8803\n",
      "Epoch 32/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.2580 - acc: 0.9204 - val_loss: 0.4789 - val_acc: 0.8774\n",
      "Epoch 33/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.2476 - acc: 0.9238 - val_loss: 0.5036 - val_acc: 0.8706\n",
      "Epoch 34/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.2430 - acc: 0.9258 - val_loss: 0.4880 - val_acc: 0.8793\n",
      "Epoch 35/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.2361 - acc: 0.9283 - val_loss: 0.4775 - val_acc: 0.8786\n",
      "Epoch 36/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.2280 - acc: 0.9314 - val_loss: 0.4797 - val_acc: 0.8817\n",
      "Epoch 37/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.2300 - acc: 0.9301 - val_loss: 0.4884 - val_acc: 0.8766\n",
      "Epoch 38/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.2233 - acc: 0.9314 - val_loss: 0.5037 - val_acc: 0.8769\n",
      "Epoch 39/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.2221 - acc: 0.9311 - val_loss: 0.4705 - val_acc: 0.8835\n",
      "Epoch 40/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.2126 - acc: 0.9350 - val_loss: 0.4795 - val_acc: 0.8837\n",
      "Epoch 41/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.2075 - acc: 0.9377 - val_loss: 0.4779 - val_acc: 0.8847\n",
      "Epoch 42/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.2053 - acc: 0.9384 - val_loss: 0.4904 - val_acc: 0.8793\n",
      "Epoch 43/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.2045 - acc: 0.9374 - val_loss: 0.4901 - val_acc: 0.8812\n",
      "Epoch 44/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.2046 - acc: 0.9366 - val_loss: 0.4726 - val_acc: 0.8858\n",
      "Epoch 45/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1940 - acc: 0.9405 - val_loss: 0.4973 - val_acc: 0.8810\n",
      "Epoch 46/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1889 - acc: 0.9424 - val_loss: 0.4947 - val_acc: 0.8841\n",
      "Epoch 47/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.1866 - acc: 0.9439 - val_loss: 0.5149 - val_acc: 0.8802\n",
      "Epoch 48/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.1801 - acc: 0.9450 - val_loss: 0.5073 - val_acc: 0.8797\n",
      "Epoch 49/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1826 - acc: 0.9445 - val_loss: 0.5073 - val_acc: 0.8790\n",
      "Epoch 50/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.1793 - acc: 0.9462 - val_loss: 0.4961 - val_acc: 0.8859\n",
      "Epoch 51/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1772 - acc: 0.9465 - val_loss: 0.5350 - val_acc: 0.8747\n",
      "Epoch 52/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.1735 - acc: 0.9459 - val_loss: 0.5078 - val_acc: 0.8823\n",
      "Epoch 53/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1674 - acc: 0.9490 - val_loss: 0.5177 - val_acc: 0.8812\n",
      "Epoch 54/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1678 - acc: 0.9479 - val_loss: 0.5274 - val_acc: 0.8774\n",
      "Epoch 55/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.1595 - acc: 0.9528 - val_loss: 0.5215 - val_acc: 0.8802\n",
      "Epoch 56/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.1592 - acc: 0.9517 - val_loss: 0.5406 - val_acc: 0.8818\n",
      "Epoch 57/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.1576 - acc: 0.9520 - val_loss: 0.5388 - val_acc: 0.8791\n",
      "Epoch 58/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.1505 - acc: 0.9546 - val_loss: 0.5318 - val_acc: 0.8826\n",
      "Epoch 59/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.1518 - acc: 0.9545 - val_loss: 0.5241 - val_acc: 0.8852\n",
      "Epoch 60/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.1526 - acc: 0.9522 - val_loss: 0.5270 - val_acc: 0.8836\n",
      "Epoch 61/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1488 - acc: 0.9544 - val_loss: 0.5640 - val_acc: 0.8732\n",
      "Epoch 62/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1492 - acc: 0.9538 - val_loss: 0.5411 - val_acc: 0.8816\n",
      "Epoch 63/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1384 - acc: 0.9576 - val_loss: 0.5359 - val_acc: 0.8840\n",
      "Epoch 64/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.1350 - acc: 0.9588 - val_loss: 0.5379 - val_acc: 0.8859\n",
      "Epoch 65/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1366 - acc: 0.9588 - val_loss: 0.5476 - val_acc: 0.8797\n",
      "Epoch 66/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.1350 - acc: 0.9576 - val_loss: 0.5362 - val_acc: 0.8859\n",
      "Epoch 67/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1327 - acc: 0.9589 - val_loss: 0.5800 - val_acc: 0.8735\n",
      "Epoch 68/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.1338 - acc: 0.9597 - val_loss: 0.5879 - val_acc: 0.8764\n",
      "Epoch 69/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1295 - acc: 0.9599 - val_loss: 0.5695 - val_acc: 0.8804\n",
      "Epoch 70/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.1267 - acc: 0.9607 - val_loss: 0.5545 - val_acc: 0.8844\n",
      "Epoch 71/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1283 - acc: 0.9621 - val_loss: 0.5700 - val_acc: 0.8814\n",
      "Epoch 72/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1214 - acc: 0.9632 - val_loss: 0.6048 - val_acc: 0.8769\n",
      "Epoch 73/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.1194 - acc: 0.9634 - val_loss: 0.5784 - val_acc: 0.8802\n",
      "Epoch 74/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1176 - acc: 0.9647 - val_loss: 0.5759 - val_acc: 0.8836\n",
      "Epoch 75/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1112 - acc: 0.9669 - val_loss: 0.5589 - val_acc: 0.8882\n",
      "Epoch 76/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1112 - acc: 0.9675 - val_loss: 0.5774 - val_acc: 0.8809\n",
      "Epoch 77/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1088 - acc: 0.9677 - val_loss: 0.5788 - val_acc: 0.8821\n",
      "Epoch 78/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.1066 - acc: 0.9683 - val_loss: 0.6234 - val_acc: 0.8769\n",
      "Epoch 79/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.1163 - acc: 0.9645 - val_loss: 0.6150 - val_acc: 0.8758\n",
      "Epoch 80/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.1076 - acc: 0.9688 - val_loss: 0.5813 - val_acc: 0.8846\n",
      "Epoch 81/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1077 - acc: 0.9669 - val_loss: 0.6383 - val_acc: 0.8720\n",
      "Epoch 82/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1021 - acc: 0.9703 - val_loss: 0.5888 - val_acc: 0.8859\n",
      "Epoch 83/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1020 - acc: 0.9701 - val_loss: 0.5847 - val_acc: 0.8870\n",
      "Epoch 84/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0986 - acc: 0.9708 - val_loss: 0.6064 - val_acc: 0.8831\n",
      "Epoch 85/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0994 - acc: 0.9707 - val_loss: 0.6554 - val_acc: 0.8692\n",
      "Epoch 86/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0951 - acc: 0.9730 - val_loss: 0.6304 - val_acc: 0.8798\n",
      "Epoch 87/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0927 - acc: 0.9738 - val_loss: 0.6026 - val_acc: 0.8836\n",
      "Epoch 88/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0901 - acc: 0.9749 - val_loss: 0.6332 - val_acc: 0.8794\n",
      "Epoch 89/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0916 - acc: 0.9733 - val_loss: 0.6298 - val_acc: 0.8831\n",
      "Epoch 90/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0898 - acc: 0.9746 - val_loss: 0.6156 - val_acc: 0.8869\n",
      "Epoch 91/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1028 - acc: 0.9692 - val_loss: 0.6373 - val_acc: 0.8809\n",
      "Epoch 92/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0951 - acc: 0.9721 - val_loss: 0.6413 - val_acc: 0.8796\n",
      "Epoch 93/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0887 - acc: 0.9731 - val_loss: 0.6490 - val_acc: 0.8814\n",
      "Epoch 94/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0789 - acc: 0.9786 - val_loss: 0.6146 - val_acc: 0.8864\n",
      "Epoch 95/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0829 - acc: 0.9765 - val_loss: 0.6797 - val_acc: 0.8743\n",
      "Epoch 96/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0892 - acc: 0.9741 - val_loss: 0.6455 - val_acc: 0.8803\n",
      "Epoch 97/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0945 - acc: 0.9719 - val_loss: 0.6317 - val_acc: 0.8861\n",
      "Epoch 98/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0745 - acc: 0.9800 - val_loss: 0.6292 - val_acc: 0.8840\n",
      "Epoch 99/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0815 - acc: 0.9764 - val_loss: 0.6629 - val_acc: 0.8784\n",
      "Epoch 100/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0837 - acc: 0.9754 - val_loss: 0.6545 - val_acc: 0.8821\n",
      "Epoch 101/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0851 - acc: 0.9751 - val_loss: 0.6543 - val_acc: 0.8837\n",
      "Epoch 102/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0909 - acc: 0.9722 - val_loss: 0.6614 - val_acc: 0.8788\n",
      "Epoch 103/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0723 - acc: 0.9797 - val_loss: 0.6923 - val_acc: 0.8778\n",
      "Epoch 104/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0716 - acc: 0.9796 - val_loss: 0.6501 - val_acc: 0.8864\n",
      "Epoch 105/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0708 - acc: 0.9801 - val_loss: 0.6523 - val_acc: 0.8851\n",
      "Epoch 106/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0741 - acc: 0.9793 - val_loss: 0.6497 - val_acc: 0.8853\n",
      "Epoch 107/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0747 - acc: 0.9779 - val_loss: 0.6782 - val_acc: 0.8840\n",
      "Epoch 108/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0661 - acc: 0.9821 - val_loss: 0.6523 - val_acc: 0.8865\n",
      "Epoch 109/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0721 - acc: 0.9797 - val_loss: 0.6939 - val_acc: 0.8786\n",
      "Epoch 110/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0651 - acc: 0.9828 - val_loss: 0.6788 - val_acc: 0.8822\n",
      "Epoch 111/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0786 - acc: 0.9767 - val_loss: 0.6854 - val_acc: 0.8821\n",
      "Epoch 112/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0736 - acc: 0.9776 - val_loss: 0.6635 - val_acc: 0.8806\n",
      "Epoch 113/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0664 - acc: 0.9814 - val_loss: 0.6660 - val_acc: 0.8860\n",
      "Epoch 114/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0664 - acc: 0.9811 - val_loss: 0.6948 - val_acc: 0.8808\n",
      "Epoch 115/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0702 - acc: 0.9798 - val_loss: 0.6569 - val_acc: 0.8901\n",
      "Epoch 116/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0614 - acc: 0.9836 - val_loss: 0.7019 - val_acc: 0.8773\n",
      "Epoch 117/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0754 - acc: 0.9773 - val_loss: 0.6974 - val_acc: 0.8800\n",
      "Epoch 118/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0576 - acc: 0.9852 - val_loss: 0.6818 - val_acc: 0.8845\n",
      "Epoch 119/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0577 - acc: 0.9843 - val_loss: 0.7105 - val_acc: 0.8826\n",
      "Epoch 120/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0605 - acc: 0.9837 - val_loss: 0.7108 - val_acc: 0.8845\n",
      "Epoch 121/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0746 - acc: 0.9776 - val_loss: 0.7004 - val_acc: 0.8785\n",
      "Epoch 122/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0690 - acc: 0.9797 - val_loss: 0.7039 - val_acc: 0.8795\n",
      "Epoch 123/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0545 - acc: 0.9851 - val_loss: 0.6899 - val_acc: 0.8872\n",
      "Epoch 124/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0641 - acc: 0.9812 - val_loss: 0.6932 - val_acc: 0.8836\n",
      "Epoch 125/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0536 - acc: 0.9865 - val_loss: 0.7209 - val_acc: 0.8821\n",
      "Epoch 126/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0475 - acc: 0.9883 - val_loss: 0.7359 - val_acc: 0.8798\n",
      "Epoch 127/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0537 - acc: 0.9859 - val_loss: 0.7590 - val_acc: 0.8754\n",
      "Epoch 128/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0848 - acc: 0.9727 - val_loss: 0.7329 - val_acc: 0.8793\n",
      "Epoch 129/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0541 - acc: 0.9860 - val_loss: 0.7349 - val_acc: 0.8815\n",
      "Epoch 130/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0475 - acc: 0.9886 - val_loss: 0.7213 - val_acc: 0.8834\n",
      "Epoch 131/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0536 - acc: 0.9853 - val_loss: 0.7268 - val_acc: 0.8844\n",
      "Epoch 132/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0482 - acc: 0.9875 - val_loss: 0.7354 - val_acc: 0.8813\n",
      "Epoch 133/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0628 - acc: 0.9815 - val_loss: 0.7318 - val_acc: 0.8831\n",
      "Epoch 134/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0449 - acc: 0.9892 - val_loss: 0.7134 - val_acc: 0.8880\n",
      "Epoch 135/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0476 - acc: 0.9874 - val_loss: 0.7575 - val_acc: 0.8840\n",
      "Epoch 136/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0531 - acc: 0.9855 - val_loss: 0.7600 - val_acc: 0.8821\n",
      "Epoch 137/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0570 - acc: 0.9843 - val_loss: 0.7285 - val_acc: 0.8852\n",
      "Epoch 138/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0474 - acc: 0.9877 - val_loss: 0.7520 - val_acc: 0.8799\n",
      "Epoch 139/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0756 - acc: 0.9771 - val_loss: 0.7594 - val_acc: 0.8812\n",
      "Epoch 140/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0543 - acc: 0.9848 - val_loss: 0.7521 - val_acc: 0.8838\n",
      "Epoch 141/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0346 - acc: 0.9929 - val_loss: 0.7427 - val_acc: 0.8819\n",
      "Epoch 142/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0473 - acc: 0.9878 - val_loss: 0.7421 - val_acc: 0.8855\n",
      "Epoch 143/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0426 - acc: 0.9890 - val_loss: 0.7808 - val_acc: 0.8762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0633 - acc: 0.9814 - val_loss: 0.7657 - val_acc: 0.8812\n",
      "Epoch 145/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0558 - acc: 0.9850 - val_loss: 0.7600 - val_acc: 0.8825\n",
      "Epoch 146/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0575 - acc: 0.9828 - val_loss: 0.7901 - val_acc: 0.8783\n",
      "Epoch 147/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0484 - acc: 0.9874 - val_loss: 0.7705 - val_acc: 0.8819\n",
      "Epoch 148/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0317 - acc: 0.9935 - val_loss: 0.7547 - val_acc: 0.8865\n",
      "Epoch 149/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0361 - acc: 0.9915 - val_loss: 0.8146 - val_acc: 0.8760\n",
      "Epoch 150/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0604 - acc: 0.9812 - val_loss: 0.7695 - val_acc: 0.8826\n",
      "Epoch 151/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0439 - acc: 0.9890 - val_loss: 0.7935 - val_acc: 0.8801\n",
      "Epoch 152/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0758 - acc: 0.9753 - val_loss: 0.7728 - val_acc: 0.8807\n",
      "Epoch 153/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0357 - acc: 0.9914 - val_loss: 0.7693 - val_acc: 0.8865\n",
      "Epoch 154/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0298 - acc: 0.9937 - val_loss: 0.7902 - val_acc: 0.8828\n",
      "Epoch 155/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0655 - acc: 0.9796 - val_loss: 0.8029 - val_acc: 0.8788\n",
      "Epoch 156/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0415 - acc: 0.9901 - val_loss: 0.7641 - val_acc: 0.8859\n",
      "Epoch 157/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0282 - acc: 0.9943 - val_loss: 0.7761 - val_acc: 0.8848\n",
      "Epoch 158/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0435 - acc: 0.9883 - val_loss: 0.8702 - val_acc: 0.8651\n",
      "Epoch 159/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0468 - acc: 0.9871 - val_loss: 0.8177 - val_acc: 0.8779\n",
      "Epoch 160/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0633 - acc: 0.9812 - val_loss: 0.8396 - val_acc: 0.8718\n",
      "Epoch 161/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0402 - acc: 0.9902 - val_loss: 0.7831 - val_acc: 0.8845\n",
      "Epoch 162/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0269 - acc: 0.9948 - val_loss: 0.7850 - val_acc: 0.8842\n",
      "Epoch 163/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0309 - acc: 0.9931 - val_loss: 0.7951 - val_acc: 0.8831\n",
      "Epoch 164/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0464 - acc: 0.9883 - val_loss: 0.8191 - val_acc: 0.8798\n",
      "Epoch 165/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0505 - acc: 0.9851 - val_loss: 0.8297 - val_acc: 0.8740\n",
      "Epoch 166/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0443 - acc: 0.9878 - val_loss: 0.7936 - val_acc: 0.8833\n",
      "Epoch 167/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0375 - acc: 0.9907 - val_loss: 0.7864 - val_acc: 0.8845\n",
      "Epoch 168/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0327 - acc: 0.9923 - val_loss: 0.7875 - val_acc: 0.8849\n",
      "Epoch 169/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0263 - acc: 0.9941 - val_loss: 0.7842 - val_acc: 0.8852\n",
      "Epoch 170/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0413 - acc: 0.9884 - val_loss: 0.8386 - val_acc: 0.8766\n",
      "Epoch 171/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0881 - acc: 0.9723 - val_loss: 0.8434 - val_acc: 0.8686\n",
      "Epoch 172/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0498 - acc: 0.9863 - val_loss: 0.7848 - val_acc: 0.8862\n",
      "Epoch 173/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0222 - acc: 0.9963 - val_loss: 0.7928 - val_acc: 0.8859\n",
      "Epoch 174/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0211 - acc: 0.9965 - val_loss: 0.8287 - val_acc: 0.8806\n",
      "Epoch 175/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0492 - acc: 0.9858 - val_loss: 0.8218 - val_acc: 0.8803\n",
      "Epoch 176/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0320 - acc: 0.9922 - val_loss: 0.8152 - val_acc: 0.8811\n",
      "Epoch 177/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0304 - acc: 0.9931 - val_loss: 0.8283 - val_acc: 0.8789\n",
      "Epoch 178/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0330 - acc: 0.9922 - val_loss: 0.8267 - val_acc: 0.8816\n",
      "Epoch 179/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0664 - acc: 0.9794 - val_loss: 0.8170 - val_acc: 0.8775\n",
      "Epoch 180/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0345 - acc: 0.9919 - val_loss: 0.8111 - val_acc: 0.8859\n",
      "Epoch 181/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0209 - acc: 0.9967 - val_loss: 0.8133 - val_acc: 0.8873\n",
      "Epoch 182/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0203 - acc: 0.9966 - val_loss: 0.8314 - val_acc: 0.8819\n",
      "Epoch 183/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0831 - acc: 0.9743 - val_loss: 0.8349 - val_acc: 0.8769\n",
      "Epoch 184/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0335 - acc: 0.9916 - val_loss: 0.8445 - val_acc: 0.8796\n",
      "Epoch 185/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0239 - acc: 0.9956 - val_loss: 0.8169 - val_acc: 0.8849\n",
      "Epoch 186/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0276 - acc: 0.9943 - val_loss: 0.8256 - val_acc: 0.8817\n",
      "Epoch 187/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0400 - acc: 0.9893 - val_loss: 0.9550 - val_acc: 0.8571\n",
      "Epoch 188/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0650 - acc: 0.9808 - val_loss: 0.8073 - val_acc: 0.8844\n",
      "Epoch 189/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0194 - acc: 0.9974 - val_loss: 0.8374 - val_acc: 0.8832\n",
      "Epoch 190/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0179 - acc: 0.9974 - val_loss: 0.8330 - val_acc: 0.8820\n",
      "Epoch 191/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0211 - acc: 0.9964 - val_loss: 0.8556 - val_acc: 0.8825\n",
      "Epoch 192/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0473 - acc: 0.9862 - val_loss: 0.9117 - val_acc: 0.8687\n",
      "Epoch 193/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0712 - acc: 0.9782 - val_loss: 0.8423 - val_acc: 0.8783\n",
      "Epoch 194/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0243 - acc: 0.9950 - val_loss: 0.8328 - val_acc: 0.8831\n",
      "Epoch 195/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0159 - acc: 0.9980 - val_loss: 0.8254 - val_acc: 0.8853\n",
      "Epoch 196/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0163 - acc: 0.9977 - val_loss: 0.8342 - val_acc: 0.8850\n",
      "Epoch 197/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0241 - acc: 0.9950 - val_loss: 0.8772 - val_acc: 0.8774\n",
      "Epoch 198/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0843 - acc: 0.9731 - val_loss: 0.8486 - val_acc: 0.8793\n",
      "Epoch 199/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0382 - acc: 0.9899 - val_loss: 0.8394 - val_acc: 0.8831\n",
      "Epoch 200/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0176 - acc: 0.9975 - val_loss: 0.8316 - val_acc: 0.8843\n",
      "Epoch 201/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0162 - acc: 0.9977 - val_loss: 0.8461 - val_acc: 0.8836\n",
      "Epoch 202/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0258 - acc: 0.9939 - val_loss: 0.8469 - val_acc: 0.8779\n",
      "Epoch 203/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0883 - acc: 0.9728 - val_loss: 0.8460 - val_acc: 0.8799\n",
      "Epoch 204/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0446 - acc: 0.9882 - val_loss: 0.8367 - val_acc: 0.8819\n",
      "Epoch 205/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0254 - acc: 0.9943 - val_loss: 0.8416 - val_acc: 0.8836\n",
      "Epoch 206/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0158 - acc: 0.9982 - val_loss: 0.8483 - val_acc: 0.8840\n",
      "Epoch 207/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0130 - acc: 0.9988 - val_loss: 0.8357 - val_acc: 0.8862\n",
      "Epoch 208/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0166 - acc: 0.9972 - val_loss: 0.8537 - val_acc: 0.8841\n",
      "Epoch 209/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1019 - acc: 0.9688 - val_loss: 0.8977 - val_acc: 0.8724\n",
      "Epoch 210/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0281 - acc: 0.9939 - val_loss: 0.8309 - val_acc: 0.8851\n",
      "Epoch 211/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0147 - acc: 0.9984 - val_loss: 0.8397 - val_acc: 0.8844\n",
      "Epoch 212/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0159 - acc: 0.9978 - val_loss: 0.8496 - val_acc: 0.8829\n",
      "Epoch 213/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0177 - acc: 0.9969 - val_loss: 0.8741 - val_acc: 0.8824\n",
      "Epoch 214/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0672 - acc: 0.9781 - val_loss: 0.8897 - val_acc: 0.8759\n",
      "Epoch 215/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0387 - acc: 0.9895 - val_loss: 0.8434 - val_acc: 0.8854\n",
      "Epoch 216/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0137 - acc: 0.9986 - val_loss: 0.8515 - val_acc: 0.8855\n",
      "Epoch 217/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0122 - acc: 0.9988 - val_loss: 0.8706 - val_acc: 0.8834\n",
      "Epoch 218/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0546 - acc: 0.9835 - val_loss: 0.9549 - val_acc: 0.8708\n",
      "Epoch 219/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0537 - acc: 0.9837 - val_loss: 0.8934 - val_acc: 0.8760\n",
      "Epoch 220/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0213 - acc: 0.9959 - val_loss: 0.8731 - val_acc: 0.8808\n",
      "Epoch 221/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0153 - acc: 0.9978 - val_loss: 0.8619 - val_acc: 0.8829\n",
      "Epoch 222/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0124 - acc: 0.9989 - val_loss: 0.8566 - val_acc: 0.8859\n",
      "Epoch 223/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0125 - acc: 0.9988 - val_loss: 0.8642 - val_acc: 0.8854\n",
      "Epoch 224/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0452 - acc: 0.9867 - val_loss: 0.9181 - val_acc: 0.8691\n",
      "Epoch 225/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0606 - acc: 0.9817 - val_loss: 0.8665 - val_acc: 0.8805\n",
      "Epoch 226/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0200 - acc: 0.9962 - val_loss: 0.8666 - val_acc: 0.8855\n",
      "Epoch 227/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0134 - acc: 0.9985 - val_loss: 0.9048 - val_acc: 0.8801\n",
      "Epoch 228/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0132 - acc: 0.9984 - val_loss: 0.8699 - val_acc: 0.8845\n",
      "Epoch 229/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0136 - acc: 0.9983 - val_loss: 0.8788 - val_acc: 0.8851\n",
      "Epoch 230/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0878 - acc: 0.9748 - val_loss: 0.9459 - val_acc: 0.8671\n",
      "Epoch 231/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0545 - acc: 0.9841 - val_loss: 0.8534 - val_acc: 0.8822\n",
      "Epoch 232/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0174 - acc: 0.9973 - val_loss: 0.8630 - val_acc: 0.8846\n",
      "Epoch 233/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0122 - acc: 0.9989 - val_loss: 0.8682 - val_acc: 0.8850\n",
      "Epoch 234/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0115 - acc: 0.9992 - val_loss: 0.8628 - val_acc: 0.8865\n",
      "Epoch 235/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0114 - acc: 0.9989 - val_loss: 0.8840 - val_acc: 0.8818\n",
      "Epoch 236/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0617 - acc: 0.9823 - val_loss: 0.9189 - val_acc: 0.8752\n",
      "Epoch 237/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0523 - acc: 0.9850 - val_loss: 0.8620 - val_acc: 0.8801\n",
      "Epoch 238/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0197 - acc: 0.9962 - val_loss: 0.8580 - val_acc: 0.8869\n",
      "Epoch 239/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0159 - acc: 0.9974 - val_loss: 0.8671 - val_acc: 0.8846\n",
      "Epoch 240/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0110 - acc: 0.9991 - val_loss: 0.8722 - val_acc: 0.8850\n",
      "Epoch 241/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0103 - acc: 0.9992 - val_loss: 0.8868 - val_acc: 0.8830\n",
      "Epoch 242/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0567 - acc: 0.9850 - val_loss: 0.9927 - val_acc: 0.8563\n",
      "Epoch 243/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0586 - acc: 0.9825 - val_loss: 0.8993 - val_acc: 0.8811\n",
      "Epoch 244/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0284 - acc: 0.9931 - val_loss: 0.8838 - val_acc: 0.8845\n",
      "Epoch 245/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0166 - acc: 0.9970 - val_loss: 0.8761 - val_acc: 0.8842\n",
      "Epoch 246/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0171 - acc: 0.9969 - val_loss: 0.8587 - val_acc: 0.8878\n",
      "Epoch 247/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0113 - acc: 0.9990 - val_loss: 0.8733 - val_acc: 0.8871\n",
      "Epoch 248/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0098 - acc: 0.9993 - val_loss: 0.8730 - val_acc: 0.8856\n",
      "Epoch 249/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0099 - acc: 0.9992 - val_loss: 0.8830 - val_acc: 0.8865\n",
      "Epoch 250/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0830 - acc: 0.9768 - val_loss: 1.0183 - val_acc: 0.8632\n",
      "Epoch 251/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0702 - acc: 0.9787 - val_loss: 0.9053 - val_acc: 0.8769\n",
      "Epoch 252/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0166 - acc: 0.9974 - val_loss: 0.9224 - val_acc: 0.8793\n",
      "Epoch 253/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0102 - acc: 0.9992 - val_loss: 0.8951 - val_acc: 0.8847\n",
      "Epoch 254/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0093 - acc: 0.9995 - val_loss: 0.8934 - val_acc: 0.8864\n",
      "Epoch 255/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0097 - acc: 0.9994 - val_loss: 0.9041 - val_acc: 0.8851\n",
      "Epoch 256/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0184 - acc: 0.9960 - val_loss: 0.9781 - val_acc: 0.8718\n",
      "Epoch 257/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0988 - acc: 0.9710 - val_loss: 0.9075 - val_acc: 0.8769\n",
      "Epoch 258/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0348 - acc: 0.9907 - val_loss: 0.8753 - val_acc: 0.8830\n",
      "Epoch 259/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0134 - acc: 0.9985 - val_loss: 0.8863 - val_acc: 0.8835\n",
      "Epoch 260/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0106 - acc: 0.9990 - val_loss: 0.8863 - val_acc: 0.8852\n",
      "Epoch 261/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0358 - acc: 0.9896 - val_loss: 0.8855 - val_acc: 0.8825\n",
      "Epoch 262/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0298 - acc: 0.9920 - val_loss: 0.9175 - val_acc: 0.8799\n",
      "Epoch 263/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0278 - acc: 0.9929 - val_loss: 0.8854 - val_acc: 0.8847\n",
      "Epoch 264/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0102 - acc: 0.9991 - val_loss: 0.8909 - val_acc: 0.8859\n",
      "Epoch 265/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0090 - acc: 0.9994 - val_loss: 0.8987 - val_acc: 0.8859\n",
      "Epoch 266/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0096 - acc: 0.9993 - val_loss: 0.8981 - val_acc: 0.8831\n",
      "Epoch 267/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0100 - acc: 0.9991 - val_loss: 0.9200 - val_acc: 0.8799\n",
      "Epoch 268/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1211 - acc: 0.9673 - val_loss: 0.8916 - val_acc: 0.8748\n",
      "Epoch 269/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0303 - acc: 0.9924 - val_loss: 0.8955 - val_acc: 0.8826\n",
      "Epoch 270/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0154 - acc: 0.9979 - val_loss: 0.8988 - val_acc: 0.8826\n",
      "Epoch 271/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0112 - acc: 0.9990 - val_loss: 0.9119 - val_acc: 0.8822\n",
      "Epoch 272/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0095 - acc: 0.9995 - val_loss: 0.9129 - val_acc: 0.8851\n",
      "Epoch 273/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0103 - acc: 0.9993 - val_loss: 0.9006 - val_acc: 0.8865\n",
      "Epoch 274/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0323 - acc: 0.9924 - val_loss: 1.0277 - val_acc: 0.8595\n",
      "Epoch 275/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0814 - acc: 0.9750 - val_loss: 0.9477 - val_acc: 0.8764\n",
      "Epoch 276/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0270 - acc: 0.9929 - val_loss: 0.9069 - val_acc: 0.8832\n",
      "Epoch 277/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0113 - acc: 0.9991 - val_loss: 0.9107 - val_acc: 0.8829\n",
      "Epoch 278/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0089 - acc: 0.9995 - val_loss: 0.8974 - val_acc: 0.8873\n",
      "Epoch 279/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0082 - acc: 0.9996 - val_loss: 0.9206 - val_acc: 0.8843\n",
      "Epoch 280/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0082 - acc: 0.9996 - val_loss: 0.9114 - val_acc: 0.8831\n",
      "Epoch 281/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0080 - acc: 0.9997 - val_loss: 0.9301 - val_acc: 0.8841\n",
      "Epoch 282/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0095 - acc: 0.9993 - val_loss: 0.9425 - val_acc: 0.8812\n",
      "Epoch 283/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1388 - acc: 0.9626 - val_loss: 0.9830 - val_acc: 0.8692\n",
      "Epoch 284/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0398 - acc: 0.9889 - val_loss: 0.9172 - val_acc: 0.8812\n",
      "Epoch 285/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0134 - acc: 0.9984 - val_loss: 0.9127 - val_acc: 0.8829\n",
      "Epoch 286/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0103 - acc: 0.9992 - val_loss: 0.9013 - val_acc: 0.8844\n",
      "Epoch 287/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0106 - acc: 0.9990 - val_loss: 0.9260 - val_acc: 0.8826\n",
      "Epoch 288/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0086 - acc: 0.9996 - val_loss: 0.9098 - val_acc: 0.8855\n",
      "Epoch 289/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0080 - acc: 0.9996 - val_loss: 0.9128 - val_acc: 0.8856\n",
      "Epoch 290/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0085 - acc: 0.9996 - val_loss: 0.9237 - val_acc: 0.8845\n",
      "Epoch 291/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0145 - acc: 0.9975 - val_loss: 1.0284 - val_acc: 0.8739\n",
      "Epoch 292/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1382 - acc: 0.9597 - val_loss: 0.9629 - val_acc: 0.8733\n",
      "Epoch 293/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0292 - acc: 0.9923 - val_loss: 0.9032 - val_acc: 0.8853\n",
      "Epoch 294/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0109 - acc: 0.9992 - val_loss: 0.9184 - val_acc: 0.8823\n",
      "Epoch 295/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0089 - acc: 0.9996 - val_loss: 0.9137 - val_acc: 0.8853\n",
      "Epoch 296/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0088 - acc: 0.9996 - val_loss: 0.9160 - val_acc: 0.8847\n",
      "Epoch 297/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0084 - acc: 0.9995 - val_loss: 0.9291 - val_acc: 0.8849\n",
      "Epoch 298/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0085 - acc: 0.9994 - val_loss: 0.9161 - val_acc: 0.8863\n",
      "Epoch 299/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0084 - acc: 0.9996 - val_loss: 0.9117 - val_acc: 0.8864\n",
      "Epoch 300/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0083 - acc: 0.9997 - val_loss: 0.9208 - val_acc: 0.8847\n",
      "Epoch 301/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0086 - acc: 0.9992 - val_loss: 0.9609 - val_acc: 0.8804\n",
      "Epoch 302/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1362 - acc: 0.9635 - val_loss: 0.9266 - val_acc: 0.8763\n",
      "Epoch 303/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0356 - acc: 0.9897 - val_loss: 0.9243 - val_acc: 0.8798\n",
      "Epoch 304/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0185 - acc: 0.9962 - val_loss: 0.9041 - val_acc: 0.8825\n",
      "Epoch 305/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0106 - acc: 0.9990 - val_loss: 0.9273 - val_acc: 0.8825\n",
      "Epoch 306/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0083 - acc: 0.9996 - val_loss: 0.9205 - val_acc: 0.8847\n",
      "Epoch 307/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0081 - acc: 0.9997 - val_loss: 0.9410 - val_acc: 0.8831\n",
      "Epoch 308/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0098 - acc: 0.9990 - val_loss: 0.9777 - val_acc: 0.8758\n",
      "Epoch 309/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0805 - acc: 0.9765 - val_loss: 1.0297 - val_acc: 0.8660\n",
      "Epoch 310/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0375 - acc: 0.9892 - val_loss: 0.9625 - val_acc: 0.8781\n",
      "Epoch 311/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0198 - acc: 0.9956 - val_loss: 0.9190 - val_acc: 0.8836\n",
      "Epoch 312/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0090 - acc: 0.9994 - val_loss: 0.9243 - val_acc: 0.8861\n",
      "Epoch 313/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0081 - acc: 0.9996 - val_loss: 0.9271 - val_acc: 0.8865\n",
      "Epoch 314/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0074 - acc: 0.9997 - val_loss: 0.9346 - val_acc: 0.8859\n",
      "Epoch 315/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0073 - acc: 0.9996 - val_loss: 0.9384 - val_acc: 0.8850\n",
      "Epoch 316/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0072 - acc: 0.9997 - val_loss: 0.9401 - val_acc: 0.8845\n",
      "Epoch 317/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0514 - acc: 0.9883 - val_loss: 1.2667 - val_acc: 0.8362\n",
      "Epoch 318/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1021 - acc: 0.9723 - val_loss: 0.9347 - val_acc: 0.8820\n",
      "Epoch 319/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0162 - acc: 0.9974 - val_loss: 0.9246 - val_acc: 0.8832\n",
      "Epoch 320/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0109 - acc: 0.9989 - val_loss: 0.9173 - val_acc: 0.8855\n",
      "Epoch 321/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0267 - acc: 0.9927 - val_loss: 0.9830 - val_acc: 0.8773\n",
      "Epoch 322/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0246 - acc: 0.9937 - val_loss: 0.9935 - val_acc: 0.8743\n",
      "Epoch 323/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0205 - acc: 0.9953 - val_loss: 0.9525 - val_acc: 0.8813\n",
      "Epoch 324/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0126 - acc: 0.9982 - val_loss: 0.9286 - val_acc: 0.8864\n",
      "Epoch 325/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0082 - acc: 0.9996 - val_loss: 0.9381 - val_acc: 0.8866\n",
      "Epoch 326/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0070 - acc: 0.9997 - val_loss: 0.9380 - val_acc: 0.8869\n",
      "Epoch 327/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0067 - acc: 0.9997 - val_loss: 0.9508 - val_acc: 0.8855\n",
      "Epoch 328/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0067 - acc: 0.9997 - val_loss: 0.9453 - val_acc: 0.8863\n",
      "Epoch 329/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0069 - acc: 0.9997 - val_loss: 0.9669 - val_acc: 0.8831\n",
      "Epoch 330/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.1043 - acc: 0.9750 - val_loss: 1.0313 - val_acc: 0.8607\n",
      "Epoch 331/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0597 - acc: 0.9811 - val_loss: 0.9619 - val_acc: 0.8784\n",
      "Epoch 332/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0140 - acc: 0.9980 - val_loss: 0.9350 - val_acc: 0.8852\n",
      "Epoch 333/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0134 - acc: 0.9981 - val_loss: 0.9669 - val_acc: 0.8793\n",
      "Epoch 334/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0094 - acc: 0.9994 - val_loss: 0.9545 - val_acc: 0.8828\n",
      "Epoch 335/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0073 - acc: 0.9997 - val_loss: 0.9467 - val_acc: 0.8851\n",
      "Epoch 336/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0070 - acc: 0.9997 - val_loss: 0.9546 - val_acc: 0.8831\n",
      "Epoch 337/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0068 - acc: 0.9997 - val_loss: 0.9560 - val_acc: 0.8841\n",
      "Epoch 338/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0571 - acc: 0.9869 - val_loss: 1.1018 - val_acc: 0.8611\n",
      "Epoch 339/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0680 - acc: 0.9820 - val_loss: 0.9866 - val_acc: 0.8798\n",
      "Epoch 340/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0191 - acc: 0.9959 - val_loss: 0.9528 - val_acc: 0.8827\n",
      "Epoch 341/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0090 - acc: 0.9994 - val_loss: 0.9692 - val_acc: 0.8830\n",
      "Epoch 342/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0075 - acc: 0.9997 - val_loss: 0.9467 - val_acc: 0.8855\n",
      "Epoch 343/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0067 - acc: 0.9997 - val_loss: 0.9558 - val_acc: 0.8840\n",
      "Epoch 344/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0066 - acc: 0.9997 - val_loss: 0.9594 - val_acc: 0.8842\n",
      "Epoch 345/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0067 - acc: 0.9997 - val_loss: 0.9631 - val_acc: 0.8835\n",
      "Epoch 346/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0067 - acc: 0.9997 - val_loss: 0.9698 - val_acc: 0.8835\n",
      "Epoch 347/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0432 - acc: 0.9906 - val_loss: 1.2622 - val_acc: 0.8327\n",
      "Epoch 348/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.1111 - acc: 0.9688 - val_loss: 0.9641 - val_acc: 0.8794\n",
      "Epoch 349/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0197 - acc: 0.9956 - val_loss: 0.9382 - val_acc: 0.8833\n",
      "Epoch 350/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0091 - acc: 0.9994 - val_loss: 0.9433 - val_acc: 0.8835\n",
      "Epoch 351/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0073 - acc: 0.9997 - val_loss: 0.9428 - val_acc: 0.8831\n",
      "Epoch 352/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0071 - acc: 0.9997 - val_loss: 0.9429 - val_acc: 0.8849\n",
      "Epoch 353/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0067 - acc: 0.9997 - val_loss: 0.9515 - val_acc: 0.8841\n",
      "Epoch 354/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0069 - acc: 0.9997 - val_loss: 0.9534 - val_acc: 0.8839\n",
      "Epoch 355/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0067 - acc: 0.9997 - val_loss: 0.9550 - val_acc: 0.8834\n",
      "Epoch 356/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0494 - acc: 0.9896 - val_loss: 1.0940 - val_acc: 0.8647\n",
      "Epoch 357/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0762 - acc: 0.9779 - val_loss: 0.9563 - val_acc: 0.8831\n",
      "Epoch 358/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0199 - acc: 0.9960 - val_loss: 0.9765 - val_acc: 0.8819\n",
      "Epoch 359/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0093 - acc: 0.9994 - val_loss: 0.9549 - val_acc: 0.8845\n",
      "Epoch 360/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0074 - acc: 0.9996 - val_loss: 0.9662 - val_acc: 0.8821\n",
      "Epoch 361/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0072 - acc: 0.9997 - val_loss: 0.9590 - val_acc: 0.8852\n",
      "Epoch 362/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0066 - acc: 0.9997 - val_loss: 0.9561 - val_acc: 0.8850\n",
      "Epoch 363/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0066 - acc: 0.9997 - val_loss: 0.9602 - val_acc: 0.8845\n",
      "Epoch 364/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0066 - acc: 0.9997 - val_loss: 0.9534 - val_acc: 0.8864\n",
      "Epoch 365/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0067 - acc: 0.9996 - val_loss: 0.9984 - val_acc: 0.8807\n",
      "Epoch 366/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1457 - acc: 0.9612 - val_loss: 1.0123 - val_acc: 0.8727\n",
      "Epoch 367/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0317 - acc: 0.9913 - val_loss: 0.9840 - val_acc: 0.8795\n",
      "Epoch 368/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0129 - acc: 0.9977 - val_loss: 0.9514 - val_acc: 0.8836\n",
      "Epoch 369/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0078 - acc: 0.9996 - val_loss: 0.9564 - val_acc: 0.8840\n",
      "Epoch 370/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0070 - acc: 0.9997 - val_loss: 0.9605 - val_acc: 0.8848\n",
      "Epoch 371/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0066 - acc: 0.9997 - val_loss: 0.9615 - val_acc: 0.8836\n",
      "Epoch 372/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0066 - acc: 0.9997 - val_loss: 0.9655 - val_acc: 0.8849\n",
      "Epoch 373/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0065 - acc: 0.9997 - val_loss: 0.9618 - val_acc: 0.8844\n",
      "Epoch 374/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0065 - acc: 0.9997 - val_loss: 0.9660 - val_acc: 0.8841\n",
      "Epoch 375/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0064 - acc: 0.9997 - val_loss: 0.9901 - val_acc: 0.8817\n",
      "Epoch 376/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.1191 - acc: 0.9683 - val_loss: 1.0307 - val_acc: 0.8701\n",
      "Epoch 377/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0390 - acc: 0.9883 - val_loss: 0.9460 - val_acc: 0.8837\n",
      "Epoch 378/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0138 - acc: 0.9978 - val_loss: 0.9559 - val_acc: 0.8839\n",
      "Epoch 379/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0100 - acc: 0.9989 - val_loss: 0.9511 - val_acc: 0.8860\n",
      "Epoch 380/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0071 - acc: 0.9997 - val_loss: 0.9545 - val_acc: 0.8855\n",
      "Epoch 381/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0067 - acc: 0.9997 - val_loss: 0.9618 - val_acc: 0.8859\n",
      "Epoch 382/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0065 - acc: 0.9997 - val_loss: 0.9624 - val_acc: 0.8864\n",
      "Epoch 383/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0065 - acc: 0.9997 - val_loss: 0.9859 - val_acc: 0.8830\n",
      "Epoch 384/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0425 - acc: 0.9894 - val_loss: 1.1672 - val_acc: 0.8547\n",
      "Epoch 385/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0987 - acc: 0.9724 - val_loss: 1.0049 - val_acc: 0.8763\n",
      "Epoch 386/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0180 - acc: 0.9965 - val_loss: 0.9692 - val_acc: 0.8822\n",
      "Epoch 387/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0079 - acc: 0.9996 - val_loss: 0.9651 - val_acc: 0.8829\n",
      "Epoch 388/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0069 - acc: 0.9997 - val_loss: 0.9779 - val_acc: 0.8837\n",
      "Epoch 389/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0065 - acc: 0.9997 - val_loss: 0.9721 - val_acc: 0.8840\n",
      "Epoch 390/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0063 - acc: 0.9997 - val_loss: 0.9817 - val_acc: 0.8826\n",
      "Epoch 391/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0070 - acc: 0.9996 - val_loss: 0.9794 - val_acc: 0.8834\n",
      "Epoch 392/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0064 - acc: 0.9997 - val_loss: 0.9870 - val_acc: 0.8828\n",
      "Epoch 393/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0064 - acc: 0.9997 - val_loss: 0.9794 - val_acc: 0.8841\n",
      "Epoch 394/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0119 - acc: 0.9980 - val_loss: 1.1074 - val_acc: 0.8695\n",
      "Epoch 395/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1477 - acc: 0.9630 - val_loss: 1.0089 - val_acc: 0.8750\n",
      "Epoch 396/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0265 - acc: 0.9935 - val_loss: 0.9424 - val_acc: 0.8863\n",
      "Epoch 397/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0153 - acc: 0.9972 - val_loss: 1.0050 - val_acc: 0.8777\n",
      "Epoch 398/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0130 - acc: 0.9979 - val_loss: 0.9746 - val_acc: 0.8845\n",
      "Epoch 399/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0074 - acc: 0.9996 - val_loss: 0.9756 - val_acc: 0.8827\n",
      "Epoch 400/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0064 - acc: 0.9997 - val_loss: 0.9835 - val_acc: 0.8824\n",
      "Epoch 401/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0062 - acc: 0.9997 - val_loss: 0.9882 - val_acc: 0.8835\n",
      "Epoch 402/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0062 - acc: 0.9997 - val_loss: 0.9809 - val_acc: 0.8849\n",
      "Epoch 403/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0109 - acc: 0.9984 - val_loss: 1.1062 - val_acc: 0.8718\n",
      "Epoch 404/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0976 - acc: 0.9733 - val_loss: 0.9929 - val_acc: 0.8769\n",
      "Epoch 405/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0244 - acc: 0.9937 - val_loss: 1.0050 - val_acc: 0.8775\n",
      "Epoch 406/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0155 - acc: 0.9971 - val_loss: 0.9909 - val_acc: 0.8821\n",
      "Epoch 407/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0074 - acc: 0.9996 - val_loss: 0.9850 - val_acc: 0.8844\n",
      "Epoch 408/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0065 - acc: 0.9997 - val_loss: 0.9854 - val_acc: 0.8836\n",
      "Epoch 409/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0063 - acc: 0.9997 - val_loss: 0.9903 - val_acc: 0.8832\n",
      "Epoch 410/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0062 - acc: 0.9997 - val_loss: 1.0068 - val_acc: 0.8832\n",
      "Epoch 411/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0068 - acc: 0.9996 - val_loss: 1.0235 - val_acc: 0.8789\n",
      "Epoch 412/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.1163 - acc: 0.9700 - val_loss: 0.9935 - val_acc: 0.8773\n",
      "Epoch 413/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0254 - acc: 0.9934 - val_loss: 1.0196 - val_acc: 0.8803\n",
      "Epoch 414/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0096 - acc: 0.9991 - val_loss: 0.9935 - val_acc: 0.8827\n",
      "Epoch 415/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0067 - acc: 0.9997 - val_loss: 0.9989 - val_acc: 0.8838\n",
      "Epoch 416/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0063 - acc: 0.9997 - val_loss: 0.9979 - val_acc: 0.8822\n",
      "Epoch 417/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0060 - acc: 0.9997 - val_loss: 1.0034 - val_acc: 0.8829\n",
      "Epoch 418/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0059 - acc: 0.9997 - val_loss: 0.9983 - val_acc: 0.8836\n",
      "Epoch 419/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0060 - acc: 0.9997 - val_loss: 0.9966 - val_acc: 0.8836\n",
      "Epoch 420/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0827 - acc: 0.9771 - val_loss: 1.0987 - val_acc: 0.8634\n",
      "Epoch 421/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0424 - acc: 0.9877 - val_loss: 1.0056 - val_acc: 0.8793\n",
      "Epoch 422/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0129 - acc: 0.9979 - val_loss: 0.9966 - val_acc: 0.8832\n",
      "Epoch 423/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0074 - acc: 0.9996 - val_loss: 0.9868 - val_acc: 0.8831\n",
      "Epoch 424/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0143 - acc: 0.9972 - val_loss: 1.0480 - val_acc: 0.8736\n",
      "Epoch 425/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0401 - acc: 0.9885 - val_loss: 1.0295 - val_acc: 0.8783\n",
      "Epoch 426/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0184 - acc: 0.9960 - val_loss: 1.0031 - val_acc: 0.8795\n",
      "Epoch 427/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0193 - acc: 0.9949 - val_loss: 0.9957 - val_acc: 0.8835\n",
      "Epoch 428/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0072 - acc: 0.9996 - val_loss: 0.9899 - val_acc: 0.8833\n",
      "Epoch 429/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0061 - acc: 0.9997 - val_loss: 1.0032 - val_acc: 0.8834\n",
      "Epoch 430/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0058 - acc: 0.9997 - val_loss: 1.0015 - val_acc: 0.8837\n",
      "Epoch 431/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0057 - acc: 0.9997 - val_loss: 1.0032 - val_acc: 0.8834\n",
      "Epoch 432/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0063 - acc: 0.9994 - val_loss: 1.0436 - val_acc: 0.8781\n",
      "Epoch 433/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.1346 - acc: 0.9660 - val_loss: 0.9820 - val_acc: 0.8804\n",
      "Epoch 434/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0223 - acc: 0.9944 - val_loss: 1.0088 - val_acc: 0.8785\n",
      "Epoch 435/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0101 - acc: 0.9989 - val_loss: 0.9872 - val_acc: 0.8832\n",
      "Epoch 436/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0067 - acc: 0.9997 - val_loss: 0.9963 - val_acc: 0.8830\n",
      "Epoch 437/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0062 - acc: 0.9997 - val_loss: 0.9935 - val_acc: 0.8839\n",
      "Epoch 438/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0059 - acc: 0.9997 - val_loss: 0.9929 - val_acc: 0.8836\n",
      "Epoch 439/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0058 - acc: 0.9997 - val_loss: 1.0049 - val_acc: 0.8833\n",
      "Epoch 440/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0058 - acc: 0.9997 - val_loss: 1.0165 - val_acc: 0.8841\n",
      "Epoch 441/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0058 - acc: 0.9997 - val_loss: 1.0033 - val_acc: 0.8842\n",
      "Epoch 442/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0057 - acc: 0.9997 - val_loss: 1.0045 - val_acc: 0.8849\n",
      "Epoch 443/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0058 - acc: 0.9997 - val_loss: 1.0147 - val_acc: 0.8829\n",
      "Epoch 444/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1265 - acc: 0.9704 - val_loss: 1.0431 - val_acc: 0.8699\n",
      "Epoch 445/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0409 - acc: 0.9883 - val_loss: 0.9821 - val_acc: 0.8803\n",
      "Epoch 446/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0122 - acc: 0.9985 - val_loss: 0.9978 - val_acc: 0.8806\n",
      "Epoch 447/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0073 - acc: 0.9997 - val_loss: 0.9993 - val_acc: 0.8837\n",
      "Epoch 448/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0067 - acc: 0.9997 - val_loss: 1.0041 - val_acc: 0.8835\n",
      "Epoch 449/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0063 - acc: 0.9997 - val_loss: 1.0059 - val_acc: 0.8840\n",
      "Epoch 450/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0061 - acc: 0.9997 - val_loss: 1.0123 - val_acc: 0.8840\n",
      "Epoch 451/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0060 - acc: 0.9997 - val_loss: 1.0146 - val_acc: 0.8838\n",
      "Epoch 452/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0058 - acc: 0.9997 - val_loss: 1.0123 - val_acc: 0.8847\n",
      "Epoch 453/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0058 - acc: 0.9997 - val_loss: 1.0080 - val_acc: 0.8844\n",
      "Epoch 454/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1054 - acc: 0.9712 - val_loss: 1.0685 - val_acc: 0.8704\n",
      "Epoch 455/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0413 - acc: 0.9877 - val_loss: 1.0387 - val_acc: 0.8766\n",
      "Epoch 456/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0195 - acc: 0.9954 - val_loss: 1.0344 - val_acc: 0.8795\n",
      "Epoch 457/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0080 - acc: 0.9993 - val_loss: 1.0131 - val_acc: 0.8825\n",
      "Epoch 458/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0062 - acc: 0.9997 - val_loss: 1.0091 - val_acc: 0.8815\n",
      "Epoch 459/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0058 - acc: 0.9997 - val_loss: 1.0189 - val_acc: 0.8830\n",
      "Epoch 460/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0057 - acc: 0.9997 - val_loss: 1.0240 - val_acc: 0.8826\n",
      "Epoch 461/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0056 - acc: 0.9997 - val_loss: 1.0248 - val_acc: 0.8832\n",
      "Epoch 462/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0055 - acc: 0.9997 - val_loss: 1.0203 - val_acc: 0.8839\n",
      "Epoch 463/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0056 - acc: 0.9997 - val_loss: 1.0212 - val_acc: 0.8832\n",
      "Epoch 464/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0055 - acc: 0.9997 - val_loss: 1.0371 - val_acc: 0.8821\n",
      "Epoch 465/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0055 - acc: 0.9997 - val_loss: 1.0153 - val_acc: 0.8842\n",
      "Epoch 466/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1098 - acc: 0.9744 - val_loss: 1.0435 - val_acc: 0.8728\n",
      "Epoch 467/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0424 - acc: 0.9880 - val_loss: 1.0769 - val_acc: 0.8719\n",
      "Epoch 468/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0159 - acc: 0.9971 - val_loss: 1.0000 - val_acc: 0.8844\n",
      "Epoch 469/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0075 - acc: 0.9995 - val_loss: 1.0058 - val_acc: 0.8849\n",
      "Epoch 470/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0070 - acc: 0.9996 - val_loss: 1.0187 - val_acc: 0.8834\n",
      "Epoch 471/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0058 - acc: 0.9997 - val_loss: 1.0115 - val_acc: 0.8851\n",
      "Epoch 472/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0057 - acc: 0.9997 - val_loss: 1.0167 - val_acc: 0.8852\n",
      "Epoch 473/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0056 - acc: 0.9997 - val_loss: 1.0185 - val_acc: 0.8845\n",
      "Epoch 474/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0057 - acc: 0.9997 - val_loss: 1.0174 - val_acc: 0.8858\n",
      "Epoch 475/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0055 - acc: 0.9997 - val_loss: 1.0185 - val_acc: 0.8852\n",
      "Epoch 476/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0055 - acc: 0.9997 - val_loss: 1.0239 - val_acc: 0.8847\n",
      "Epoch 477/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0054 - acc: 0.9997 - val_loss: 1.0253 - val_acc: 0.8851\n",
      "Epoch 478/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0056 - acc: 0.9997 - val_loss: 1.0329 - val_acc: 0.8836\n",
      "Epoch 479/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1476 - acc: 0.9633 - val_loss: 1.0699 - val_acc: 0.8706\n",
      "Epoch 480/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0257 - acc: 0.9929 - val_loss: 1.0196 - val_acc: 0.8801\n",
      "Epoch 481/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0091 - acc: 0.9993 - val_loss: 1.0013 - val_acc: 0.8846\n",
      "Epoch 482/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0070 - acc: 0.9996 - val_loss: 1.0167 - val_acc: 0.8831\n",
      "Epoch 483/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0063 - acc: 0.9997 - val_loss: 1.0125 - val_acc: 0.8845\n",
      "Epoch 484/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0061 - acc: 0.9997 - val_loss: 1.0144 - val_acc: 0.8849\n",
      "Epoch 485/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0058 - acc: 0.9997 - val_loss: 1.0160 - val_acc: 0.8839\n",
      "Epoch 486/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0057 - acc: 0.9997 - val_loss: 1.0164 - val_acc: 0.8858\n",
      "Epoch 487/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0056 - acc: 0.9997 - val_loss: 1.0213 - val_acc: 0.8850\n",
      "Epoch 488/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0056 - acc: 0.9997 - val_loss: 1.0233 - val_acc: 0.8845\n",
      "Epoch 489/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0692 - acc: 0.9865 - val_loss: 1.3330 - val_acc: 0.8448\n",
      "Epoch 490/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.1140 - acc: 0.9713 - val_loss: 1.0168 - val_acc: 0.8791\n",
      "Epoch 491/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0160 - acc: 0.9967 - val_loss: 1.0250 - val_acc: 0.8803\n",
      "Epoch 492/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0119 - acc: 0.9979 - val_loss: 1.0115 - val_acc: 0.8853\n",
      "Epoch 493/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0068 - acc: 0.9996 - val_loss: 1.0188 - val_acc: 0.8845\n",
      "Epoch 494/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0059 - acc: 0.9997 - val_loss: 1.0205 - val_acc: 0.8848\n",
      "Epoch 495/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0056 - acc: 0.9997 - val_loss: 1.0234 - val_acc: 0.8837\n",
      "Epoch 496/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0055 - acc: 0.9997 - val_loss: 1.0171 - val_acc: 0.8862\n",
      "Epoch 497/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0054 - acc: 0.9997 - val_loss: 1.0241 - val_acc: 0.8857\n",
      "Epoch 498/500\n",
      "34108/34108 [==============================] - 1s 40us/step - loss: 0.0053 - acc: 0.9997 - val_loss: 1.0326 - val_acc: 0.8840\n",
      "Epoch 499/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0053 - acc: 0.9997 - val_loss: 1.0260 - val_acc: 0.8853\n",
      "Epoch 500/500\n",
      "34108/34108 [==============================] - 1s 39us/step - loss: 0.0053 - acc: 0.9997 - val_loss: 1.0351 - val_acc: 0.8827\n"
     ]
    }
   ],
   "source": [
    "nb_neurones =[10,100,200,400,600,750,1000]\n",
    "models = []\n",
    "models_history = []\n",
    "for i, nb in enumerate(nb_neurones):\n",
    "    tmp = Sequential([\n",
    "        Dense(nb, input_shape=(256,), activation='relu'),\n",
    "        Dense(5, activation='softmax')\n",
    "    ])\n",
    "    tmp.compile(loss= \"categorical_crossentropy\",\n",
    "               optimizer = Adam(),\n",
    "               metrics=['accuracy'])\n",
    "    models.append(tmp)\n",
    "    history = tmp.fit(x_train, y_train,\n",
    "           batch_size= 128,\n",
    "           epochs=500,\n",
    "           verbose=1,\n",
    "           validation_data=(x_test, y_test))\n",
    "    models_history.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEdCAYAAABZtfMGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAUoppZRX0gCllFLKK/0/jX525+o2yLYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1833357470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEdCAYAAABZtfMGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/JIlKGOMMX7JEpQxxhi/9P+Fiu4yjbcu3gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18334269e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEdCAYAAABZtfMGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkgco55xzkeQByjnnXCT9DYjELC3SbDzHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1832edaf60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEdCAYAAABZtfMGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLWkFpZRSypa0glJKKWVL/w/8kHohftsbWAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x183123a860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEdCAYAAABZtfMGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18331e3588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEdCAYAAABZtfMGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x183403a9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEdCAYAAABZtfMGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18341615f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in models_history:\n",
    "    plot_history(i, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Comparison to deep models\n",
    "\n",
    "### Description\n",
    "\n",
    "Instead of choosing one hidden layer (with many neurons) you experiment here with multiple hidden layers (each with not so many neurons).\n",
    "\n",
    "1. Fit models with 2, 3 and 4 hidden layers with approximately the same number of parameters as a network with one hidden layer of 100 neurons. Hint: Calculate the number of parameters in a network with input dimensionality N_in, K hidden layers with N_h units, one output layer with N_out dimensions and solve for N_h. Confirm you result with the keras method model.summary().\n",
    "2. Run each model multiple times with different initial conditions and plot summary statistics of the best validation loss and accuracy versus the number of hidden layers.\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Tricks (regularization, batch normalization, dropout)\n",
    "\n",
    "### Description\n",
    "\n",
    "Overfitting can also be counteracted with regularization and dropout. Batch normalization is supposed to mainly decrease convergence time.\n",
    "\n",
    "1. Try to improve the best validation scores of the model with 1 layer and 100 hidden neurons and the model with 4 hidden layers. Experiment with batch_normalization layers, dropout layers and l1- and l2-regularization on weights (kernels) and biases.\n",
    "2. After you have found good settings, plot for both models the learning curves of the naive model you fitted in the previous exercises together with the learning curves of the current version.\n",
    "3. For proper comparison, plot also the learning curves of the two current models in a third figure.\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7: Convolutional networks\n",
    "\n",
    "### Description\n",
    "\n",
    "Convolutional neural networks have an inductive bias that is well adapted to image classification.\n",
    "\n",
    "1. Design a convolutional neural network, play with the parameters and fit it. Hint: You may get valuable inspiration from the keras [examples](https://github.com/keras-team/keras/tree/master/examples), e.g. [mnist_cnn](https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py).\n",
    "2. Plot the learning curves of the convolutional neural network together with the so far best performing model.\n",
    "\n",
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
